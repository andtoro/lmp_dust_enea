{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA HANDLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates               \n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis, pearsonr, norm\n",
    "import itertools\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange\n",
    "from matplotlib.table import Table\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import datetime\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun, daylight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to detect the right header line\n",
    "# with open(\"/home/andrea/enea_project/data/data_new_2025/out/Aleria_MF/20240101_20241231_ALERIA_MF.lev15\", 'r') as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         if \"Date\" in line:\n",
    "#             header_row = i\n",
    "#             break\n",
    "\n",
    "# # Read the file from that header\n",
    "# df = pd.read_csv(\"/home/andrea/enea_project/data/data_new_2025/out/Aleria_MF/20240101_20241231_ALERIA_MF.lev15\", skiprows=header_row, delimiter=',')\n",
    "# print(df['Date(dd:mm:yyyy)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "stazioni = [\"ALERIA_MF\", \"Ersa\", \"Modena\", \"Potenza\", \"Aosta\", \"Ispra\", \"Medenine\", \"Napoli\"]\n",
    "year = [23, 24, 25]\n",
    "out = [\"conc\", \"meteo\"]\n",
    "\n",
    "dati_path = {}\n",
    "mod_path = {}\n",
    "\n",
    "for j in stazioni:\n",
    "    # Store observation paths per year\n",
    "    dati_path[j] = {\n",
    "        y: f\"/home/andrea/enea_project/data/data_new_2025/obs/{j}_obs/20{y}0101_20{y}1231_{j}/20{y}0101_20{y}1231_{j}.lev15\"\n",
    "        for y in year\n",
    "    }\n",
    "\n",
    "    # Store model paths per output type\n",
    "    mod_path[j] = {\n",
    "        mod: f\"/home/andrea/enea_project/data/data_new_2025/out/{j}/{mod}_{j}.nc\"\n",
    "        for mod in out\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati = {}\n",
    "\n",
    "for y in year:\n",
    "    with open(dati_path['Modena'][y], 'r', encoding= 'latin1') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if \"Date\" in line:\n",
    "                header_row = i\n",
    "                break \n",
    "    dat = pd.read_csv(dati_path['Modena'][y], skiprows=header_row, delimiter=',', encoding='latin1')\n",
    "    dati[y]= dat\n",
    "\n",
    "df_lmp_dump = pd.concat([pd.concat([pd.DataFrame(dati[23]), pd.DataFrame(dati[24])], axis= 0), pd.DataFrame(dati[25])], axis= 0)\n",
    "df_lmp_dump.reset_index(inplace= True, drop= False)\n",
    "df_lmp_dummy = pd.DataFrame({'time': df_lmp_dump['Day_of_Year(Fraction)'][1:], '675nm': df_lmp_dump['AOD_675nm'][1:], '500nm': df_lmp_dump['AOD_500nm'][1:], 'ang_440_870': df_lmp_dump['440-870_Angstrom_Exponent'][1:], 'ang_440_675': df_lmp_dump['440-675_Angstrom_Exponent'][1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_lmp_dummy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dati[25])+len(dati[24])+len(dati[23]))\n",
    "print(len(df_lmp_dummy))\n",
    "print(dati[24].index[-1]+dati[23].index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes:  LMP, FARM, IMP1F, IMP2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting pandas to print whole dataframes \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# open and read file.netCDF4 and file.xlsx\n",
    "\n",
    "# LETTURA FILE PER LAMPEDUSA\n",
    "\n",
    "#####################################\n",
    "\n",
    "# station_path_obs_23 = \"/home/andrea/enea_project/data/data_new_2025/20230101_20240619_Lampedusa.lev15_02072024.xlsx\"\n",
    "# station_path_obs_25 = \"/home/andrea/enea_project/data/data_new_2025/20250101_20251231_Lampedusa.lev15.xlsx\"\n",
    "# station_path_obs_24 = \"/home/andrea/enea_project/data/data_new_2025/20240101_20241231_Lampedusa.lev15.xlsx\"\n",
    "\n",
    "# dati_25 = pd.read_excel(station_path_obs_25, header= 6)\n",
    "# dati_24 = pd.read_excel(station_path_obs_24, header= 6)\n",
    "# dati_23 = pd.read_excel(station_path_obs_23, header= 7)\n",
    "# dati_23 = dati_23[dati_23.index <= 25827]\n",
    "\n",
    "#####################################\n",
    "\n",
    "# Read the file from that header\n",
    "\n",
    "save_fig = True\n",
    "name_save_fig = \"modena\"\n",
    "\n",
    "dati = {}\n",
    "\n",
    "for y in year:\n",
    "    with open(dati_path['Modena'][y], 'r', encoding= 'latin1') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if \"Date\" in line:\n",
    "                header_row = i\n",
    "                break \n",
    "    dat = pd.read_csv(dati_path['Modena'][y], skiprows=header_row, delimiter=',', encoding= 'latin1')\n",
    "    dati[y]= dat\n",
    "\n",
    "df_lmp_dump = pd.concat([pd.concat([pd.DataFrame(dati[23]), pd.DataFrame(dati[24])], axis= 0), pd.DataFrame(dati[25])], axis= 0)\n",
    "df_lmp_dump.reset_index(inplace= True, drop= True)\n",
    "\n",
    "# PATH FOR EACH STATION\n",
    "\n",
    "# station_path_conc = \"/home/andrea/enea_project/data/data_new_2025/out/Lampedusa/conc_Lampedusa.nc\"\n",
    "# station_path_meteo = \"/home/andrea/enea_project/data/data_new_2025/out/Lampedusa/meteo_Lampedusa.nc\"\n",
    "\n",
    "# build the dataframe of observations only with the information that it is going to be used\n",
    "#df_lmp_dummy = pd.DataFrame({'time': df_lmp_dump['Day_of_Year(Fraction)'][1:], '675nm': df_lmp_dump['AOD_675nm'][1:], '500nm': df_lmp_dump['AOD_500nm'][1:], '440nm': df_lmp_dump['AOD_440nm'][1:], 'pw': df_lmp_dump['Precipitable_Water(cm)'][1:], 'ang_440_870': df_lmp_dump['440-870_Angstrom_Exponent'][1:], 'ang_440_675': df_lmp_dump['440-675_Angstrom_Exponent'][1:], 'ang_500_870': df_lmp_dump['500-870_Angstrom_Exponent'][1:]}) #'sza': df_lmp_dump['info su cui riflettere'][2:], 'oam': df_lmp_dump['info su cui riflettere.1'][2:]\n",
    "\n",
    "df_lmp_dummy = pd.DataFrame({'time': df_lmp_dump['Day_of_Year(Fraction)'][1:], '675nm': df_lmp_dump['AOD_675nm'][1:], '500nm': df_lmp_dump['AOD_500nm'][1:], 'ang_440_870': df_lmp_dump['440-870_Angstrom_Exponent'][1:], 'ang_440_675': df_lmp_dump['440-675_Angstrom_Exponent'][1:]})\n",
    "\n",
    "# decoding time for observed data and famr and meteo data. Observation starting time: 2022-12-31 00:00:00. Simulation starting time: 1900-01-01 00:00:00\n",
    "\n",
    "df_f_dump = netCDF4.Dataset(mod_path['Modena']['conc'], 'r')\n",
    "df_m_dump = netCDF4.Dataset(mod_path['Modena']['meteo'], 'r')\n",
    "\n",
    "# reopen files\n",
    "reference_time_f_m = dt.datetime(1900, 1, 1, 0, 0, 0)\n",
    "reference_time_lmp = dt.datetime(2022, 12, 31, 1, 0, 0) # from UTC to UTC+1\n",
    "decoded_time_f = [reference_time_f_m + dt.timedelta(hours= float(t)) for t in df_f_dump.variables['time'][:]]\n",
    "decoded_time_m = [reference_time_f_m + dt.timedelta(hours= float(t)) for t in df_m_dump.variables['time'][:]]\n",
    "\n",
    "# define error of AOD and ANG\n",
    "err_aod = 0.021\n",
    "err_ang = 0.001\n",
    "err_ang_440_675 = abs(-(1/np.log(500/675))*((err_aod/df_lmp_dummy['500nm'])-(err_aod/df_lmp_dummy['675nm']))) # prima era tra 400nm e 675nm ora facciamo tra 500nm e 675nm\n",
    "\n",
    "# convert aod at 500nm to aod at 550nm through Angstrom exponent in the range of 500-870nm using the Beer-Lambert law\n",
    "aod550 = df_lmp_dummy['500nm']*(550/500)**(-df_lmp_dummy['ang_440_675'])\n",
    "err_aod550 = (err_aod*(aod550/df_lmp_dummy['500nm']) + err_ang*abs(np.log(500/550))*aod550)\n",
    "err_aod550_new = (err_aod*(aod550/df_lmp_dummy['500nm']) + err_ang_440_675*abs(np.log(500/550))*aod550)\n",
    "\n",
    "# multiplied time for 24 to covert the day fraction of the year in hours to obtain the decoded time of observations\n",
    "#df_lmp = pd.DataFrame({'time': df_lmp_dummy['time']*(24), '675nm': df_lmp_dummy['675nm'], '500nm': df_lmp_dummy['500nm'], 'LMP': aod550, 'err_550': err_aod550, '440nm': df_lmp_dummy['440nm'], 'pw': df_lmp_dummy['pw'], 'ang_440_870': df_lmp_dummy['ang_440_870'], 'ang_440_675': df_lmp_dummy['ang_440_675'], 'ang_500_870': df_lmp_dummy['ang_500_870']}) \n",
    "df_lmp = pd.DataFrame({'time': df_lmp_dummy['time']*(24), '675nm': df_lmp_dummy['675nm'], '500nm': df_lmp_dummy['500nm'], 'LMP': aod550, 'err_550': err_aod550, 'ang_440_870': df_lmp_dummy['ang_440_870'], 'ang_440_675': df_lmp_dummy['ang_440_675']}) #'sza': df_lmp_dummy['sza'], 'oam': df_lmp_dummy['oam']\n",
    "index_1 = dati[23].index[-1]\n",
    "index_2 = dati[24].index[-1] + dati[23].index[-1]\n",
    "number_to_add = df_lmp.iloc[index_1, 0]\n",
    "number_to_add_2 = df_lmp.iloc[index_2, 0]\n",
    "df_lmp_mod = df_lmp.copy()\n",
    "\n",
    "# adding hours at the beginning of the new year because the counter was inizialized and the decoded time was giving the same year\n",
    "df_lmp_mod.loc[df_lmp_mod.index > index_1 + 1, 'time'] += 365*24\n",
    "df_lmp_mod.loc[df_lmp_mod.index > index_2 + 1, 'time'] += 366*24\n",
    "\n",
    "df_lmp.reset_index(drop= True, inplace= True)\n",
    "df_lmp_mod.reset_index(drop= True, inplace= True)\n",
    "decoded_time_lmp = [reference_time_lmp + dt.timedelta(hours= float(t)) for t in df_lmp_mod['time'][:]]\n",
    "#decoded_time_lmp = [reference_time_lmp + dt.timedelta(hours= float(t)) for t in df_lmp['time'][:]]\n",
    "\n",
    "# convert decoded time into pandas datetime object\n",
    "dt_f = pd.to_datetime(decoded_time_f)\n",
    "dt_m = pd.to_datetime(decoded_time_m)\n",
    "dt_lmp = pd.to_datetime(decoded_time_lmp)\n",
    "\n",
    "# defining dataframe with time coded in pandas format, using pd.to_datetime\n",
    "#df_lmp_filter = pd.DataFrame({'time': dt_lmp, '675nm': df_lmp_dummy['675nm'], '500nm': df_lmp_dummy['500nm'], 'LMP': aod550, 'err_550': err_aod550, 'err_new': err_aod550_new, '440nm': df_lmp_dummy['440nm'], 'pw': df_lmp_dummy['pw'], 'ang_440_870': df_lmp_dummy['ang_440_870'], 'ang_440_675': df_lmp_dummy['ang_440_675'], 'ang_500_870': df_lmp_dummy['ang_500_870']})\n",
    "df_lmp_filter = pd.DataFrame({'time': dt_lmp, '675nm': df_lmp_dummy['675nm'], '500nm': df_lmp_dummy['500nm'], 'LMP': aod550, 'err_550': err_aod550, 'err_new': err_aod550_new, 'ang_440_870': df_lmp_dummy['ang_440_870'], 'ang_440_675': df_lmp_dummy['ang_440_675']}) # 'sza': df_lmp_dummy['sza'], 'oam': df_lmp_dummy['oam']\n",
    "\n",
    "# filter data from -999 values\n",
    "#df_lmp_filter = df_lmp_filter[(df_lmp_filter['LMP'] != -999) & (df_lmp_filter['LMP'] >= 0) & (df_lmp_filter['500nm'] != -999) & (df_lmp_filter['500nm'] >= 0) & (df_lmp_filter['675nm'] != -999) & (df_lmp_filter['675nm'] >= 0) & (df_lmp_filter['440nm'] != -999) & (df_lmp_filter['440nm'] >= 0) & (df_lmp_filter['pw'] != -999) & (df_lmp_filter['pw'] >= 0) & (df_lmp_filter['ang_500_870'] != -999) & (df_lmp_filter['ang_500_870'] >= 0)]\n",
    "df_lmp_filter = df_lmp_filter[(df_lmp_filter['LMP'] != -999) & (df_lmp_filter['LMP'] >= 0) & (df_lmp_filter['LMP'] < 100) & (df_lmp_filter['500nm'] != -999) & (df_lmp_filter['500nm'] >= 0) & (df_lmp_filter['675nm'] != -999) & (df_lmp_filter['675nm'] >= 0)]\n",
    "df_lmp_filter.reset_index(drop= True, inplace= True)\n",
    "\n",
    "rayleigh = 0.0729 # in FARM\n",
    "# now we create FARM and METEO dataframes with varibles of interest\n",
    "df_m = pd.DataFrame({'time': dt_m, 'REL': df_m_dump.variables['REL'][:], 'HMIX': df_m_dump.variables['HMIX'][:]})\n",
    "df_f = pd.DataFrame({'time': dt_f, 'AOD': df_f_dump['AOD'][:], 'FARM': (df_f_dump['AOD'][:]-rayleigh)})\n",
    "#'ALB': df_m_dump.variables['ALBEDO'][:],\n",
    "#'TCC': df_m_dump.variables['TCC'][:]/(10),\n",
    "#'PREC': df_m_dump.variables['PREC'][:],\n",
    "print(df_lmp_filter['time'][0:1])\n",
    "print(df_lmp_filter['time'][len(df_lmp_filter)-1:len(df_lmp_filter)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = pd.Timestamp(\"2022-12-31 01:00:00\")\n",
    "# end = pd.Timestamp(\"2025-05-13 06:54:13\")  # or exact time from Excel\n",
    "# total_expected_hours = (end - start).total_seconds() / 3600\n",
    "# print(\"Expected total hours:\", total_expected_hours)\n",
    "# print(df_lmp_mod['time'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert start_time and end_time to datetime objects\n",
    "start_time = pd.to_datetime(df_lmp_filter['time'].iloc[0])\n",
    "end_time = pd.to_datetime(df_lmp_filter['time'].iloc[-1])\n",
    "\n",
    "# Filter data within the time range using .loc[]\n",
    "df_lampedusa_f = df_lmp_filter.loc[(df_lmp_filter['time'] >= start_time) & (df_lmp_filter['time'] <= end_time)]\n",
    "df_farm_f = df_f.loc[(df_f['time'] >= start_time) & (df_f['time'] <= end_time)]\n",
    "df_meteo_f = df_m.loc[(df_m['time'] >= start_time) & (df_m['time'] <= end_time)]\n",
    "\n",
    "# Print the filtered DataFrames to verify\n",
    "print(df_lampedusa_f.head())\n",
    "print(df_farm_f)\n",
    "#print(df_meteo_f.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto correlation function, using the statsmodels library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "time_index = pd.to_datetime(df_lampedusa_f['time'])\n",
    "df_time_index = pd.DataFrame({'aod': df_lampedusa_f['LMP'], 'time': df_lampedusa_f['time']}).reset_index(inplace= False, drop= True).set_index('time')\n",
    "\n",
    "daily_groups = {day: group for day, group in df_time_index.groupby(df_time_index.index.date)}\n",
    "# fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "# for day, groups in daily_groups.items():\n",
    "#     func = acf(\n",
    "#         daily_groups[day]['aod'],\n",
    "#         missing= \"conservative\",\n",
    "#         bartlett_confint= False,\n",
    "#         adjusted= True,\n",
    "#         nlags = 1, \n",
    "#         fft= True\n",
    "#         )\n",
    "#     plot_acf(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for day, group in daily_groups.items():\n",
    "#     # Drop NaNs to avoid issues\n",
    "#     aod_series = group['aod'].dropna()\n",
    "    \n",
    "#     if len(aod_series) > 1:  # ACF needs at least 2 data points\n",
    "#         print(f\"Plotting ACF for {day}\")\n",
    "        \n",
    "#         plot_acf(\n",
    "#             aod_series,\n",
    "#             missing=\"conservative\",\n",
    "#             bartlett_confint=False,\n",
    "#             adjusted=True,\n",
    "#             lags=len(aod_series)-1,\n",
    "#             fft=True,\n",
    "#             title=f\"ACF for {day}\",\n",
    "#             alpha=None\n",
    "#         )\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import math\n",
    "\n",
    "# Filter only groups with at least 2 non-NaN points\n",
    "valid_groups = {day: g['aod'].dropna() for day, g in daily_groups.items() if g['aod'].dropna().shape[0] > 1}\n",
    "\n",
    "n_plots = len(valid_groups)\n",
    "n_cols = 5  # Choose how many columns you want\n",
    "n_rows = math.ceil(n_plots / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows), squeeze=False)\n",
    "\n",
    "for ax, (day, series) in zip(axes.flat, valid_groups.items()):\n",
    "    plot_acf(\n",
    "        series,\n",
    "        ax=ax,\n",
    "        lags=len(series)-1,\n",
    "        title=str(day),\n",
    "        missing=\"conservative\",\n",
    "        bartlett_confint=False,\n",
    "        adjusted=True,\n",
    "        fft=True, \n",
    "        alpha=None\n",
    "    )\n",
    "\n",
    "# Hide any unused axes\n",
    "for ax in axes.flat[n_plots:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measeure = df_lmp_filter.copy()\n",
    "\n",
    "df_measeure['year'] = df_measeure['time'].dt.year\n",
    "df_measeure['month'] = df_measeure['time'].dt.month\n",
    "df_measeure['day'] = df_measeure['time'].dt.day\n",
    "df_measeure['h'] = df_measeure['time'].dt.hour\n",
    "df_measeure['m'] = df_measeure['time'].dt.minute\n",
    "df_measeure['s'] = df_measeure['time'].dt.second\n",
    "\n",
    "#print(df_measeure)\n",
    "\n",
    "columns_mean = ['675nm', '500nm', 'LMP', 'err_550', 'err_new', '440nm', 'pw', 'ang_440_870', 'ang_440_675', 'ang_500_870']\n",
    "filter_on_hourly_values= 6\n",
    "\n",
    "hourly_count = df_measeure.groupby(['year', 'month', 'day', 'h']).size().reset_index(name= 'n')\n",
    "filt_h = hourly_count[hourly_count['n'] >= filter_on_hourly_values]\n",
    "\n",
    "filt_df = pd.merge(df_measeure, filt_h, on=['year', 'month', 'day', 'h'], how= 'right')\n",
    "\n",
    "print(hourly_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean at 6 corresponds to the average between 5 and 6. Error calculation and propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOD and ANG error propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of the DataFrames\n",
    "df_lmp_offset = filt_df.copy()\n",
    "df_f_offset = df_farm_f.copy()\n",
    "df_m_offset = df_meteo_f.copy()\n",
    "\n",
    "# dataframe of errors\n",
    "df_obs = pd.DataFrame({\n",
    "    'time': df_lmp_offset['time'],\n",
    "    'LMP': df_lmp_offset['LMP']\n",
    "    })\n",
    "df_error = pd.DataFrame({\n",
    "    'time': df_lmp_offset['time'],\n",
    "    'err_obs': df_lmp_offset['err_550'], # errori propagazione associati alle misure al minuto\n",
    "    'err_new': df_lmp_offset['err_new']\n",
    "    })\n",
    "\n",
    "df_error['time'] += pd.Timedelta(hours= 1)\n",
    "df_obs['time'] += pd.Timedelta(hours= 1)\n",
    "\n",
    "# Offset the 'time' column in df_lmp_offset by 1 hour\n",
    "df_lmp_offset['time'] += pd.Timedelta(hours=1)\n",
    "\n",
    "# Resample df_lmp_offset to hourly means and drop NaN values\n",
    "df_lmp_re = df_lmp_offset.resample('h', on= 'time').mean().dropna()\n",
    "df_err_mean = df_obs.resample('h', on= 'time').mean().dropna()\n",
    "df_err_var = df_obs.resample('h', on= 'time').var().dropna()\n",
    "df_err_std = df_obs.resample('h', on= 'time').std(ddof=1).dropna()\n",
    "\n",
    "df_err_mean_d = df_obs.resample('D', on= 'time').mean().dropna()\n",
    "df_err_var_d = df_obs.resample('D', on= 'time').var().dropna()\n",
    "df_err_std_d = df_obs.resample('D', on= 'time').std(ddof=1).dropna()\n",
    "\n",
    "df_error_count = df_error.groupby(pd.Grouper(key= 'time', freq= 'h')).size().dropna()\n",
    "df_ErrCount = pd.DataFrame({'time': df_error_count.index.to_numpy(), 'n_values': df_error_count})\n",
    "df_ErrCount.reset_index(inplace = True, drop= True)\n",
    "\n",
    "df_err_h_mean = df_error.groupby(pd.Grouper(key= 'time', freq= 'h'))[['err_obs', 'err_new']].apply(\n",
    "    lambda x: pd.Series({\n",
    "        'err_mean': np.mean(x['err_obs']), \n",
    "        'err_mean_new': np.mean(x['err_new'])\n",
    "    })\n",
    "    ).dropna()\n",
    "df_ErrMean = pd.DataFrame({\n",
    "    'time': df_err_h_mean.index.to_numpy(),\n",
    "    'err_mean': df_err_h_mean['err_mean'],\n",
    "    'err_mean_new': df_err_h_mean['err_mean_new']})\n",
    "df_ErrMean.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_error_count_D = df_error.groupby(pd.Grouper(key= 'time', freq= 'D')).size().dropna()\n",
    "df_ErrCountDay = pd.DataFrame({'time': df_error_count_D.index.to_numpy(), 'n_values': df_error_count_D})\n",
    "df_ErrCountDay.reset_index(inplace = True, drop= True)\n",
    "\n",
    "df_err_h_mean_D = df_error.groupby(pd.Grouper(key= 'time', freq= 'D'))[['err_obs', 'err_new']].apply(\n",
    "    lambda x: pd.Series({\n",
    "        'err_mean': np.mean(x['err_obs']**2),#/len(x['err_obs']),\n",
    "        'err_mean_new': np.mean(x['err_new']**2)#/len(x['err_new'])\n",
    "        })\n",
    "        ).dropna()\n",
    "df_ErrMeanDay = pd.DataFrame({\n",
    "    'time': df_err_h_mean_D.index.to_numpy(),\n",
    "    'err_mean': df_err_h_mean_D['err_mean'],\n",
    "    'err_mean_new': df_err_h_mean_D['err_mean_new']})\n",
    "df_ErrMeanDay.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_ErrCount_eq = pd.merge(df_ErrMean, df_ErrCount, on= 'time', how= 'inner')\n",
    "df_ErrStd = pd.DataFrame({\n",
    "    'time': df_ErrCount_eq['time'],\n",
    "    'std': (df_ErrMean['err_mean']/(np.sqrt(df_ErrCount_eq['n_values']))),\n",
    "    'std_new': (df_ErrMean['err_mean_new']/(np.sqrt(df_ErrCount_eq['n_values'])))})\n",
    "df_ErrStd.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_ErrCount_eq_D = pd.merge(df_ErrMeanDay, df_ErrCountDay, on= 'time', how= 'inner')\n",
    "df_ErrStdDay = pd.DataFrame({\n",
    "    'time': df_ErrCount_eq_D['time'],\n",
    "    'std': (df_ErrMeanDay['err_mean']/(np.sqrt(df_ErrCount_eq_D['n_values']))),\n",
    "    'std_new': (df_ErrMeanDay['err_mean_new']/(np.sqrt(df_ErrCount_eq_D['n_values'])))})\n",
    "df_ErrStdDay.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_ErrStd_camp = pd.DataFrame({'time': df_err_std.index.to_numpy(), 'std_camp': df_err_std['LMP']})\n",
    "df_ErrStd_camp.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_ErrStd_camp_D = pd.DataFrame({'time': df_err_std_d.index.to_numpy(), 'std_camp': df_err_std_d['LMP']})\n",
    "df_ErrStd_camp_D.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_ErrSum_h = np.sqrt((df_ErrStd_camp['std_camp']**2) + (df_ErrStd['std']**2))\n",
    "df_ErrSum_24h= np.sqrt((df_ErrStd_camp_D['std_camp']**2) + (df_ErrStdDay['std']**2))\n",
    "df_ErrSum_h_new = np.sqrt((df_ErrStd_camp['std_camp']**2) + (df_ErrStd['std_new']**2))\n",
    "df_ErrSum_24h_new= np.sqrt((df_ErrStd_camp_D['std_camp']**2) + (df_ErrStdDay['std_new']**2))\n",
    "\n",
    "df_ErrSum_H = pd.DataFrame({'time': df_ErrStd['time'], 'err_1h': df_ErrSum_h, 'err_1h_new': df_ErrSum_h_new})\n",
    "df_ErrSum_H.reset_index(inplace= True, drop= True)\n",
    "df_ErrSum_H.dropna(inplace= True)\n",
    "df_ErrSum_24H = pd.DataFrame({'time': df_ErrStdDay['time'], 'err_day': df_ErrSum_24h, 'err_day_new': df_ErrSum_24h_new})\n",
    "df_ErrSum_24H.reset_index(inplace= True, drop= True)\n",
    "\n",
    "# Merge DataFrames on 'time' to create a unified DataFrame with common timestamps\n",
    "df_homo = (df_m_offset.merge(df_f_offset, on= 'time', how='inner').merge(df_lmp_re, on= 'time', how='inner'))\n",
    "\n",
    "def resample_data(df, period):\n",
    "    df_resampled = df.resample(period, on= 'time').mean()\n",
    "    df_resampled.dropna(inplace= True)\n",
    "    df_resampled.reset_index(inplace= True)\n",
    "    return df_resampled\n",
    "\n",
    "# Create a dictionary with resampled data for 1h, 3h, 6h, and 24h intervals\n",
    "data = {\n",
    "    'data1h': pd.merge(resample_data(df_homo, '1h'), df_ErrSum_H, on= 'time', how= 'inner'),\n",
    "    'data3h': resample_data(df_homo, '3h'),\n",
    "    'data6h': resample_data(df_homo, '6h'),\n",
    "    'data24h': pd.merge(resample_data(df_homo, 'D'), df_ErrSum_24H, on= 'time', how= 'inner')\n",
    "}\n",
    "data['data1h'].drop(columns=['n'], inplace= True)\n",
    "data['data3h'].drop(columns=['n'], inplace= True)\n",
    "data['data6h'].drop(columns=['n'], inplace= True)\n",
    "data['data24h'].drop(columns=['n'], inplace= True)\n",
    "\n",
    "print(data['data1h'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering hours per day, taking the maximum in summer and the maximun in winter. Then it is necessary to do a fit and take the 75% or 60% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_count_dump = data['data1h'].copy()\n",
    "#print(day_count_dump.columns)\n",
    "\n",
    "day_count_dump['year_1'] = day_count_dump['time'].dt.year \n",
    "day_count_dump['month_1'] = day_count_dump['time'].dt.month\n",
    "day_count_dump['day_1'] = day_count_dump['time'].dt.day\n",
    "day_count_dump['hour_1'] = day_count_dump['time'].dt.hour\n",
    "\n",
    "# #print(day_count_dump)\n",
    "\n",
    "day_count = day_count_dump.groupby(['year_1', 'month_1', 'day_1']).size().reset_index(name = 'hours_in_day')\n",
    "\n",
    "# X_h = pd.DataFrame()\n",
    "\n",
    "# for i in range(1, 13):\n",
    "#     month_data = day_count[day_count['month_1'] == i].max()\n",
    "#     X_h[f'month_{i}'] = month_data\n",
    "\n",
    "# X_h = X_h.T\n",
    "# X = []\n",
    "# Y = []\n",
    "\n",
    "# for i in range(1, 13): \n",
    "#     X.append(X_h.loc[f'month_{i}', 'month_1'])\n",
    "#     Y.append(X_h.loc[f'month_{i}', 'hours_in_day'])\n",
    "\n",
    "# X = np.array(X).reshape(-1, 1)\n",
    "# Y = np.array(Y).reshape(-1, 1)\n",
    "# print(X)\n",
    "\n",
    "# reg_h = linear_model.LinearRegression(fit_intercept= True).fit(X, Y)\n",
    "# print(f\"Coeff_imp1:{reg_h.coef_}\\nIntercept_imp1:{reg_h.intercept_}\")\n",
    "\n",
    "# Y_pred = reg_h.predict(X)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# for i in range(1, 13):\n",
    "#     plt.scatter(X_h.loc[f'month_{i}', 'month_1'], X_h.loc[f'month_{i}', 'hours_in_day'], label=f'Month {i}')\n",
    "# plt.title('Scatter Plot of Maximum Hours in Each Day per Month')\n",
    "# plt.xlabel('Day of the Month')\n",
    "# plt.ylabel('Hours in Day')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# # Scatter plot dei dati originali\n",
    "# plt.scatter(X, Y, color='blue', label='Data')\n",
    "\n",
    "# # Linea di regressione\n",
    "# plt.plot(X, Y_pred, color='red', label='Regression Line')\n",
    "# plt.title('Plot of Maximum Hours in Each Day per Month')\n",
    "# plt.xlabel('Month of the Year')\n",
    "# plt.ylabel('Maximum Hours in Day')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "# X_poly = poly.fit_transform(X)\n",
    "\n",
    "# # Regressione lineare con caratteristiche polinomiali\n",
    "# reg_h2 = LinearRegression(fit_intercept=True).fit(X_poly, Y)\n",
    "\n",
    "# # Coefficienti e intercetta\n",
    "# print(f\"Coefficients: {reg_h2.coef_}\\nIntercept: {reg_h2.intercept_}\")\n",
    "\n",
    "# # Predire i valori\n",
    "# Y_pred2 = reg_h2.predict(X_poly)\n",
    "\n",
    "# # Creazione del grafico\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# # Scatter plot dei dati originali\n",
    "# plt.scatter(X, Y, color='blue', label='Data')\n",
    "\n",
    "# # Linea di regressione\n",
    "# plt.plot(X, Y_pred2, color='red', label='Second-Order Fit')\n",
    "\n",
    "# # Configurazioni grafiche\n",
    "# # plt.title('Plot of Maximum Hours in Each Day per Month with Second-Order Fit')\n",
    "# # plt.xlabel('Month of the Year')\n",
    "# # plt.ylabel('Maximum Hours in Day')\n",
    "# # plt.legend()\n",
    "# # plt.grid()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daylight during the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMPsite = LocationInfo(name=\"Lampedusa\", region=\"Italy\", latitude=35.52, longitude=12.63)\n",
    "date_range = pd.date_range(start= \"2023-09-01\", end= \"2024-08-31\", freq= 'D')\n",
    "\n",
    "daylight_durations = []\n",
    "\n",
    "# Loop through each date and calculate daylight duration\n",
    "for single_date in date_range:\n",
    "    specific_date = single_date.date()\n",
    "    sun_hours = sun(LMPsite.observer, date = specific_date)\n",
    "    daylight_duration = sun_hours['sunset'] - sun_hours['sunrise']\n",
    "    daylight_durations.append({\n",
    "        \"time\": pd.to_datetime(specific_date),\n",
    "        \"daylight_duration\": int(daylight_duration.total_seconds() // 3600)\n",
    "    })\n",
    "\n",
    "# Convert results to a Pandas DataFrame for easier analysis\n",
    "daylight_df = pd.DataFrame(daylight_durations)\n",
    "\n",
    "# Display the first few rows\n",
    "print(daylight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering hours per day based on the 60% of the daylight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_count_dump_2 = data['data24h'].copy()\n",
    "day_count_dump = data['data1h'].copy()\n",
    "#print(day_count_dump.columns)\n",
    "\n",
    "day_count_dump['year_1'] = day_count_dump['time'].dt.year \n",
    "day_count_dump['month_1'] = day_count_dump['time'].dt.month\n",
    "day_count_dump['day_1'] = day_count_dump['time'].dt.day\n",
    "day_count_dump['hour_1'] = day_count_dump['time'].dt.hour\n",
    "day_count = day_count_dump.groupby(['year_1', 'month_1', 'day_1']).size().reset_index(name = 'hours_in_day')\n",
    "df_filter_on_days = pd.concat([day_count_dump_2, day_count], axis = 1)\n",
    "\n",
    "def filter_day(xMonth):\n",
    "    yDay = (-0.2)*xMonth**2 + 2.3*xMonth + 5.6\n",
    "    soglia = 0.6 * yDay\n",
    "    return soglia\n",
    "\n",
    "df_days_filtered = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 13):\n",
    "    filterData = df_filter_on_days[(df_filter_on_days['time'].dt.month == i) & (df_filter_on_days['hours_in_day'] >= filter_day(i))]\n",
    "    df_days_filtered = pd.concat([df_days_filtered, filterData], ignore_index=True)\n",
    "\n",
    "df_days_filtered.sort_values(by='time', inplace=True)\n",
    "df_days_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#print(df_days_filtered)\n",
    "\n",
    "#### FILTER WITH ASTRAL HOURS\n",
    "\n",
    "df_days_filtered_astral = pd.merge(df_filter_on_days, daylight_df, on= 'time', how= 'left')\n",
    "#print(df_days_filtered_astral.columns)\n",
    "\n",
    "df_daylight_50 = df_days_filtered_astral[df_days_filtered_astral['hours_in_day'] >= 0.5*df_days_filtered_astral['daylight_duration']].reset_index(drop= True)\n",
    "\n",
    "DataDayFiltered = {\n",
    "    'Fit2Ord': df_days_filtered,\n",
    "    'FiltAstral60': df_daylight_50 \n",
    "}\n",
    "\n",
    "print(df_daylight_50.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season: \n",
    "- Winter: December-Jaunary-February (DJF) 12-1-2\n",
    "- Spring: March-April-May (MAM) 3-4-5\n",
    "- Summer: June-July-August (JJA) 6-7-8\n",
    "- Fall: September-October-November (SON) 9-10-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual months\n",
    "december23_1h = data['data1h'][(data['data1h']['time'].dt.year == 2023) & (data['data1h']['time'].dt.month == 12)]\n",
    "november23_1h = data['data1h'][(data['data1h']['time'].dt.year == 2023) & (data['data1h']['time'].dt.month == 11)]\n",
    "october23_1h = data['data1h'][(data['data1h']['time'].dt.year == 2023) & (data['data1h']['time'].dt.month == 10)]\n",
    "september23_1h = data['data1h'][(data['data1h']['time'].dt.year == 2023) & (data['data1h']['time'].dt.month == 9)]\n",
    "january24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 1)]\n",
    "february24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 2)]\n",
    "march24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 3)]\n",
    "april24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 4)]\n",
    "may24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 5)]\n",
    "june24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 6)]\n",
    "july24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 7)]\n",
    "august24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 8)]\n",
    "september24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 9)]\n",
    "october24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 10)]\n",
    "november24_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 11)]\n",
    "december25_1h = data['data1h'][(data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month == 12)]\n",
    "january25_1h = data['data1h'][(data['data1h']['time'].dt.year == 2025) & (data['data1h']['time'].dt.month == 1)]\n",
    "february25_1h = data['data1h'][(data['data1h']['time'].dt.year == 2025) & (data['data1h']['time'].dt.month == 2)]\n",
    "march25_1h = data['data1h'][(data['data1h']['time'].dt.year == 2025) & (data['data1h']['time'].dt.month == 3)]\n",
    "april25_1h = data['data1h'][(data['data1h']['time'].dt.year == 2025) & (data['data1h']['time'].dt.month == 4)]\n",
    "may25_1h = data['data1h'][(data['data1h']['time'].dt.year == 2025) & (data['data1h']['time'].dt.month == 5)]\n",
    "\n",
    "\n",
    "# Seasons\n",
    "fall_1h = data['data1h'][\n",
    "    (data['data1h']['time'].dt.year == 2023) & \n",
    "    (data['data1h']['time'].dt.month >= 9) & \n",
    "    (data['data1h']['time'].dt.month <= 11)\n",
    "]\n",
    "\n",
    "# Correcting the winter season logic to include December 2023 and January/February 2024\n",
    "winter_1h = data['data1h'][\n",
    "    ((data['data1h']['time'].dt.year == 2023) & (data['data1h']['time'].dt.month == 12)) |\n",
    "    ((data['data1h']['time'].dt.year == 2024) & (data['data1h']['time'].dt.month <= 2))\n",
    "]\n",
    "\n",
    "spring_1h = data['data1h'][\n",
    "    (data['data1h']['time'].dt.year == 2024) & \n",
    "    (data['data1h']['time'].dt.month >= 3) & \n",
    "    (data['data1h']['time'].dt.month <= 5)\n",
    "]\n",
    "\n",
    "summer_1h = data['data1h'][\n",
    "    (data['data1h']['time'].dt.year == 2024) & \n",
    "    (data['data1h']['time'].dt.month >= 6) & \n",
    "    (data['data1h']['time'].dt.month <= 8)\n",
    "]\n",
    "\n",
    "print(winter_1h.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Kim's formula for Lampedusa site\n",
    "## First IMPROVE:\n",
    "Rayleigh scattering assumed to be costant ($10 Mm^{-1}$), absorption by gases is considered zero. Concentrations in $[\\mu g\\cdot  m^{-3}]$ and dry mass extinction efficiency are in $(m^{2}\\cdot \\mu g^{-1})$ and $f(RH)$ is **unitless**.\n",
    "$$\n",
    "b_{ext}\\approx 0.003\\times f(RH)[Ammonium Sulfate((NH_{4})_{2}SO_{4})] +\\\\\n",
    "+0.003\\times f(RH)[Ammonium Nitrate(NH_{4}NO_{3})] + 0.004\\times [Organic Mass]\\\\\n",
    "+0.01\\times [Elemental Carbon] + 0.001\\times [Fine Soil]\\\\\n",
    "+0.0006\\times [Coarse Mass] + 0.001 \\times RayleighScattering\n",
    "$$\n",
    "## Second IMPROVE\n",
    "- Sea salt has been added;\n",
    "- Site-specific Rayleigh scattering; \n",
    "- OC ratio from 1.4 to 1.8; \n",
    "- Associated hygroscopies for *small mode, large mode, sea salt*\n",
    "$$\n",
    "b_{ext}\\approx 2.2f_{S}(RH)[Small Ammonium Sulfate] + 4.8f_{L}(RH)[Large Ammonium Sulfate]\\\\\n",
    "+2.4f_{S}(RH)[Small Ammonium Nitrate] + 5.1f_{L}(RH)[Large Ammonium Nitrate]\\\\\n",
    "+2.8[Small Organic Mass] + 6.1[Large Organic Mass]\\\\\n",
    "+10[Elemental Carbon] + 1[Fine Soil] + 1.7f_{SS}(RH)[Sea Salt]\\\\\n",
    "+0.6 × [Coarse Mass] + Rayleigh Scattering(Site Specific) + 0.33[NO2 (ppb)]\n",
    "$$\n",
    "\n",
    "### $f(RH)$:\n",
    "$$\n",
    "\\begin{align}\n",
    "f(RH) = b_{0}+b_{1}\\left(\\frac{1}{1-RH}\\right)+b_{2}\\left(\\frac{1}{1-RH}\\right)^{2}\\\\\n",
    "f(RH) = \\exp{\\left(-1-\\frac{0.6}{RH-1.2}-\\frac{0.75}{RH-1.5}\\right)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "## AODs estimated: \n",
    "\n",
    "$$\n",
    "    AOD = \\sum_{i=1}^{N}\\left(b_{ext}\\right)_{i}\\Delta Z_{i}\n",
    "$$\n",
    "\n",
    "- $N$: number of vertical layers in the numerical model; \n",
    "- $\\Delta Z_{i}$: is the thickness of each layer;\n",
    "  \n",
    "### centro-cella\n",
    "20 65 125 210 325 480 690 975 1360 1880 2580 3525 4805 6290\n",
    "\n",
    "### facce\n",
    "0 40 90 160 260 390 570 810 1140 1580 2180 2980 4070 5540 7040\n",
    "\n",
    "### spessore\n",
    "40 50 70 100 130 180 240 330 440 600 800 1090 1470 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMP1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_RH import f_rh_farm\n",
    "\n",
    "z = df_f_dump['z'][:]\n",
    "dz_C = np.diff(z)\n",
    "dz = [40, 50, 70, 100, 130, 180, 240, 330, 440, 600, 800, 1090, 1470, 1500]\n",
    "N = len(dz)\n",
    "df_dz = pd.DataFrame({'dz': dz})\n",
    "df_rh = pd.DataFrame({'time': dt_m})\n",
    "df_species = pd.DataFrame({'time' : dt_f})\n",
    "df_meteo = pd.DataFrame({'time': dt_m})\n",
    "\n",
    "species = ['c_A25I', 'c_A25J', 'c_ACORS', 'c_AECI', 'c_AECJ', 'c_ANH4I', 'c_ANH4J', 'c_ANO3I', 'c_ANO3J', 'c_AORAI', 'c_AORAJ', 'c_AORBI', 'c_AORBJ', \n",
    "           'c_AORPAI', 'c_AORPAJ', 'c_ASEAS', 'c_ASEASJ', 'c_ASO4I', 'c_ASO4J', 'c_ASOIL', 'c_ASOILJ', 'c_PM10', 'c_PM25', 'c_NO2']\n",
    "\n",
    "species_test = ['c_A25I', 'c_A25J', 'c_ACORS', 'c_AECI', 'c_AECJ', 'c_ANH4I', 'c_ANH4J', 'c_ANO3I', 'c_ANO3J', 'c_AORAI', 'c_AORAJ', 'c_AORBI', 'c_AORBJ', \n",
    "           'c_AORPAI', 'c_AORPAJ', 'c_ASEAS', 'c_ASEASJ', 'c_ASO4I', 'c_ASO4J', 'c_ASOIL', 'c_PM10', 'c_PM25', 'c_NO2']\n",
    "\n",
    "meteos = ['P', 'T']\n",
    "\n",
    "# extracting data all at once\n",
    "rh_data = df_m_dump.variables['RH'][:, :N]/100\n",
    "species_data = {species_name: df_f_dump.variables[species_name][:, :N] for species_name in species}\n",
    "meteo_data = {meteo_var: df_m_dump.variables[meteo_var][:, :N] for meteo_var in meteos}\n",
    "\n",
    "#creating dataframe with time column\n",
    "df_rh = pd.concat([df_rh, pd.DataFrame(rh_data, columns=[f'layer_{i}' for i in range(N)])], axis= 1)\n",
    "\n",
    "for species_name, species_array in species_data.items():\n",
    "    species_columns = {f'layer_{i}_species_{species_name}': species_array[:, i] for i in range(N)}\n",
    "    df_species = pd.concat([df_species, pd.DataFrame(species_columns)], axis= 1)\n",
    "\n",
    "for meteo_var, meteo_array in meteo_data.items():\n",
    "    meteo_colums = {f'layer_{i}_{meteo_var}': meteo_array[:, i] for i in range(N)}\n",
    "    df_meteo = pd.concat([df_meteo, pd.DataFrame(meteo_colums)], axis= 1)\n",
    "\n",
    "#for species_name_test in species_test:\n",
    "#    for i in range(N): \n",
    "#        df_species[f'layer_{i}_species_{species_name_test}'] = 0.0\n",
    "\n",
    "df_FarmRhSpecies_merged = pd.merge(df_species, df_rh, on= 'time', how= 'inner')\n",
    "\n",
    "df_frh_farm = {}\n",
    "\n",
    "# f(RH) function, Kim function is the second one used in Kim's article, the first one will be not used because its divergence for humidity high values\n",
    "for k in range(N):\n",
    "    column= f'layer_{k}'\n",
    "    df_frh_farm[column] = f_rh_farm.g_h_c(df_FarmRhSpecies_merged[f'layer_{k}'])\n",
    "\n",
    "# defining costants for the extinction coeffiencient \n",
    "RayS_1 = 10e-6\n",
    "RayS_2 = 12e-6\n",
    "A = 3e-6\n",
    "B = 4e-6\n",
    "C = 1e-6\n",
    "E = 1e-5\n",
    "C_fit_ODR = 1.3346e-6 \n",
    "D_fit_ODR = 0.801e-6\n",
    "C_fit_NS = 1.3110e-6\n",
    "D_fit_NS = 0.787e-6\n",
    "D = 6e-7\n",
    "\n",
    "aitken = ['c_A25I', 'c_AECI', 'c_ANH4I', 'c_ANO3I', 'c_AORAI', 'c_AORBI', 'c_AORPAI', 'c_ASO4I']\n",
    "accumulation = ['c_A25J', 'c_AECJ', 'c_ANH4J', 'c_ANO3J', 'c_AORAJ', 'c_AORBJ', 'c_AORPAJ', 'c_ASEASJ', 'c_ASO4J', 'c_ASOILJ']\n",
    "coarse = ['c_ACORS', 'c_ASEAS', 'c_ASOIL']\n",
    "\n",
    "df_bext_kim_I = {}\n",
    "df_bext_kim_J = {}\n",
    "df_bext_farm_I = {}\n",
    "df_bext_farm_J = {}\n",
    "df_bext_farm_J_ODR = {}\n",
    "df_bext_farm_J_NS = {}\n",
    "\n",
    "# coarse mode is indipendent from f(RH)\n",
    "df_bext_C = {}\n",
    "df_bext_C_ODR = {}\n",
    "df_bext_C_NS = {}\n",
    " \n",
    "for l in range(N):\n",
    "    column_1= f'layer_{l}'\n",
    "\n",
    "    bext_farm_1I = A * df_frh_farm[f'layer_{l}'] * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4I'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3I'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4I']) +\\\n",
    "                B * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25I'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAI'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAI'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBI']) +\\\n",
    "                C * df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECI']\n",
    "    df_bext_farm_I[column_1] = bext_farm_1I\n",
    "\n",
    "    bext_farm_1J = A * df_frh_farm[f'layer_{l}'] * ( df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3J'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4J']) + B * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAJ'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBJ']) + \\\n",
    "                C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEASJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOILJ'])\n",
    "    df_bext_farm_J[column_1] = bext_farm_1J\n",
    "\n",
    "    bext_farm_1J_ODR = A * df_frh_farm[f'layer_{l}'] * ( df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3J'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4J']) + B * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAJ'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBJ']) + \\\n",
    "                C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEASJ']) +\\\n",
    "                      (C_fit_ODR * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOILJ']))\n",
    "    df_bext_farm_J_ODR[column_1] = bext_farm_1J_ODR\n",
    "\n",
    "    bext_farm_1J_NS = A * df_frh_farm[f'layer_{l}'] * ( df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3J'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4J']) + B * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAJ'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBJ']) + \\\n",
    "                C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEASJ']) +\\\n",
    "                      (C_fit_NS * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOILJ']))\n",
    "    df_bext_farm_J_NS[column_1] = bext_farm_1J_NS\n",
    "\n",
    "    bext_1C = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL'])\n",
    "    df_bext_C[column_1] = bext_1C\n",
    "\n",
    "    bext_1C_ODR = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS']) + D_fit_ODR * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL'])\n",
    "    df_bext_C_ODR[column_1] = bext_1C_ODR\n",
    "\n",
    "    bext_1C_NS = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS']) + D_fit_NS * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL'])\n",
    "    df_bext_C_NS[column_1] = bext_1C_NS\n",
    "\n",
    "#aitken\n",
    "df_bext_farm_I = pd.DataFrame(df_bext_farm_I)\n",
    "df_bext_farm_I = pd.concat([df_FarmRhSpecies_merged['time'], df_bext_farm_I], axis= 1)\n",
    "#accumulation\n",
    "df_bext_farm_J = pd.DataFrame(df_bext_farm_J)\n",
    "df_bext_farm_J = pd.concat([df_FarmRhSpecies_merged['time'], df_bext_farm_J], axis= 1)\n",
    "df_bext_farm_J_ODR = pd.DataFrame(df_bext_farm_J_ODR)\n",
    "df_bext_farm_J_ODR = pd.concat([df_FarmRhSpecies_merged['time'], df_bext_farm_J_ODR], axis= 1)\n",
    "df_bext_farm_J_NS = pd.DataFrame(df_bext_farm_J_NS)\n",
    "df_bext_farm_J_NS = pd.concat([df_FarmRhSpecies_merged['time'], df_bext_farm_J_NS], axis= 1)\n",
    "#coarse\n",
    "df_bext_C = pd.DataFrame(df_bext_C)\n",
    "df_bext_C = pd.concat([df_FarmRhSpecies_merged['time'], df_bext_C], axis= 1)\n",
    "df_bext_C_ODR = pd.DataFrame(df_bext_C_ODR)\n",
    "df_bext_C_ODR = pd.concat([df_FarmRhSpecies_merged['time'], df_bext_C_ODR], axis= 1)\n",
    "df_bext_C_NS = pd.DataFrame(df_bext_C_NS)\n",
    "df_bext_C_NS = pd.concat([df_FarmRhSpecies_merged['time'], df_bext_C_NS], axis= 1)\n",
    "\n",
    "# AOD IMPROVE first formula with Kim-f(RH) and FARM-f(RH)\n",
    "aodimp = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "aodimp['IMP1F'] = 0.0\n",
    "aodimp['IMP1F_ODR'] = 0.0\n",
    "aodimp['IMP1F_NS'] = 0.0\n",
    "\n",
    "# Rayleigh scattering calculated with the formual from HansenAndTravis 1974\n",
    "length = 0.55 # micrometri\n",
    "P_atm = 1013.25\n",
    "c_1 = 0.008569\n",
    "c_2 = 0.0113\n",
    "c_3 = 0.00013\n",
    "tau0 = (c_1*(length)**(-4)*(1+c_2*(length)**(-2)+c_3*(length)**(-4)))*10e-6\n",
    "df_ray = {}\n",
    "raytot = 0.0\n",
    "raytot_1 = 0.0\n",
    "raytot_2 = 0.0\n",
    "\n",
    "for i in range(N):\n",
    "    name = f'lay_{i}'\n",
    "    temp = (tau0*((df_meteo[f'layer_{i}_P'])/P_atm)) \n",
    "    df_ray[name] = temp\n",
    "    tot_2 = df_ray[f'lay_{i}']*dz[i]\n",
    "    raytot += tot_2\n",
    "\n",
    "for i in range(N):\n",
    "    tot = RayS_1 * dz[i]\n",
    "    tot_1 = RayS_2 * dz[i]\n",
    "    raytot_1 += tot\n",
    "    raytot_2 += tot_1\n",
    "    \n",
    "for n in range(N): \n",
    "    aod_farm_1 = (df_bext_farm_I[f'layer_{n}'] + df_bext_farm_J[f'layer_{n}'] + df_bext_C[f'layer_{n}']) * dz[n:n+1]\n",
    "    aod_farm_1_ODR = (df_bext_farm_I[f'layer_{n}'] + df_bext_farm_J_ODR[f'layer_{n}'] + df_bext_C_ODR[f'layer_{n}']) * dz[n:n+1]\n",
    "    aod_farm_1_NS = (df_bext_farm_I[f'layer_{n}'] + df_bext_farm_J_NS[f'layer_{n}'] + df_bext_C_NS[f'layer_{n}']) * dz[n:n+1]\n",
    "    aodimp['IMP1F_ODR'] += aod_farm_1_ODR\n",
    "    aodimp['IMP1F_NS'] += aod_farm_1_NS\n",
    "    aodimp['IMP1F'] += aod_farm_1\n",
    "#print(df_FarmRhSpecies_merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f(RH): FARM based on tabulated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_RH import f_rh_kim_2\n",
    "df_frh = {}\n",
    "\n",
    "for i in range(N):\n",
    "    column3 = f'layer_{i}'\n",
    "    frh = f_rh_kim_2.func2(df_FarmRhSpecies_merged['time'], df_FarmRhSpecies_merged, column3)\n",
    "    df_frh[column3] = frh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Mode and Large Mode: $20\\mu g/cm^{3}$ threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large mode and small mode: IMPROVE 2\n",
    "df_ASO4_large = {}\n",
    "df_ASO4_small = {}\n",
    "\n",
    "df_ANO3_large = {}\n",
    "df_ANO3_small = {}\n",
    "\n",
    "df_OrgMas_large = {}\n",
    "df_OrgMas_small = {}\n",
    "\n",
    "threshold = 20.0\n",
    "\n",
    "for j in range(N):\n",
    "    column_3 = f'layer_{j}'\n",
    "\n",
    "    value_1 = (1.375) * (df_FarmRhSpecies_merged[f'layer_{j}_species_c_ASO4I'] + df_FarmRhSpecies_merged[f'layer_{j}_species_c_ASO4J'])\n",
    "\n",
    "    value_2 = (1.291) * (df_FarmRhSpecies_merged[f'layer_{j}_species_c_ANO3I'] + df_FarmRhSpecies_merged[f'layer_{j}_species_c_ANO3J'])\n",
    "\n",
    "    value_3 = df_FarmRhSpecies_merged[f'layer_{j}_species_c_A25I'] + df_FarmRhSpecies_merged[f'layer_{j}_species_c_A25J'] \\\n",
    "                + df_FarmRhSpecies_merged[f'layer_{j}_species_c_AORAI'] + df_FarmRhSpecies_merged[f'layer_{j}_species_c_AORAJ']\\\n",
    "                + df_FarmRhSpecies_merged[f'layer_{j}_species_c_AORBI'] + df_FarmRhSpecies_merged[f'layer_{j}_species_c_AORBJ']\\\n",
    "                + df_FarmRhSpecies_merged[f'layer_{j}_species_c_AORPAI'] + df_FarmRhSpecies_merged[f'layer_{j}_species_c_AORPAJ']\n",
    "        \n",
    "    df_ASO4_large[column_3]= np.where(value_1 <= threshold, (value_1 / threshold) * value_1, value_1)\n",
    "    df_ASO4_small[column_3] = np.where(value_1 <= threshold, value_1 - (value_1 / threshold) * value_1, 0.0)\n",
    "\n",
    "    df_ANO3_large[column_3] = np.where(value_2 <= threshold, (value_2 / threshold) * value_2, value_2)\n",
    "    df_ANO3_small[column_3] = np.where(value_2 <= threshold, value_2 - (value_2 / threshold) * value_2, 0.0)\n",
    "\n",
    "    df_OrgMas_large[column_3] = np.where(value_3 <= threshold, (value_3 / threshold) * value_3, value_3)\n",
    "    df_OrgMas_small[column_3] = np.where(value_3 <= threshold, value_3 - (value_3 / threshold) * value_3, 0.0)\n",
    "\n",
    "df_ASO4_large = pd.DataFrame(df_ASO4_large)\n",
    "df_ASO4_large = pd.concat([df_FarmRhSpecies_merged['time'], df_ASO4_large], axis= 1)\n",
    "\n",
    "df_ASO4_small = pd.DataFrame(df_ASO4_small)\n",
    "df_ASO4_small = pd.concat([df_FarmRhSpecies_merged['time'], df_ASO4_small], axis= 1)\n",
    "\n",
    "df_ANO3_large = pd.DataFrame(df_ANO3_large)\n",
    "df_ANO3_large = pd.concat([df_FarmRhSpecies_merged['time'], df_ANO3_large], axis= 1)\n",
    "\n",
    "df_ANO3_small = pd.DataFrame(df_ANO3_small)\n",
    "df_ANO3_small = pd.concat([df_FarmRhSpecies_merged['time'], df_ANO3_small], axis= 1)\n",
    "\n",
    "df_OrgMas_large = pd.DataFrame(df_OrgMas_large)\n",
    "df_OrgMas_large = pd.concat([df_FarmRhSpecies_merged['time'], df_OrgMas_large], axis= 1)\n",
    "\n",
    "df_OrgMas_small = pd.DataFrame(df_OrgMas_small)\n",
    "df_OrgMas_small = pd.concat([df_FarmRhSpecies_merged['time'], df_OrgMas_small], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMP2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aodimp['IMP2F'] = 0.0\n",
    "aodimp['IMP2F_ODR'] = 0.0\n",
    "aodimp['IMP2F_NS'] = 0.0\n",
    "\n",
    "#Costants\n",
    "Rayleigh = 0.0729\n",
    "Temp = 298.15\n",
    "R = 8.314\n",
    "NO2 = 4.6\n",
    "A1 = 2.2e-6\n",
    "A2 = 4.8e-6\n",
    "A3 = 2.4e-6\n",
    "A4 = 5.1e-6\n",
    "A5 = 2.8e-6\n",
    "A6 = 6.1e-6\n",
    "B1 = 1.0e-5\n",
    "C1 = 1.0e-6 \n",
    "C1_fit_ODR = 1.3512e-6\n",
    "C3_fit_ODR = 0.811e-6\n",
    "C1_fit_NS = 1.2804e-6\n",
    "C3_fit_NS = 0.768e-6\n",
    "C2 = 1.7e-6\n",
    "C3 = 6.0e-7\n",
    "D1 = 3.3e-7\n",
    "\n",
    "df_bext_imp2 = {}\n",
    "df_bext_imp2_ODR = {}\n",
    "df_bext_imp2_NS = {}\n",
    "\n",
    "for h in range(N): \n",
    "    column_2 = f'layer_{h}'\n",
    "\n",
    "    bext_2 = A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "            A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}']) + \\\n",
    "            A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "            A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}']) + \\\n",
    "            A5 * (df_OrgMas_small[f'layer_{h}']) + \\\n",
    "            A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "            B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) + \\\n",
    "            C1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + \\\n",
    "            C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS']) + \\\n",
    "            C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS'] +\\\n",
    "                    df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "            D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "\n",
    "    df_bext_imp2[column_2] = bext_2\n",
    "    aod2 = (df_bext_imp2[column_2]) * dz[h:h+1]\n",
    "    #aod2 = aod2\n",
    "    aodimp['IMP2F'] += aod2\n",
    "    \n",
    "    bext_2_ODR = A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "            A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}']) + \\\n",
    "            A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "            A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}']) + \\\n",
    "            A5 * (df_OrgMas_small[f'layer_{h}']) + \\\n",
    "            A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "            B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) + \\\n",
    "            C1_fit_ODR * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + \\\n",
    "            C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS']) + \\\n",
    "            C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS']) + \\\n",
    "            C3_fit_ODR * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "            D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "\n",
    "    df_bext_imp2_ODR[column_2] = bext_2_ODR\n",
    "    aod2_ODR = (df_bext_imp2_ODR[column_2]) * dz[h:h+1]\n",
    "    #aod2 = aod2\n",
    "    aodimp['IMP2F_ODR'] += aod2_ODR\n",
    "    \n",
    "    bext_2_NS = A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "            A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}']) + \\\n",
    "            A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "            A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}']) + \\\n",
    "            A5 * (df_OrgMas_small[f'layer_{h}']) + \\\n",
    "            A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "            B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) + \\\n",
    "            C1_fit_NS * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + \\\n",
    "            C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS']) + \\\n",
    "            C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS']) + \\\n",
    "            C3_fit_NS * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "            D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "\n",
    "    df_bext_imp2_NS[column_2] = bext_2_NS\n",
    "    aod2_NS = (df_bext_imp2_NS[column_2]) * dz[h:h+1]\n",
    "    #aod2 = aod2\n",
    "    aodimp['IMP2F_NS'] += aod2_NS\n",
    "\n",
    "df_aodimp = aodimp[(aodimp['time'] >= start_time) & (aodimp['time'] <= end_time)].copy()\n",
    "df_aodimp.reset_index(drop= True, inplace= True)\n",
    "print(df_aodimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IMP = pd.merge(df_homo, df_aodimp, on= 'time', how= 'inner')\n",
    "\n",
    "df_IMP_1h = df_IMP.resample('1h', on= 'time').mean()\n",
    "df_IMP_1h.dropna(inplace= True)\n",
    "df_IMP_1h.reset_index(inplace= True)\n",
    "\n",
    "df_IMP_3h = df_IMP.resample('3h', on= 'time').mean()\n",
    "df_IMP_3h.dropna(inplace= True)\n",
    "df_IMP_3h.reset_index(inplace= True)\n",
    "\n",
    "df_IMP_6h = df_IMP.resample('6h', on= 'time').mean()\n",
    "df_IMP_6h.dropna(inplace= True)\n",
    "df_IMP_6h.reset_index(inplace= True)\n",
    "\n",
    "df_IMP_24h = df_IMP.resample('24h', on= 'time').mean()\n",
    "df_IMP_24h.dropna(inplace= True)\n",
    "df_IMP_24h.reset_index(inplace= True)\n",
    "\n",
    "# dataframe complete with IMPROVE aod\n",
    "data_h = {\n",
    "    'm1': pd.concat([df_IMP_1h, data['data1h']['err_1h']], axis= 1),\n",
    "    'm3': df_IMP_3h,\n",
    "    'm6': df_IMP_6h,\n",
    "    'm24': pd.concat([df_IMP_24h, data['data24h']['err_day_new']], axis= 1)\n",
    "}\n",
    "\n",
    "print(data_h['m24'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error (variability) for daily mean of models (FARM, IMP1F, IMP2F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df_IMP_1h['time']\n",
    "AodFarm = df_IMP_1h['FARM']\n",
    "AodImp1 = df_IMP_1h['IMP1F']\n",
    "AodImp2 = df_IMP_1h['IMP2F']\n",
    "\n",
    "ErrFarm = df_IMP_1h.resample('D', on= 'time').apply(lambda x: np.std(x['AOD']))\n",
    "ErrImp1 = df_IMP_1h.resample('D', on= 'time').apply(lambda x: np.std(x['IMP1F']))\n",
    "ErrImp2 = df_IMP_1h.resample('D', on= 'time').apply(lambda x: np.std(x['IMP2F']))\n",
    "\n",
    "ErrImp1.dropna(inplace= True)\n",
    "ErrImp1.reset_index()\n",
    "ErrImp2.dropna(inplace= True)\n",
    "ErrImp2.reset_index()\n",
    "ErrFarm.dropna(inplace= True)\n",
    "ErrFarm.reset_index()\n",
    "\n",
    "df_ErrImp1_24 = pd.DataFrame({'time': ErrImp1.index.to_numpy(), 'err_IMP1_24': ErrImp1})\n",
    "df_ErrImp2_24 = pd.DataFrame({'time': ErrImp2.index.to_numpy(), 'err_IMP2_24': ErrImp2})\n",
    "df_ErrFarm_24 = pd.DataFrame({'time': ErrFarm.index.to_numpy(), 'errFarm_24': ErrFarm})\n",
    "\n",
    "df_ErrImp1_24.reset_index(inplace= True, drop= True)\n",
    "df_ErrImp2_24.reset_index(inplace= True, drop= True)\n",
    "df_ErrFarm_24.reset_index(inplace= True, drop= True)\n",
    "\n",
    "df_ErrMod = pd.merge(pd.merge(df_ErrFarm_24, df_ErrImp1_24, on = 'time', how= 'inner'), df_ErrImp2_24, on= 'time', how= 'inner')\n",
    "\n",
    "df_to_clean = pd.merge(DataDayFiltered['FiltAstral60'], pd.merge(data_h['m24'], df_ErrMod, on= 'time', how= 'inner'), on= 'time', how= 'inner')\n",
    "\n",
    "columns_to_keep = ['time', 'REL', 'HMIX', 'AOD', 'FARM', '675nm', '500nm',\n",
    "       'LMP', 'err_550', 'ang_440_870',\n",
    "       'ang_440_675', 'hours_in_day',\n",
    "       'daylight_duration', 'IMP1F', 'IMP2F', 'err_FARM_24',\n",
    "       'err_IMP1_24', 'err_IMP2_24', 'err_day_new']\n",
    "\n",
    "df_cleaned = df_to_clean.rename(columns = {\n",
    "    'time': 'time',\n",
    "    'REL_x': 'REL',\n",
    "    'HMIX_x': 'HMIX',\n",
    "    'AOD_x': 'AOD',\n",
    "    'FARM_x': 'FARM',\n",
    "    '675nm_x': '675nm',\n",
    "    '500nm_x': '500nm',\n",
    "    'LMP_x': 'LMP',\n",
    "    'err_550_x': 'err_550',\n",
    "    'ang_440_870_x': 'ang_440_870',\n",
    "    'ang_440_675_x': 'ang_440_675',\n",
    "    'err_day_x': 'err_day',\n",
    "    'hours_in_day_x': 'hours_in_day',\n",
    "    'daylight_duration_x': 'daylight_duration',\n",
    "    'IMP1F_x': 'IMP1F',\n",
    "    'IMP2F_x': 'IMP2F',\n",
    "    'errFarm_24': 'err_FARM_24',\n",
    "    'err_IMP1_24_x': 'err_IMP1_24',\n",
    "    'err_IMP2_24_x': 'err_IMP2_24', \n",
    "    'err_day_new_x': 'err_day_new'\n",
    "}   \n",
    ")\n",
    "\n",
    "df_cleaned = df_cleaned[columns_to_keep]\n",
    "\n",
    "Data = {\n",
    "    '1H': data_h['m1'],\n",
    "    '3H': data_h['m3'],\n",
    "    '6H': data_h['m6'],\n",
    "    '1D': pd.merge(data_h['m24'], df_ErrMod, on= 'time', how= 'inner'),\n",
    "    '1D_f': df_cleaned\n",
    "}\n",
    "\n",
    "#print(Data['1D']['FARM']-Data['1D']['LMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data on ANG and AOD values\n",
    "- Desert Dust (DD): $\\tau\\ge0.15 $ and $\\alpha\\le0.5$; \n",
    "- Biomass burnign urban/industrial (BU): $\\tau\\ge0.1$ and $\\alpha\\ge1.5$;\n",
    "- Mixed aerosol (M): everything outside the previous intervals;\n",
    "  \n",
    "*The filter was applied for hourly averaged values and it is possible having relaxed conditions for daily averaged values but for the first analysis the filter is manteined invariated*\n",
    "\n",
    "### Histograms: \n",
    "Bin width based on: \n",
    "$$\\frac{Max - Min}{\\sqrt{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Season 3H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasons\n",
    "fall_3h = data_h['m3'][\n",
    "    (data_h['m3']['time'].dt.year == 2023) & \n",
    "    (data_h['m3']['time'].dt.month >= 9) & \n",
    "    (data_h['m3']['time'].dt.month <= 11)\n",
    "]\n",
    "\n",
    "winter_3h = data_h['m3'][\n",
    "    (((data_h['m3']['time'].dt.year == 2023) & (data_h['m3']['time'].dt.month == 12))|((data_h['m3']['time'].dt.year == 2024) & (data_h['m3']['time'].dt.month <= 2)))\n",
    "]\n",
    "\n",
    "spring_3h = data_h['m3'][\n",
    "    (data_h['m3']['time'].dt.year == 2024) & \n",
    "    (data_h['m3']['time'].dt.month >= 3) & \n",
    "    (data_h['m3']['time'].dt.month <= 5)\n",
    "]\n",
    "\n",
    "summer_3h = data_h['m3'][\n",
    "    (data_h['m3']['time'].dt.year == 2024) & \n",
    "    (data_h['m3']['time'].dt.month >= 6) & \n",
    "    (data_h['m3']['time'].dt.month <= 8)\n",
    "]\n",
    "\n",
    "#Categories of aerosol\n",
    "# ffd23f\n",
    "DeDu = data_h['m3'][\n",
    "    (data_h['m3']['LMP'] >= 0.15) & \n",
    "    (data_h['m3']['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# 0ead69\n",
    "BioBu = data_h['m3'][\n",
    "    (data_h['m3']['LMP'] >= 0.1) &\n",
    "    (data_h['m3']['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# 540d6e\n",
    "Mix = data_h['m3'][\n",
    "    ~((data_h['m3']['LMP'] >= 0.15) & \n",
    "    (data_h['m3']['ang_440_870'] <= 0.5)) & \n",
    "    ~((data_h['m3']['LMP'] >= 0.1) &\n",
    "    (data_h['m3']['ang_440_870'] >= 1.5))\n",
    "]\n",
    "\n",
    "\n",
    "#Categories of aerosol for 24h\n",
    "# ffd23f\n",
    "DeDu24 = Data['1D'][\n",
    "    (Data['1D']['LMP'] >= 0.15) & \n",
    "    (Data['1D']['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# 0ead69\n",
    "BioBu24 = Data['1D'][\n",
    "    (Data['1D']['LMP'] >= 0.1) &\n",
    "    (Data['1D']['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# 540d6e\n",
    "Mix24 = Data['1D'][\n",
    "    ~((Data['1D']['LMP'] >= 0.15) & \n",
    "    (Data['1D']['ang_440_870'] <= 0.5)) & \n",
    "    ~((Data['1D']['LMP'] >= 0.1) &\n",
    "    (Data['1D']['ang_440_870'] >= 1.5))\n",
    "]\n",
    "\n",
    "# Seasons Desert Dust\n",
    "fall_3h_DD = fall_3h[\n",
    "    (fall_3h['LMP'] >= 0.15) &\n",
    "    (fall_3h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "winter_3h_DD = winter_3h[\n",
    "    (winter_3h['LMP'] >= 0.15) &  \n",
    "    (winter_3h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "spring_3h_DD = spring_3h[\n",
    "    (spring_3h['LMP'] >= 0.15) & \n",
    "    (spring_3h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "summer_3h_DD = summer_3h[\n",
    "    (summer_3h['LMP'] >= 0.15) &  \n",
    "    (summer_3h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# Seasons Biomass Burning\n",
    "fall_3h_BB = fall_3h[\n",
    "    (fall_3h['LMP'] >= 0.1) & \n",
    "    (fall_3h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "winter_3h_BB = winter_3h[\n",
    "    (winter_3h['LMP'] >= 0.1) &  \n",
    "    (winter_3h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "spring_3h_BB = spring_3h[\n",
    "    (spring_3h['LMP'] >= 0.1) &  \n",
    "    (spring_3h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "summer_3h_BB = summer_3h[\n",
    "    (summer_3h['LMP'] >= 0.1) &  \n",
    "    (summer_3h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# Seasons Mix\n",
    "fall_3h_MX = fall_3h[\n",
    "    (fall_3h['ang_440_870'] >= 0.5) & \n",
    "    (fall_3h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "winter_3h_MX = winter_3h[\n",
    "    (winter_3h['ang_440_870'] >= 0.5) & \n",
    "    (winter_3h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "spring_3h_MX = spring_3h[ \n",
    "    (spring_3h['ang_440_870'] >= 0.5) & \n",
    "    (spring_3h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "summer_3h_MX = summer_3h[\n",
    "    (summer_3h['ang_440_870'] >= 0.5) & \n",
    "    (summer_3h['ang_440_870'] <= 1.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month day mean\n",
    "\n",
    "december23D= Data['1D'][(Data['1D']['time'].dt.year == 2023) & (Data['1D']['time'].dt.month == 12)]\n",
    "november23D = Data['1D'][(Data['1D']['time'].dt.year == 2023) & (Data['1D']['time'].dt.month == 11)]\n",
    "october23D = Data['1D'][(Data['1D']['time'].dt.year == 2023) & (Data['1D']['time'].dt.month == 10)]\n",
    "september23D = Data['1D'][(Data['1D']['time'].dt.year == 2023) & (Data['1D']['time'].dt.month == 9)]\n",
    "january24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 1)]\n",
    "february24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 2)]\n",
    "march24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 3)]\n",
    "april24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 4)]\n",
    "may24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 5)]\n",
    "june24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 6)]\n",
    "july24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 7)]\n",
    "august24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 8)]\n",
    "september24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 9)]\n",
    "october24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 10)]\n",
    "november24D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 11)]\n",
    "december25D = Data['1D'][(Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month == 12)]\n",
    "january25D = Data['1D'][(Data['1D']['time'].dt.year == 2025) & (Data['1D']['time'].dt.month == 1)]\n",
    "february25D = Data['1D'][(Data['1D']['time'].dt.year == 2025) & (Data['1D']['time'].dt.month == 2)]\n",
    "march25D = Data['1D'][(Data['1D']['time'].dt.year == 2025) & (Data['1D']['time'].dt.month == 3)]\n",
    "april25D = Data['1D'][(Data['1D']['time'].dt.year == 2025) & (Data['1D']['time'].dt.month == 4)]\n",
    "may25D = Data['1D'][(Data['1D']['time'].dt.year == 2025) & (Data['1D']['time'].dt.month == 5)]\n",
    "\n",
    "# Month filter, Month day mean\n",
    "\n",
    "december23D_f= Data['1D_f'][(Data['1D_f']['time'].dt.year == 2023) & (Data['1D_f']['time'].dt.month == 12)]\n",
    "november23D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2023) & (Data['1D_f']['time'].dt.month == 11)]\n",
    "october23D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2023) & (Data['1D_f']['time'].dt.month == 10)]\n",
    "september23D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2023) & (Data['1D_f']['time'].dt.month == 9)]\n",
    "january24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 1)]\n",
    "february24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 2)]\n",
    "march24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 3)]\n",
    "april24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 4)]\n",
    "may24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 5)]\n",
    "june24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 6)]\n",
    "july24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 7)]\n",
    "august24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 8)]\n",
    "september24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 9)]\n",
    "october24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 10)]\n",
    "november24D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 11)]\n",
    "december25D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month == 12)]\n",
    "january25D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2025) & (Data['1D_f']['time'].dt.month == 1)]\n",
    "february25D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2025) & (Data['1D_f']['time'].dt.month == 2)]\n",
    "march25D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2025) & (Data['1D_f']['time'].dt.month == 3)]\n",
    "april25D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2025) & (Data['1D_f']['time'].dt.month == 4)]\n",
    "may25D_f = Data['1D_f'][(Data['1D_f']['time'].dt.year == 2025) & (Data['1D_f']['time'].dt.month == 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Season 24H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasons\n",
    "fall_24h = Data['1D'][\n",
    "    (Data['1D']['time'].dt.year == 2023) & \n",
    "    (Data['1D']['time'].dt.month >= 9) & \n",
    "    (Data['1D']['time'].dt.month <= 11)\n",
    "]\n",
    "\n",
    "winter_24h = Data['1D'][\n",
    "    (((Data['1D']['time'].dt.year == 2023) & (Data['1D']['time'].dt.month == 12)) | ((Data['1D']['time'].dt.year == 2024) & (Data['1D']['time'].dt.month <= 2)))\n",
    "]\n",
    "\n",
    "spring_24h = Data['1D'][\n",
    "    (Data['1D']['time'].dt.year == 2024) & \n",
    "    (Data['1D']['time'].dt.month >= 3) & \n",
    "    (Data['1D']['time'].dt.month <= 5)\n",
    "]\n",
    "\n",
    "summer_24h = Data['1D'][\n",
    "    (Data['1D']['time'].dt.year == 2024) & \n",
    "    (Data['1D']['time'].dt.month >= 6) & \n",
    "    (Data['1D']['time'].dt.month <= 8)\n",
    "]\n",
    "\n",
    "#Categories of aerosol\n",
    "# ffd23f\n",
    "DeDu24 = Data['1D'][\n",
    "    (Data['1D']['LMP'] >= 0.15) & \n",
    "    (Data['1D']['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# 0ead69\n",
    "BioBu24 = Data['1D'][\n",
    "    (Data['1D']['LMP'] >= 0.1) &\n",
    "    (Data['1D']['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# 540d6e\n",
    "Mix24 = Data['1D'][\n",
    "    ~((Data['1D']['LMP'] >= 0.15) & \n",
    "    (Data['1D']['ang_440_870'] <= 0.5)) & \n",
    "    ~((Data['1D']['LMP'] >= 0.1) &\n",
    "    (Data['1D']['ang_440_870'] >= 1.5))\n",
    "]\n",
    "\n",
    "#Categories of aerosol 2025\n",
    "DeDu25 = Data['1D'][\n",
    "    (Data['1D']['LMP'] >= 0.15) & \n",
    "    (Data['1D']['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# 0ead69\n",
    "BioBu25 = Data['1D'][\n",
    "    (Data['1D']['LMP'] >= 0.1) &\n",
    "    (Data['1D']['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# 540d6e\n",
    "Mix25 = Data['1D'][\n",
    "    ~((Data['1D']['LMP'] >= 0.15) & \n",
    "    (Data['1D']['ang_440_870'] <= 0.5)) & \n",
    "    ~((Data['1D']['LMP'] >= 0.1) &\n",
    "    (Data['1D']['ang_440_870'] >= 1.5))\n",
    "]\n",
    "\n",
    "# Seasons Desert Dust\n",
    "fall_24h_DD = fall_24h[\n",
    "    (fall_24h['LMP'] >= 0.15) &\n",
    "    (fall_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "winter_24h_DD = winter_24h[\n",
    "    (winter_24h['LMP'] >= 0.15) &  \n",
    "    (winter_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "spring_24h_DD = spring_24h[\n",
    "    (spring_24h['LMP'] >= 0.15) & \n",
    "    (spring_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "summer_24h_DD = summer_24h[\n",
    "    (summer_24h['LMP'] >= 0.15) &  \n",
    "    (summer_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# Seasons Biomass Burning\n",
    "fall_24h_BB = fall_24h[\n",
    "    (fall_24h['LMP'] >= 0.1) & \n",
    "    (fall_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "winter_24h_BB = winter_24h[\n",
    "    (winter_24h['LMP'] >= 0.1) &  \n",
    "    (winter_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "spring_24h_BB = spring_24h[\n",
    "    (spring_24h['LMP'] >= 0.1) &  \n",
    "    (spring_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "summer_24h_BB = summer_24h[\n",
    "    (summer_24h['LMP'] >= 0.1) &  \n",
    "    (summer_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# Seasons Mix\n",
    "fall_24h_MX = fall_24h[\n",
    "    (fall_24h['ang_440_870'] >= 0.5) & \n",
    "    (fall_24h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "winter_24h_MX = winter_24h[\n",
    "    (winter_24h['ang_440_870'] >= 0.5) & \n",
    "    (winter_24h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "spring_24h_MX = spring_24h[ \n",
    "    (spring_24h['ang_440_870'] >= 0.5) & \n",
    "    (spring_24h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "summer_24h_MX = summer_24h[\n",
    "    (summer_24h['ang_440_870'] >= 0.5) & \n",
    "    (summer_24h['ang_440_870'] <= 1.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Season 24h filtered on daylight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasons\n",
    "fall_24h_f = Data['1D_f'][\n",
    "    (Data['1D_f']['time'].dt.year == 2023) & \n",
    "    (Data['1D_f']['time'].dt.month >= 9) & \n",
    "    (Data['1D_f']['time'].dt.month <= 11)\n",
    "]\n",
    "\n",
    "winter_24h_f = Data['1D_f'][\n",
    "    (((Data['1D_f']['time'].dt.year == 2023) & (Data['1D_f']['time'].dt.month == 12)) | ((Data['1D_f']['time'].dt.year == 2024) & (Data['1D_f']['time'].dt.month <= 2)))\n",
    "]\n",
    "\n",
    "spring_24h_f = Data['1D_f'][\n",
    "    (Data['1D_f']['time'].dt.year == 2024) & \n",
    "    (Data['1D_f']['time'].dt.month >= 3) & \n",
    "    (Data['1D_f']['time'].dt.month <= 5)\n",
    "]\n",
    "\n",
    "summer_24h_f = Data['1D_f'][\n",
    "    (Data['1D_f']['time'].dt.year == 2024) & \n",
    "    (Data['1D_f']['time'].dt.month >= 6) & \n",
    "    (Data['1D_f']['time'].dt.month <= 8)\n",
    "]\n",
    "\n",
    "#Categories of aerosol\n",
    "# ffd23f\n",
    "DeDu24_f = Data['1D_f'][\n",
    "    (Data['1D_f']['LMP'] >= 0.15) & \n",
    "    (Data['1D_f']['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# 0ead69\n",
    "BioBu24_f = Data['1D_f'][\n",
    "    (Data['1D_f']['LMP'] >= 0.1) &\n",
    "    (Data['1D_f']['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# 540d6e\n",
    "Mix25_f = Data['1D_f'][\n",
    "    ~((Data['1D_f']['LMP'] >= 0.15) & \n",
    "    (Data['1D_f']['ang_440_870'] <= 0.5)) & \n",
    "    ~((Data['1D_f']['LMP'] >= 0.1) &\n",
    "    (Data['1D_f']['ang_440_870'] >= 1.5))\n",
    "]\n",
    "\n",
    "DeDu25_f = Data['1D_f'][\n",
    "    (Data['1D_f']['LMP'] >= 0.15) & \n",
    "    (Data['1D_f']['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# 0ead69\n",
    "BioBu25_f = Data['1D_f'][\n",
    "    (Data['1D_f']['LMP'] >= 0.1) &\n",
    "    (Data['1D_f']['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# 540d6e\n",
    "Mix24_f = Data['1D_f'][\n",
    "    ~((Data['1D_f']['LMP'] >= 0.15) & \n",
    "    (Data['1D_f']['ang_440_870'] <= 0.5)) & \n",
    "    ~((Data['1D_f']['LMP'] >= 0.1) &\n",
    "    (Data['1D_f']['ang_440_870'] >= 1.5))\n",
    "]\n",
    "\n",
    "# Seasons Desert Dust\n",
    "fall_24h_DD_f = fall_24h[\n",
    "    (fall_24h['LMP'] >= 0.15) &\n",
    "    (fall_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "winter_24h_DD_f = winter_24h[\n",
    "    (winter_24h['LMP'] >= 0.15) &  \n",
    "    (winter_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "spring_24h_DD_f = spring_24h[\n",
    "    (spring_24h['LMP'] >= 0.15) & \n",
    "    (spring_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "summer_24h_DD_f = summer_24h[\n",
    "    (summer_24h['LMP'] >= 0.15) &  \n",
    "    (summer_24h['ang_440_870'] <= 0.5)\n",
    "]\n",
    "\n",
    "# Seasons Biomass Burning\n",
    "fall_24h_BB_f = fall_24h[\n",
    "    (fall_24h['LMP'] >= 0.1) & \n",
    "    (fall_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "winter_24h_BB_f = winter_24h[\n",
    "    (winter_24h['LMP'] >= 0.1) &  \n",
    "    (winter_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "spring_24h_BB_f = spring_24h[\n",
    "    (spring_24h['LMP'] >= 0.1) &  \n",
    "    (spring_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "summer_24h_BB_f = summer_24h[\n",
    "    (summer_24h['LMP'] >= 0.1) &  \n",
    "    (summer_24h['ang_440_870'] >= 1.5)\n",
    "]\n",
    "\n",
    "# Seasons Mix\n",
    "fall_24h_MX_f = fall_24h[\n",
    "    (fall_24h['ang_440_870'] >= 0.5) & \n",
    "    (fall_24h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "winter_24h_MX_f = winter_24h[\n",
    "    (winter_24h['ang_440_870'] >= 0.5) & \n",
    "    (winter_24h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "spring_24h_MX_f = spring_24h[ \n",
    "    (spring_24h['ang_440_870'] >= 0.5) & \n",
    "    (spring_24h['ang_440_870'] <= 1.5)\n",
    "]\n",
    "\n",
    "summer_24h_MX_f = summer_24h[\n",
    "    (summer_24h['ang_440_870'] >= 0.5) & \n",
    "    (summer_24h['ang_440_870'] <= 1.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of DD filter on daily averages using concentrations of FARM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "## Statistical indexes:\n",
    "### Mean: \n",
    "$$\\mu = \\frac{1}{N}\\sum_{i=1}^{N}x_{i}$$\n",
    "### Variance: \n",
    "$$Var(x) = \\frac{1}{N-1}\\sum_{i}^{N}(x_{i}-\\mu)^{2}$$ \n",
    "(*Unbiased variance sample*)\n",
    "### Standard deviation:\n",
    "$$\\sigma_{N} = \\sqrt{\\frac{1}{N-1}\\sum_{i}^{N}(x_{i}-\\mu)^{2}} = \\sqrt{Var(x)}$$\n",
    "### Bias: \n",
    "$$\\frac{1}{N}\\sum_{i=1}^{N}\\left(x_{observed, i}-x_{model, i}\\right)$$\n",
    "### Pearson correlation: \n",
    "$$r_{xy} = \\frac{x_{i}y_{i}-N\\bar{x}\\bar{y}}{\\sqrt{Nx^{2}_{i}-(x_{i})^{2}}\\sqrt{Ny^{2}_{i}-(y_{i})^{2}}}$$\n",
    "### MSE:\n",
    "$$MSE = \\frac{1}{N}\\sum_{i}^{N}(x_{obs,i}-x_{pred, i})^{2}$$\n",
    "### RMSE:\n",
    "$$RMSE = \\sqrt{MSE}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs = Data['1D']['LMP'].to_numpy()\n",
    "data_farm = Data['1D']['FARM'].to_numpy()\n",
    "data_imp1f = Data['1D']['IMP1F'].to_numpy()\n",
    "data_imp2f = Data['1D']['IMP2F'].to_numpy()\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Calculate Bias\n",
    "    bias = np.mean(y_true - y_pred)\n",
    "\n",
    "    # Calculate Correlation\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "    # Calculate NMSE\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    var_y = np.var(y_true)\n",
    "    #nmse = mse / var_y if var_y != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "    # Calculate Variance\n",
    "    variance = var_y\n",
    "    return bias, corr, rmse, variance, mse\n",
    "\n",
    "# Calculate metrics for each comparison\n",
    "metrics_farm = calculate_metrics(data_obs, data_farm)\n",
    "metrics_imp1f = calculate_metrics(data_obs, data_imp1f)\n",
    "metrics_imp2f = calculate_metrics(data_obs, data_imp2f)\n",
    "\n",
    "# Print the results\n",
    "print(\"Metrics for AOD (FARM):\")\n",
    "print(f'Bias: {metrics_farm[0]}, Correlation: {metrics_farm[1]}, RMSE: {metrics_farm[2]}, Variance: {metrics_farm[3]}, N: {len(data_obs)}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP1F):\")\n",
    "print(f'Bias: {metrics_imp1f[0]}, Correlation: {metrics_imp1f[1]}, RMSE: {metrics_imp1f[2]}, Variance: {metrics_imp1f[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP2F):\")\n",
    "print(f'Bias: {metrics_imp2f[0]}, Correlation: {metrics_imp2f[1]}, RMSE: {metrics_imp2f[2]}, Variance: {metrics_imp2f[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display, Math\n",
    "\n",
    "# Load data\n",
    "data_obs = Data['1D']['LMP'].to_numpy()\n",
    "data_farm = Data['1D']['FARM'].to_numpy()\n",
    "data_imp1f = Data['1D']['IMP1F'].to_numpy()\n",
    "data_imp2f = Data['1D']['IMP2F'].to_numpy()\n",
    "\n",
    "# Number of observations and parameters\n",
    "n = len(data_obs)  # Number of data points (49)\n",
    "p = 2  # Number of parameters (slope + intercept)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, n, p):\n",
    "    # Calculate Bias\n",
    "    bias = np.mean(y_true - y_pred)\n",
    "\n",
    "    # Calculate Correlation\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "    # Calculate NMSE\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    var_y = np.var(y_true)\n",
    "\n",
    "    # Calculate R² (coefficient of determination)\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)  # Residual sum of squares\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)  # Total sum of squares\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "    # Calculate Adjusted R²\n",
    "    adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1)) if (n - p - 1) != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "    return bias, corr, rmse, var_y, mse, r2, adj_r2\n",
    "\n",
    "# Calculate metrics for each comparison\n",
    "metrics_farm = calculate_metrics(data_obs, data_farm, n, p)\n",
    "metrics_imp1f = calculate_metrics(data_obs, data_imp1f, n, p)\n",
    "metrics_imp2f = calculate_metrics(data_obs, data_imp2f, n, p)\n",
    "\n",
    "# Print the results\n",
    "print(\"Metrics for AOD (FARM):\")\n",
    "#display(Math(rf'Bias: {metrics_farm[0]:.4f}, Correlation: {metrics_farm[1]:.4f}, RMSE: {metrics_farm[2]:.4f}, Variance: {metrics_farm[3]:.4f}, R^{{2}} = {metrics_farm[5]:.4f}, \\text{{Adjusted }} R^{{2}} = {metrics_farm[6]:.4f}, N = {n}'))\n",
    "print(rf'Bias: {metrics_farm[0]:.4f}, Correlation: {metrics_farm[1]:.4f}, RMSE: {metrics_farm[2]:.4f}, Variance: {metrics_farm[3]:.4f}, R2 {metrics_farm[5]:.4f}, Adjusted R2: {metrics_farm[6]:.4f}, N: {n}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP1F):\")\n",
    "print(rf'Bias: {metrics_imp1f[0]:.4f}, Correlation: {metrics_imp1f[1]:.4f}, RMSE: {metrics_imp1f[2]:.4f}, Variance: {metrics_imp1f[3]:.4f}, R2: {metrics_imp1f[5]:.4f}, Adjusted R2: {metrics_imp1f[6]:.4f}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP2F):\")\n",
    "print(rf'Bias: {metrics_imp2f[0]:.4f}, Correlation: {metrics_imp2f[1]:.4f}, RMSE: {metrics_imp2f[2]:.4f}, Variance: {metrics_imp2f[3]:.4f}, R2: {metrics_imp2f[5]:.4f}, Adjusted R2: {metrics_imp2f[6]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics for each sub-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_DD = DeDu25['LMP'].to_numpy()\n",
    "# obs_BB = BioBu25['LMP'].to_numpy()\n",
    "# obs_MX = Mix25['LMP'].to_numpy()\n",
    "# farm_DD = DeDu25['FARM'].to_numpy()\n",
    "# farm_BB = BioBu25['FARM'].to_numpy()\n",
    "# farm_MX = Mix25['FARM'].to_numpy()\n",
    "# imp1_DD = DeDu25['IMP1F'].to_numpy()\n",
    "# imp1_BB = BioBu25['IMP1F'].to_numpy()\n",
    "# imp1_MX = Mix25['IMP1F'].to_numpy()\n",
    "# imp2_DD = DeDu25['IMP2F'].to_numpy()\n",
    "# imp2_BB = BioBu25['IMP2F'].to_numpy()\n",
    "# imp2_MX = Mix25['IMP2F'].to_numpy()\n",
    "\n",
    "# imp1_odr_DD = DeDu25['IMP1F_ODR'].to_numpy()\n",
    "# imp1_odr_BB = BioBu25['IMP1F_ODR'].to_numpy()\n",
    "# imp1_odr_MX = Mix25['IMP1F_ODR'].to_numpy()\n",
    "# imp2_odr_DD = DeDu25['IMP2F_ODR'].to_numpy()\n",
    "# imp2_odr_BB = BioBu25['IMP2F_ODR'].to_numpy()\n",
    "# imp2_odr_MX = Mix25['IMP2F_ODR'].to_numpy()\n",
    "\n",
    "# imp1_odr_DD = DeDu25['IMP1F_ODR'].to_numpy()\n",
    "# imp1_odr_BB = BioBu25['IMP1F_ODR'].to_numpy()\n",
    "# imp1_odr_MX = Mix25['IMP1F_ODR'].to_numpy()\n",
    "# imp2_odr_DD = DeDu25['IMP2F_ODR'].to_numpy()\n",
    "# imp2_odr_BB = BioBu25['IMP2F_ODR'].to_numpy()\n",
    "# imp2_odr_MX = Mix25['IMP2F_ODR'].to_numpy()\n",
    "\n",
    "\n",
    "# # Function to calculate metrics\n",
    "# def calculate_metrics(y_true, y_pred):\n",
    "#     # Calculate Bias\n",
    "#     bias = np.mean(y_true - y_pred)\n",
    "\n",
    "#     # Calculate Correlation\n",
    "#     corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "#     # Calculate RMSE\n",
    "#     rmse = np.sqrt((np.mean((y_true - y_pred) ** 2 )))\n",
    "    \n",
    "#     # Calculate NMSE\n",
    "#     mse = np.mean((y_true - y_pred) ** 2)\n",
    "#     var_y = np.var(y_true)\n",
    "#     #nmse = mse / var_y if var_y != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "#     # Coefficient of Determination (R²)\n",
    "#     ss_total = np.sum((y_true - np.mean(y_true)) ** 2)  # Total Sum of Squares\n",
    "#     ss_residual = np.sum((y_true - y_pred) ** 2)  # Residual Sum of Squares\n",
    "#     r_squared = 1 - (ss_residual / ss_total) if ss_total != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "#     # Calculate Variance\n",
    "#     variance = var_y\n",
    "#     return bias, corr, rmse, variance, mse, r_squared\n",
    "\n",
    "# # Calculate metrics for each comparison\n",
    "# metrics_farm_DD = calculate_metrics(obs_DD, farm_DD)\n",
    "# metrics_imp1f_DD = calculate_metrics(obs_DD, imp1_DD)\n",
    "# metrics_imp2f_DD = calculate_metrics(obs_DD, imp2_DD)\n",
    "# metrics_farm_BB = calculate_metrics(obs_BB, farm_BB)\n",
    "# metrics_imp1f_BB = calculate_metrics(obs_BB, imp1_BB)\n",
    "# metrics_imp2f_BB = calculate_metrics(obs_BB, imp2_BB)\n",
    "# metrics_farm_MX = calculate_metrics(obs_MX, farm_MX)\n",
    "# metrics_imp1f_MX = calculate_metrics(obs_MX, imp1_MX)\n",
    "# metrics_imp2f_MX = calculate_metrics(obs_MX, imp2_MX)\n",
    "\n",
    "# metrics_imp1f_odr_BB = calculate_metrics(obs_BB, imp1_odr_BB)\n",
    "# metrics_imp2f_odr_BB = calculate_metrics(obs_BB, imp2_odr_BB)\n",
    "# metrics_imp1f_odr_DD = calculate_metrics(obs_DD, imp1_odr_DD)\n",
    "# metrics_imp2f_odr_DD = calculate_metrics(obs_DD, imp2_odr_DD)\n",
    "# metrics_imp1f_odr_MX = calculate_metrics(obs_MX, imp1_odr_MX)\n",
    "# metrics_imp2f_odr_MX = calculate_metrics(obs_MX, imp2_odr_MX)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Metrics for AOD (FARM-DD):\")\n",
    "# print(f'Bias: {metrics_farm_DD[0]}, Correlation: {metrics_farm_DD[1]}, RMSE: {metrics_farm_DD[2]}, Variance: {metrics_farm_DD[3]}, n_DD: {len(obs_DD)}')\n",
    "# print(\"Metrics for AOD (FARM-BU):\")\n",
    "# print(f'Bias: {metrics_farm_BB[0]}, Correlation: {metrics_farm_BB[1]}, RMSE: {metrics_farm_BB[2]}, Variance: {metrics_farm_BB[3]}, n_BB: {len(obs_BB)}')\n",
    "# print(\"Metrics for AOD (FARM-M):\")\n",
    "# print(f'Bias: {metrics_farm_MX[0]}, Correlation: {metrics_farm_MX[1]}, RMSE: {metrics_farm_MX[2]}, Variance: {metrics_farm_MX[3]}, n_MX: {len(obs_MX)}')\n",
    "\n",
    "# print(\"\\nMetrics for AOD (IMP1F-DD):\")\n",
    "# print(f'Bias: {metrics_imp1f_DD[0]}, Correlation: {metrics_imp1f_DD[1]}, RMSE: {metrics_imp1f_DD[2]}, Variance: {metrics_imp1f_DD[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP1F-BU):\")\n",
    "# print(f'Bias: {metrics_imp1f_BB[0]}, Correlation: {metrics_imp1f_BB[1]}, RMSE: {metrics_imp1f_BB[2]}, Variance: {metrics_imp1f_BB[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP1F-M):\")\n",
    "# print(f'Bias: {metrics_imp1f_MX[0]}, Correlation: {metrics_imp1f_MX[1]}, RMSE: {metrics_imp1f_MX[2]}, Variance: {metrics_imp1f_MX[3]}')\n",
    "\n",
    "# print(\"\\nMetrics for AOD (IMP1F_ODR-DD):\")\n",
    "# print(f'Bias: {metrics_imp1f_odr_DD[0]}, Correlation: {metrics_imp1f_odr_DD[1]}, RMSE: {metrics_imp1f_odr_DD[2]}, Variance: {metrics_imp1f_odr_DD[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP1F_ODR-BB):\")\n",
    "# print(f'Bias: {metrics_imp1f_odr_BB[0]}, Correlation: {metrics_imp1f_odr_BB[1]}, RMSE: {metrics_imp1f_odr_BB[2]}, Variance: {metrics_imp1f_odr_BB[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP1F_ODR-MX):\")\n",
    "# print(f'Bias: {metrics_imp1f_odr_MX[0]}, Correlation: {metrics_imp1f_odr_MX[1]}, RMSE: {metrics_imp1f_odr_MX[2]}, Variance: {metrics_imp1f_odr_MX[3]}')\n",
    "\n",
    "# print(\"\\nMetrics for AOD (IMP2F-DD):\")\n",
    "# print(f'Bias: {metrics_imp2f_DD[0]}, Correlation: {metrics_imp2f_DD[1]}, RMSE: {metrics_imp2f_DD[2]}, Variance: {metrics_imp2f_DD[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP2F-BB):\")\n",
    "# print(f'Bias: {metrics_imp2f_BB[0]}, Correlation: {metrics_imp2f_BB[1]}, RMSE: {metrics_imp2f_BB[2]}, Variance: {metrics_imp2f_BB[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP2F-MX):\")\n",
    "# print(f'Bias: {metrics_imp2f_MX[0]}, Correlation: {metrics_imp2f_MX[1]}, RMSE: {metrics_imp2f_MX[2]}, Variance: {metrics_imp2f_MX[3]}')\n",
    "\n",
    "# print(\"\\nMetrics for AOD (IMP2F_ODR-DD):\")\n",
    "# print(f'Bias: {metrics_imp2f_odr_DD[0]}, Correlation: {metrics_imp2f_odr_DD[1]}, RMSE: {metrics_imp2f_odr_DD[2]}, Variance: {metrics_imp2f_odr_DD[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP2F_ODR-BB):\")\n",
    "# print(f'Bias: {metrics_imp2f_odr_BB[0]}, Correlation: {metrics_imp2f_odr_BB[1]}, RMSE: {metrics_imp2f_odr_BB[2]}, Variance: {metrics_imp2f_odr_BB[3]}')\n",
    "# print(\"\\nMetrics for AOD (IMP2F_ODR-MX):\")\n",
    "# print(f'Bias: {metrics_imp2f_odr_MX[0]}, Correlation: {metrics_imp2f_odr_MX[1]}, RMSE: {metrics_imp2f_odr_MX[2]}, Variance: {metrics_imp2f_odr_MX[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Function to calculate metrics\n",
    "# def calculate_metrics(y_true, y_pred, n, p):\n",
    "#     # Calculate Bias\n",
    "#     bias = np.mean(y_true - y_pred)\n",
    "\n",
    "#     # Calculate Correlation\n",
    "#     corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "#     # Calculate RMSE\n",
    "#     rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "#     # Calculate Variance\n",
    "#     variance = np.var(y_true)\n",
    "\n",
    "#     # Calculate R² (Coefficient of Determination)\n",
    "#     ss_total = np.sum((y_true - np.mean(y_true)) ** 2)  # Total Sum of Squares (TSS)\n",
    "#     ss_residual = np.sum((y_true - y_pred) ** 2)  # Residual Sum of Squares (RSS)\n",
    "#     r2 = 1 - (ss_residual / ss_total) if ss_total != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "#     # Calculate Adjusted R²\n",
    "#     adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1)) if n > p + 1 else np.nan  # Avoid invalid adjustment\n",
    "\n",
    "#     return bias, corr, rmse, variance, r2, adjusted_r2\n",
    "\n",
    "# # Define number of observations (n) and number of parameters (p)\n",
    "# n_DD, n_BB, n_MX = len(obs_DD), len(obs_BB), len(obs_MX)\n",
    "# p = 2  # Two parameters in the regression model\n",
    "\n",
    "# # Calculate metrics for each comparison\n",
    "# metrics = {\n",
    "#     \"FARM-DD\": calculate_metrics(obs_DD, farm_DD, n_DD, p),\n",
    "#     \"FARM-BB\": calculate_metrics(obs_BB, farm_BB, n_BB, p),\n",
    "#     \"FARM-MX\": calculate_metrics(obs_MX, farm_MX, n_MX, p),\n",
    "#     \"IMP1F-DD\": calculate_metrics(obs_DD, imp1_DD, n_DD, p),\n",
    "#     \"IMP1F-BB\": calculate_metrics(obs_BB, imp1_BB, n_BB, p),\n",
    "#     \"IMP1F-MX\": calculate_metrics(obs_MX, imp1_MX, n_MX, p),\n",
    "#     \"IMP2F-DD\": calculate_metrics(obs_DD, imp2_DD, n_DD, p),\n",
    "#     }\n",
    "\n",
    "# # Print results\n",
    "# for name, vals in metrics.items():\n",
    "#     print(f\"\\nMetrics for AOD ({name}):\")\n",
    "#     print(f'Bias: {vals[0]:.4f}, Correlation: {vals[1]:.4f}, RMSE: {vals[2]:.4f}, Variance: {vals[3]:.4f}, '\n",
    "#           f'R²: {vals[4]:.4f}, Adjusted R²: {vals[5]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics for each sub-group divdidend into seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fall_obs_DD = fall_24h_DD['LMP']\n",
    "# fall_obs_BB = fall_24h_BB['LMP']\n",
    "# fall_obs_MX = fall_24h_MX['LMP']\n",
    "# fall_farm_DD = fall_24h_DD['FARM']\n",
    "# fall_farm_BB = fall_24h_BB['FARM']\n",
    "# fall_farm_MX = fall_24h_MX['FARM']\n",
    "# fall_imp1_DD = fall_24h_DD['IMP1F']\n",
    "# fall_imp1_BB = fall_24h_BB['IMP1F']\n",
    "# fall_imp1_MX = fall_24h_MX['IMP1F']\n",
    "# fall_imp2_DD = fall_24h_DD['IMP2F']\n",
    "# fall_imp2_BB = fall_24h_BB['IMP2F']\n",
    "# fall_imp2_MX = fall_24h_MX['IMP2F']\n",
    "\n",
    "# winter_obs_DD = winter_24h_DD['LMP']\n",
    "# winter_obs_BB = winter_24h_BB['LMP']\n",
    "# winter_obs_MX = winter_24h_MX['LMP']\n",
    "# winter_farm_DD = winter_24h_DD['FARM']\n",
    "# winter_farm_BB = winter_24h_BB['FARM']\n",
    "# winter_farm_MX = winter_24h_MX['FARM']\n",
    "# winter_imp1_DD = winter_24h_DD['IMP1F']\n",
    "# winter_imp1_BB = winter_24h_BB['IMP1F']\n",
    "# winter_imp1_MX = winter_24h_MX['IMP1F']\n",
    "# winter_imp2_DD = winter_24h_DD['IMP2F']\n",
    "# winter_imp2_BB = winter_24h_BB['IMP2F']\n",
    "# winter_imp2_MX = winter_24h_MX['IMP2F']\n",
    "\n",
    "# spring_obs_DD = spring_24h_DD['LMP']\n",
    "# spring_obs_BB = spring_24h_BB['LMP']\n",
    "# spring_obs_MX = spring_24h_MX['LMP']\n",
    "# spring_farm_DD = spring_24h_DD['FARM']\n",
    "# spring_farm_BB = spring_24h_BB['FARM']\n",
    "# spring_farm_MX = spring_24h_MX['FARM']\n",
    "# spring_imp1_DD = spring_24h_DD['IMP1F']\n",
    "# spring_imp1_BB = spring_24h_BB['IMP1F']\n",
    "# spring_imp1_MX = spring_24h_MX['IMP1F']\n",
    "# spring_imp2_DD = spring_24h_DD['IMP2F']\n",
    "# spring_imp2_BB = spring_24h_BB['IMP2F']\n",
    "# spring_imp2_MX = spring_24h_MX['IMP2F']\n",
    "\n",
    "# summer_obs_DD = summer_24h_DD['LMP']\n",
    "# summer_obs_BB = summer_24h_BB['LMP']\n",
    "# summer_obs_MX = summer_24h_MX['LMP']\n",
    "# summer_farm_DD = summer_24h_DD['FARM']\n",
    "# summer_farm_BB = summer_24h_BB['FARM']\n",
    "# summer_farm_MX = summer_24h_MX['FARM']\n",
    "# summer_imp1_DD = summer_24h_DD['IMP1F']\n",
    "# summer_imp1_BB = summer_24h_BB['IMP1F']\n",
    "# summer_imp1_MX = summer_24h_MX['IMP1F']\n",
    "# summer_imp2_DD = summer_24h_DD['IMP2F']\n",
    "# summer_imp2_BB = summer_24h_BB['IMP2F']\n",
    "# summer_imp2_MX = summer_24h_MX['IMP2F']\n",
    "\n",
    "# # Statistics\n",
    "# def calculate_metrics(y_true, y_pred):\n",
    "#     if len(y_true) < 2 or len(y_pred) < 2:\n",
    "#         return np.nan, np.nan, np.nan, np.nan\n",
    "#     else: \n",
    "#     # Calculate Bias\n",
    "#         bias = np.mean(y_true - y_pred)\n",
    "\n",
    "#     # Calculate Correlation\n",
    "#         corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "#     # Calculate RMSE\n",
    "#         rmse = np.sqrt((np.mean((y_true - y_pred) ** 2 )))\n",
    "    \n",
    "#     # Calculate NMSE\n",
    "#         #mse = np.mean((y_true - y_pred) ** 2)\n",
    "#         var_y = np.var(y_true)\n",
    "#         #nmse = mse / var_y if var_y != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "#     # Calculate Variance\n",
    "#         variance = var_y\n",
    "#     return bias, corr, rmse, variance\n",
    "\n",
    "# metrics_data_DD = []\n",
    "# metrics_data_BB = []\n",
    "# metrics_data_MX = []\n",
    "\n",
    "# seasons = [\"Fall\", \"Winter\", \"Spring\", \"Summer\"]\n",
    "# models = [\"Farm\", \"Imp1\", \"Imp2\"]\n",
    "\n",
    "# datasets_DD = {\n",
    "#     \"Fall\": (fall_obs_DD, fall_farm_DD, fall_imp1_DD, fall_imp2_DD),\n",
    "#     \"Winter\": (winter_obs_DD, winter_farm_DD, winter_imp1_DD, winter_imp2_DD),\n",
    "#     \"Spring\": (spring_obs_DD, spring_farm_DD, spring_imp1_DD, spring_imp2_DD),\n",
    "#     \"Summer\": (summer_obs_DD, summer_farm_DD, summer_imp1_DD, summer_imp2_DD)\n",
    "# }\n",
    "# datasets_BB = {\n",
    "#     \"Fall\": (fall_obs_BB, fall_farm_BB, fall_imp1_BB, fall_imp2_BB),\n",
    "#     \"Winter\": (winter_obs_BB, winter_farm_BB, winter_imp1_BB, winter_imp2_BB),\n",
    "#     \"Spring\": (spring_obs_BB, spring_farm_BB, spring_imp1_BB, spring_imp2_BB),\n",
    "#     \"Summer\": (summer_obs_BB, summer_farm_BB, summer_imp1_BB, summer_imp2_BB)\n",
    "# }\n",
    "# datasets_MX = {\n",
    "#     \"Fall\": (fall_obs_MX, fall_farm_MX, fall_imp1_MX, fall_imp2_MX),\n",
    "#     \"Winter\": (winter_obs_MX, winter_farm_MX, winter_imp1_MX, winter_imp2_MX),\n",
    "#     \"Spring\": (spring_obs_MX, spring_farm_MX, spring_imp1_MX, spring_imp2_MX),\n",
    "#     \"Summer\": (summer_obs_MX, summer_farm_MX, summer_imp1_MX, summer_imp2_MX)\n",
    "# }\n",
    "\n",
    "# for season, _data in datasets_DD.items():\n",
    "#     obs, *models_data = _data\n",
    "#     for model_name, model_data in zip(models, models_data):\n",
    "#         bias, corr, rmse, variance = calculate_metrics(obs, model_data)\n",
    "#         metrics_data_DD.append([season, model_name, bias, corr, rmse, variance, len(obs)])\n",
    "\n",
    "# for season, _data in datasets_BB.items():\n",
    "#     obs, *models_data = _data\n",
    "#     for model_name, model_data in zip(models, models_data):\n",
    "#         bias, corr, rmse, variance = calculate_metrics(obs, model_data)\n",
    "#         metrics_data_BB.append([season, model_name, bias, corr, rmse, variance, len(obs)])\n",
    "\n",
    "# for season, _data in datasets_MX.items():\n",
    "#     obs, *models_data = _data\n",
    "#     for model_name, model_data in zip(models, models_data):\n",
    "#         bias, corr, rmse, variance = calculate_metrics(obs, model_data)\n",
    "#         metrics_data_MX.append([season, model_name, bias, corr, rmse, variance, len(obs)])\n",
    "\n",
    "# # Creazione del DataFrame\n",
    "# metrics_df_DD = pd.DataFrame(\n",
    "#     metrics_data_DD,\n",
    "#     columns=[\"Season\", \"Model\", \"Bias\", \"Correlation\", \"RMSE\", \"Variance\", \"N\"]\n",
    "# )\n",
    "# metrics_df_BB = pd.DataFrame(\n",
    "#     metrics_data_BB,\n",
    "#     columns=[\"Season\", \"Model\", \"Bias\", \"Correlation\", \"RMSE\", \"Variance\", \"N\"]\n",
    "# )\n",
    "# metrics_df_MX = pd.DataFrame(\n",
    "#     metrics_data_MX,\n",
    "#     columns=[\"Season\", \"Model\", \"Bias\", \"Correlation\", \"RMSE\", \"Variance\", \"N\"]\n",
    "# )\n",
    "\n",
    "# # Visualizzazione\n",
    "# print(metrics_df_MX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# # Function to calculate performance metrics\n",
    "# def calculate_metrics(y_true, y_pred):\n",
    "#     if len(y_true) < 2 or len(y_pred) < 2:\n",
    "#         return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "#     else:\n",
    "#         # Calculate Bias\n",
    "#         bias = np.mean(y_true - y_pred)\n",
    "    \n",
    "#         # Calculate Correlation\n",
    "#         corr, _ = pearsonr(y_true, y_pred)\n",
    "    \n",
    "#         # Calculate RMSE\n",
    "#         rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    \n",
    "#         # Calculate Variance\n",
    "#         variance = np.var(y_true)\n",
    "    \n",
    "#         # Calculate R² (coefficient of determination)\n",
    "#         ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "#         ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "#         r2 = 1 - (ss_residual / ss_total) if ss_total != 0 else 0\n",
    "    \n",
    "#         # Calculate Adjusted R²\n",
    "#         n = len(y_true)\n",
    "#         p = 1  # One predictor (model estimate)\n",
    "#         r2_adj = 1 - (1 - r2) * ((n - 1) / (n - p - 1)) if n > p + 1 else 0\n",
    "    \n",
    "#         return bias, corr, rmse, variance, r2, r2_adj\n",
    "\n",
    "# # Initialize data storage\n",
    "# metrics_data_DD = []\n",
    "# metrics_data_BB = []\n",
    "# metrics_data_MX = []\n",
    "\n",
    "# seasons = [\"Fall\", \"Winter\", \"Spring\", \"Summer\"]\n",
    "# models = [\"Farm\", \"Imp1\", \"Imp2\"]\n",
    "\n",
    "# datasets_DD = {\n",
    "#     \"Fall\": (fall_obs_DD, fall_farm_DD, fall_imp1_DD, fall_imp2_DD),\n",
    "#     \"Winter\": (winter_obs_DD, winter_farm_DD, winter_imp1_DD, winter_imp2_DD),\n",
    "#     \"Spring\": (spring_obs_DD, spring_farm_DD, spring_imp1_DD, spring_imp2_DD),\n",
    "#     \"Summer\": (summer_obs_DD, summer_farm_DD, summer_imp1_DD, summer_imp2_DD)\n",
    "# }\n",
    "# datasets_BB = {\n",
    "#     \"Fall\": (fall_obs_BB, fall_farm_BB, fall_imp1_BB, fall_imp2_BB),\n",
    "#     \"Winter\": (winter_obs_BB, winter_farm_BB, winter_imp1_BB, winter_imp2_BB),\n",
    "#     \"Spring\": (spring_obs_BB, spring_farm_BB, spring_imp1_BB, spring_imp2_BB),\n",
    "#     \"Summer\": (summer_obs_BB, summer_farm_BB, summer_imp1_BB, summer_imp2_BB)\n",
    "# }\n",
    "# datasets_MX = {\n",
    "#     \"Fall\": (fall_obs_MX, fall_farm_MX, fall_imp1_MX, fall_imp2_MX),\n",
    "#     \"Winter\": (winter_obs_MX, winter_farm_MX, winter_imp1_MX, winter_imp2_MX),\n",
    "#     \"Spring\": (spring_obs_MX, spring_farm_MX, spring_imp1_MX, spring_imp2_MX),\n",
    "#     \"Summer\": (summer_obs_MX, summer_farm_MX, summer_imp1_MX, summer_imp2_MX)\n",
    "# }\n",
    "\n",
    "# # Compute metrics for each dataset\n",
    "# for season, _data in datasets_DD.items():\n",
    "#     obs, *models_data = _data\n",
    "#     for model_name, model_data in zip(models, models_data):\n",
    "#         bias, corr, rmse, variance, r2, r2_adj = calculate_metrics(obs, model_data)\n",
    "#         metrics_data_DD.append([season, model_name, bias, corr, rmse, variance, r2, r2_adj, len(obs)])\n",
    "\n",
    "# for season, _data in datasets_BB.items():\n",
    "#     obs, *models_data = _data\n",
    "#     for model_name, model_data in zip(models, models_data):\n",
    "#         bias, corr, rmse, variance, r2, r2_adj = calculate_metrics(obs, model_data)\n",
    "#         metrics_data_BB.append([season, model_name, bias, corr, rmse, variance, r2, r2_adj, len(obs)])\n",
    "\n",
    "# for season, _data in datasets_MX.items():\n",
    "#     obs, *models_data = _data\n",
    "#     for model_name, model_data in zip(models, models_data):\n",
    "#         bias, corr, rmse, variance, r2, r2_adj = calculate_metrics(obs, model_data)\n",
    "#         metrics_data_MX.append([season, model_name, bias, corr, rmse, variance, r2, r2_adj, len(obs)])\n",
    "\n",
    "# # Create DataFrames\n",
    "# metrics_df_DD = pd.DataFrame(\n",
    "#     metrics_data_DD,\n",
    "#     columns=[\"Season\", \"Model\", \"Bias\", \"Correlation\", \"RMSE\", \"Variance\", \"R²\", \"Adjusted R²\", \"N\"]\n",
    "# )\n",
    "# metrics_df_BB = pd.DataFrame(\n",
    "#     metrics_data_BB,\n",
    "#     columns=[\"Season\", \"Model\", \"Bias\", \"Correlation\", \"RMSE\", \"Variance\", \"R²\", \"Adjusted R²\", \"N\"]\n",
    "# )\n",
    "# metrics_df_MX = pd.DataFrame(\n",
    "#     metrics_data_MX,\n",
    "#     columns=[\"Season\", \"Model\", \"Bias\", \"Correlation\", \"RMSE\", \"Variance\", \"R²\", \"Adjusted R²\", \"N\"]\n",
    "# )\n",
    "\n",
    "# # Display the results\n",
    "# print(metrics_df_MX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of events based on mean and std of each sub-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # statistics for DD, BU, M\n",
    "# DD_mean_obs = np.mean(DeDu24['550nm'])\n",
    "# DD_std_obs = np.std(DeDu24['550nm'])\n",
    "# BU_mean_obs = np.mean(BioBu24['550nm'])\n",
    "# BU_std_obs = np.std(BioBu24['550nm'])\n",
    "# M_mean_obs = np.mean(Mix24['550nm'])\n",
    "# M_std_obs = np.std(Mix24['550nm'])\n",
    "\n",
    "# MeanObs = np.mean(Data['1D']['550nm'])\n",
    "# StdObs = np.std(Data['1D']['550nm'])\n",
    "\n",
    "# print(f'DD mean: {DD_mean_obs:.2f}', f'DD std: {DD_std_obs:.2f}', f'Media totale: {MeanObs:.2f}', f'Std totale: {StdObs:.2f}')\n",
    "# # Whole dataset\n",
    "# DD_events = Data['1D'][abs(Data['1D']['550nm']-MeanObs) >= 1.2*StdObs]\n",
    "# BU_events = Data['1D'][abs(Data['1D']['550nm']-BU_mean_obs) >= 1*BU_std_obs]\n",
    "# M_events = Data['1D'][abs(Data['1D']['550nm']-M_mean_obs) >= 1*M_std_obs]\n",
    "\n",
    "# # Sub-sets\n",
    "# DD_events_sub = DeDu24[abs(DeDu24['550nm']-MeanObs) > 1*StdObs]\n",
    "# BU_events_sub = BioBu24[abs(BioBu24['550nm']-BU_mean_obs) >= 1*BU_std_obs]\n",
    "# M_events_sub = Mix24[abs(Mix24['550nm']-M_mean_obs) >= 1*M_std_obs]\n",
    "\n",
    "# DD_date = DD_events['time'].dt.date\n",
    "# BU_date = BU_events['time'].dt.date\n",
    "# M_date = BU_events['time'].dt.date\n",
    "\n",
    "# DD_date_s = DD_events_sub['time'].dt.date\n",
    "# BU_date_s = BU_events_sub['time'].dt.date\n",
    "# M_date_s = BU_events_sub['time'].dt.date\n",
    "\n",
    "# df_DD_days = pd.DataFrame({'time': DD_events['time'], 'DD_Y': DD_events['time'].dt.year, 'DD_M': DD_events['time'].dt.month, \n",
    "#                            'DD_D': DD_events['time'].dt.day, 'diff_day': DD_date.diff()})\n",
    "# EventsDD = df_DD_days[(df_DD_days['diff_day'] <= pd.Timedelta(days= 2))]\n",
    "# DD_events.reset_index(inplace= True)\n",
    "# EventsDD.reset_index(inplace= True)\n",
    "# df_Events_DD = pd.merge(EventsDD, DD_events, on= 'time', how= 'inner')\n",
    "\n",
    "# df_BU_days = pd.DataFrame({'time': BU_events['time'], 'BU_Y': BU_events['time'].dt.year, 'BU_M': BU_events['time'].dt.month, \n",
    "#                            'BU_D': BU_events['time'].dt.day, 'diff_day': BU_date.diff()})\n",
    "# EventsBU = df_BU_days[(df_BU_days['diff_day'] <= pd.Timedelta(days= 2))]\n",
    "# BU_events.reset_index(inplace= True)\n",
    "# EventsBU.reset_index(inplace= True)\n",
    "# df_Events_BU = pd.merge(EventsBU, BU_events, on= 'time', how= 'inner')\n",
    "\n",
    "# df_M_days = pd.DataFrame({'time': M_events['time'], 'M_Y': M_events['time'].dt.year, 'M_M': M_events['time'].dt.month, \n",
    "#                            'M_D': M_events['time'].dt.day, 'diff_day': M_date.diff()})\n",
    "# EventsM = df_M_days[(df_M_days['diff_day'] <= pd.Timedelta(days= 2))]\n",
    "# M_events.reset_index(inplace= True)\n",
    "# EventsM.reset_index(inplace= True)\n",
    "# df_Events_M = pd.merge(EventsM, M_events, on= 'time', how= 'inner')\n",
    "\n",
    "# ###################################################################################\n",
    "\n",
    "# # subsets\n",
    "# df_DD_days_s = pd.DataFrame({'time': DD_events_sub['time'], 'DD_Y': DD_events_sub['time'].dt.year, 'DD_M': DD_events_sub['time'].dt.month, \n",
    "#                            'DD_D': DD_events_sub['time'].dt.day, 'diff_day': DD_date_s.diff()})\n",
    "# #EventsDD_mask = df_DD_days_s[df_DD_days_s['time'] == ]\n",
    "# EventsDD_sub = df_DD_days_s[(df_DD_days_s['diff_day'] >= pd.Timedelta(days= 2))]\n",
    "# DD_events_sub.reset_index(inplace= True)\n",
    "# EventsDD_sub.reset_index(inplace= True)\n",
    "# df_Events_DD_s = pd.merge(EventsDD_sub, DD_events_sub, on= 'time', how= 'inner')\n",
    "\n",
    "# df_BU_days_s = pd.DataFrame({'time': BU_events_sub['time'], 'BU_Y': BU_events_sub['time'].dt.year, 'BU_M': BU_events_sub['time'].dt.month, \n",
    "#                            'BU_D': BU_events_sub['time'].dt.day, 'diff_day': BU_date_s.diff()})\n",
    "# EventsBU_sub = df_BU_days_s[(df_BU_days_s['diff_day'] >= pd.Timedelta(days= 2))]\n",
    "# BU_events_sub.reset_index(inplace= True)\n",
    "# EventsBU_sub.reset_index(inplace= True)\n",
    "# df_Events_BU_s = pd.merge(EventsBU_sub, BU_events_sub, on= 'time', how= 'inner')\n",
    "\n",
    "# df_M_days_s = pd.DataFrame({'time': M_events['time'], 'M_Y': M_events['time'].dt.year, 'M_M': M_events['time'].dt.month, \n",
    "#                            'M_D': M_events['time'].dt.day, 'diff_day': M_date.diff()})\n",
    "# EventsM_sub = df_M_days_s[(df_M_days_s['diff_day'] >= pd.Timedelta(days= 2))]\n",
    "# M_events_sub.reset_index(inplace= True)\n",
    "# EventsM.reset_index(inplace= True)\n",
    "# df_Events_M_s = pd.merge(EventsM_sub, M_events_sub, on= 'time', how= 'inner')\n",
    "# print(df_Events_DD['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data by species and by layers\n",
    "### Species: \n",
    "\n",
    "- ASO4\n",
    "- ANO3\n",
    "- ASEAS\n",
    "- DUST = ASOIL + ASOILJ\n",
    "- OTHER\n",
    "### Layers:\n",
    "\n",
    "- (20-65)m layer 0 45m\n",
    "- (65-125)m layer 1 60m\n",
    "- (125-210)m layer 2 85m\n",
    "- (210-325)m layer 3 115m\n",
    "- (325-480)m layer 4 155m\n",
    "- (480-690)m layer 5 210m\n",
    "- (690-975)m layer 6 285m\n",
    "- (975-1360)m layer 7 385m\n",
    "- (1360-1880)m layer 8 520m\n",
    "- (1880-2580)m layer 9 700m\n",
    "- (2580-3525)m layer 10 945m\n",
    "- (3525-4805)m layer 11 1280m \n",
    "- (4805-6290)m layer 12 1485m\n",
    "### FARM layers:\n",
    "\n",
    "- z : [  20.   65.  125.  210.  325.  480.  690.  975. 1360. 1880. 2580. 3525. 4805. 6290. ]\n",
    "- dz : [  45.   60.   85.  115.  155.  210.  285.  385.  520.  700.  945. 1280. 1485.]\n",
    "\n",
    "### Layers defined by us \n",
    "- (0-390)m thickness 390m\n",
    "- (390-1140)m thickness 750m\n",
    "- (1140-2980)m thickness 1840m\n",
    "- (2980-7040)m thickness 4060m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMP1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aod_species_imp1 = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "df_aod_species_imp1['ASO4']= 0.0 \n",
    "df_aod_species_imp1['ANO3']= 0.0\n",
    "df_aod_species_imp1['ASOIL']= 0.0\n",
    "df_aod_species_imp1['ASEAS']= 0.0\n",
    "df_aod_species_imp1['OTHER']= 0.0\n",
    "df_aod_species_imp1['AEC']= 0.0\n",
    "df_aod_species_imp1['COARSE']= 0.0\n",
    "df_aod_species_imp1['ASOIL_C']= 0.0\n",
    "df_aod_species_imp1['ASEAS_C']= 0.0\n",
    "df_aod_species_imp1['ACORS_C']= 0.0\n",
    "\n",
    "N = 14\n",
    "species_list = ['ASO4', 'ANO3', 'ASEAS', 'ASOIL', 'OTHER', 'AEC', 'COARSE', 'ASOIL_C', 'ASEAS_C', 'ACORS_C']\n",
    "new_layer = [390, 750, 1840, 4060]\n",
    "\n",
    "# defining a dataframe of extinction coefficients for both species and layers \n",
    "df_BEXT_spec_imp1  = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "df_BEXT_spec_new_imp1  = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "\n",
    "new_columns = {}\n",
    "\n",
    "for i in species_list: \n",
    "      for j in range(N):\n",
    "            new_columns[f's_{i}_l_{j}'] = 0.0\n",
    "      \n",
    "df_new = pd.DataFrame(new_columns, index=df_BEXT_spec_imp1.index)\n",
    "df_BEXT_spec_imp1 = pd.concat([df_BEXT_spec_imp1, df_new], axis=1)\n",
    "\n",
    "new_columns_1 = {}\n",
    "\n",
    "for i in species_list: \n",
    "      for idx, number in enumerate(new_layer) :\n",
    "            new_columns_1[f's_{i}_l_{idx}'] = 0.0\n",
    "            \n",
    "df_new_1 = pd.DataFrame(new_columns_1, index=df_BEXT_spec_new_imp1.index)\n",
    "df_BEXT_spec_new_imp1 = pd.concat([df_BEXT_spec_new_imp1, df_new_1], axis=1)\n",
    "\n",
    "# defining a datafame of AOD divided into layers\n",
    "df_aod_layer_imp1 = {}\n",
    "df_aod_layer_imp1 = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "df_aod_layer_new_imp1 = {}\n",
    "df_aod_layer_new_imp1 = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "\n",
    "dz= [40, 50, 70, 100, 130, 180, 240, 330, 440, 600, 800, 1090, 1470, 1500]\n",
    "\n",
    "for l in range(N):\n",
    "\n",
    "    bext_1_ASO4 =   A * df_frh_farm[f'layer_{l}'] * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4J'] + \\\n",
    "                                                      df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4I'])\n",
    "    #df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4I'] + \\\n",
    "                                                     #df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4J'] + \\\n",
    "                                                     \n",
    "    \n",
    "    bext_1_ANO3 =   A * df_frh_farm[f'layer_{l}'] * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3I'] + \\\n",
    "                                                     df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3J'])\n",
    "    \n",
    "    bext_1_ASOIL = C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOILJ']) + \\\n",
    "                  D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL'])   \n",
    "\n",
    "    bext_1_ASEAS = C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEASJ']) + \\\n",
    "                  D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS'])\n",
    "    \n",
    "    bext_1_OTHER = B * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25I'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAI'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAI'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBI'] + \\\n",
    "                  df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAJ'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBJ']) + \\\n",
    "                D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS'])\n",
    "\n",
    "    bext_1_AEC = C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECI'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECJ'])\n",
    "\n",
    "    bext_COARSE = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS']) +\\\n",
    "      D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL']) + \\\n",
    "      D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS'])\n",
    "    \n",
    "    b_asoil_C = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL'])\n",
    "    b_aseas_C = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS'])\n",
    "    b_acors_C = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS'])\n",
    "    \n",
    "    for i in species_list:\n",
    "            if i == 'ASO4':\n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = bext_1_ASO4\n",
    "            elif i == 'ANO3':\n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = bext_1_ANO3\n",
    "            elif i == 'ASOIL': \n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = bext_1_ASOIL\n",
    "            elif i == 'ASEAS': \n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = bext_1_ASEAS\n",
    "            elif i == 'OTHER':\n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = bext_1_OTHER\n",
    "            elif i == 'AEC':\n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = bext_1_AEC\n",
    "            elif i == 'COARSE':\n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = bext_COARSE\n",
    "            elif i == 'ASOIL_C': \n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = b_asoil_C\n",
    "            elif i == 'ASEAS_C': \n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = b_aseas_C\n",
    "            elif i == 'ACORS_C': \n",
    "                  df_BEXT_spec_imp1[f's_{i}_l_{l}'] = b_acors_C\n",
    "    \n",
    "\n",
    "    aod_ASO4 = bext_1_ASO4 * dz[l:l+1]\n",
    "    aod_ANO3 = bext_1_ANO3 * dz[l:l+1]\n",
    "    aod_ASOIL = bext_1_ASOIL * dz[l:l+1]\n",
    "    aod_ASEAS = bext_1_ASEAS * dz[l:l+1]\n",
    "    aod_OTHER = bext_1_OTHER * dz[l:l+1]\n",
    "    aod_AEC = bext_1_AEC * dz[l:l+1]\n",
    "    aod_COARSE = bext_COARSE * dz[l:l+1]\n",
    "    aod_ASOIL_C = b_asoil_C * dz[l:l+1]\n",
    "    aod_ASEAS_C = b_aseas_C * dz[l:l+1]\n",
    "    aod_ACORS_C = b_acors_C * dz[l:l+1]\n",
    "\n",
    "    df_aod_species_imp1['ASO4'] += aod_ASO4\n",
    "    df_aod_species_imp1['ANO3'] += aod_ANO3\n",
    "    df_aod_species_imp1['ASOIL'] += aod_ASOIL\n",
    "    df_aod_species_imp1['ASEAS'] += aod_ASEAS\n",
    "    df_aod_species_imp1['OTHER'] += aod_OTHER\n",
    "    df_aod_species_imp1['AEC'] += aod_AEC\n",
    "    df_aod_species_imp1['COARSE'] += aod_COARSE\n",
    "    df_aod_species_imp1['ASOIL_C'] += aod_ASOIL_C\n",
    "    df_aod_species_imp1['ASEAS_C'] += aod_ASEAS_C\n",
    "    df_aod_species_imp1['ACORS_C'] += aod_ACORS_C\n",
    "\n",
    "df_aod_species_imp1_dump = df_aod_species_imp1[(df_aod_species_imp1['time'] >= start_time) & (df_aod_species_imp1['time'] <= end_time)]\n",
    "df_aod_species_imp1_dump.reset_index(drop= True, inplace= True)\n",
    "df_aod_species_imp1_merged = pd.merge(data_h['m1'], df_aod_species_imp1_dump, on= 'time', how= 'inner')\n",
    "df_aod_species_imp1_merged.dropna(inplace= True)\n",
    "df_aod_species_imp1_merged.reset_index(drop= True, inplace= True)\n",
    "\n",
    "Layer = {}\n",
    "\n",
    "for i, j in enumerate(dz):\n",
    "      n = f'layer_{i}'\n",
    "      temp = j\n",
    "      Layer[n] = temp\n",
    "#df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4I']df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4J']\n",
    "def compute_aod_layer(layer, l):\n",
    "      aodlayer = 0.0            \n",
    "      bext_layer = A * df_frh_farm[f'layer_{l}'] * ( + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3I'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4I'] + \\\n",
    "                                                       + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3J'] + \\\n",
    "                                                            df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4J']) + \\\n",
    "                                                                  B * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25I'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAI'] + \\\n",
    "                                                                       df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAI'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBI'] + \\\n",
    "                                                                        df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAJ'] + \\\n",
    "                                                                              df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBJ']) +\\\n",
    "                                                                                    C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECI'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECJ'] + \\\n",
    "                                                                                         df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEASJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOILJ']) + \\\n",
    "                                                                                          D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS'] + \\\n",
    "                                                                                               df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL'])\n",
    "      aodlayer = bext_layer * layer\n",
    "      return aodlayer\n",
    "\n",
    "df_FarmRhSpecies_merged_imp1_layer = {}\n",
    "layer_columns = [f'{species}_layer_{layer}' for species in species_list for layer in range(N)]\n",
    "df_prova = pd.DataFrame(columns= layer_columns)\n",
    "df_prova = pd.DataFrame(0.0, index= range(len(df_FarmRhSpecies_merged['time'])), columns=layer_columns)\n",
    "df_prove = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "df_FarmRhSpecies_merged_imp1_layer = pd.concat([df_prove, df_prova], axis=1)\n",
    "\n",
    "def compute_aod_layer_species(layer, l, species):\n",
    "      temp = 0.0\n",
    "      bext_aso4 =  A * df_frh_farm[f'layer_{l}'] * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4J'] + \\\n",
    "                                                      df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASO4I'])\n",
    "      #(df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4I'] + \\\n",
    "      # df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANH4J'] + \\\n",
    "                                                    \n",
    "    \n",
    "      bext_ano3 =  A * df_frh_farm[f'layer_{l}'] * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3I'] + \\\n",
    "                                                     df_FarmRhSpecies_merged[f'layer_{l}_species_c_ANO3J']) \n",
    "    \n",
    "      bext_asoil =  C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOILJ']) + \\\n",
    "                  D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL']) \n",
    "\n",
    "      bext_aseas =  C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEASJ']) + \\\n",
    "                  D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS'])\n",
    "    \n",
    "      bext_other=  B * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25I'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAI'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAI'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBI'] + \\\n",
    "                  df_FarmRhSpecies_merged[f'layer_{l}_species_c_A25J'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORAJ'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORPAJ'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AORBJ']) + \\\n",
    "                D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS'])\n",
    "      \n",
    "      bext_aec= C * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECI'] + df_FarmRhSpecies_merged[f'layer_{l}_species_c_AECJ'])\n",
    "\n",
    "      bext_COARSE = D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASEAS']) +\\\n",
    "      D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ASOIL']) + \\\n",
    "      D * (df_FarmRhSpecies_merged[f'layer_{l}_species_c_ACORS'])\n",
    "\n",
    "      if species == 'ASO4': \n",
    "            temp = bext_aso4 * layer\n",
    "      elif species == 'ANO3':\n",
    "            temp = bext_ano3 * layer\n",
    "      elif species == 'ASEAS':\n",
    "            temp = bext_aseas * layer\n",
    "      elif species == 'ASOIL':\n",
    "            temp = bext_asoil * layer\n",
    "      elif species == 'OTHER':\n",
    "            temp = bext_other * layer\n",
    "      elif species == 'AEC':\n",
    "            temp = bext_aec * layer\n",
    "      elif species == 'COARSE':\n",
    "            temp = bext_COARSE * layer \n",
    "      return temp\n",
    "\n",
    "for i in range(len(Layer)):\n",
    "      df_aod_layer_imp1[i] = compute_aod_layer(Layer[f'layer_{i}'], i)\n",
    "\n",
    "for k in species_list: \n",
    "      for i in range(len(Layer)):\n",
    "            df_FarmRhSpecies_merged_imp1_layer[f'{k}_layer_{i}'] = compute_aod_layer_species(Layer[f'layer_{i}'], i, k)\n",
    "\n",
    "df_aod_layer_imp1 = df_aod_layer_imp1[(df_aod_layer_imp1['time'] >= start_time) & (df_aod_layer_imp1['time'] <= end_time)]\n",
    "df_aod_layer_imp1.reset_index(drop= True, inplace= True)\n",
    "df_aod_layer_imp1_merged = pd.merge(data_h['m1'], df_aod_layer_imp1, on= 'time', how= 'inner')\n",
    "df_aod_layer_imp1_merged.dropna(inplace= True)\n",
    "df_aod_layer_imp1_merged.reset_index(drop= True, inplace= True)\n",
    "\n",
    "df_FarmRhSpecies_merged_imp1_layer = df_FarmRhSpecies_merged_imp1_layer[(df_FarmRhSpecies_merged_imp1_layer['time'] >= start_time) & (df_FarmRhSpecies_merged_imp1_layer['time'] <= end_time)]\n",
    "df_FarmRhSpecies_merged_imp1_layer_merged = pd.merge(data_h['m1'], df_FarmRhSpecies_merged_imp1_layer, on= 'time', how= 'inner')\n",
    "df_FarmRhSpecies_merged_imp1_layer_merged.dropna(inplace= True)\n",
    "df_FarmRhSpecies_merged_imp1_layer_merged.reset_index(drop= True, inplace= True)\n",
    "\n",
    "# check\n",
    "\n",
    "somma = 0\n",
    "temp = 0\n",
    "for s_l in species_list: \n",
    "      temp = df_aod_species_imp1_merged[f'{s_l}']\n",
    "      somma += temp\n",
    "\n",
    "spec_contribution = 0\n",
    "species_tot = 0\n",
    "for k in species_list:\n",
    "      for i in range(N): \n",
    "            spec_contribution = df_FarmRhSpecies_merged_imp1_layer_merged[f'{k}_layer_{i}']\n",
    "            species_tot += spec_contribution\n",
    "\n",
    "#print(f\"Specie:{tot_1.head(10)}\\nTot AOD: {species_tot}\\nIMP1: {data_h['m1']['IMP1F']}\")\n",
    "#print(df_FarmRhSpecies_merged_imp1_layer_merged['AEC_layer_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of new layers and calculation of each species contribution for each layer using IMPROVE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['ASO4', 'ANO3', 'ASEAS', 'ASOIL', 'OTHER', 'AEC', 'COARSE']\n",
    "new_layer = [390, 750, 1840, 4060]\n",
    "delta_z = [[40, 50, 70, 100, 130], [180, 240, 330], [440, 600, 800], [1090, 1470, 1500]]\n",
    "\n",
    "df_BEXT_spec_imp1_new  = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "for i in species_list: \n",
    "      for idx, number in enumerate(new_layer) : \n",
    "            df_BEXT_spec_imp1_new[f's_{i}_l_{idx}'] = 0.0\n",
    "\n",
    "def compute_aod_per_layer_new(species, idx_layer, thickness):\n",
    "\n",
    "      bext = 0.0      \n",
    "      temp_aso4 = A * df_frh_farm[f'layer_{idx_layer}'] * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ANH4I'] + \\\n",
    "                                                           df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ANH4J'] + \\\n",
    "                                                    df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASO4J'] + \\\n",
    "                                                      df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASO4I'])\n",
    "      temp_ano3 = A * df_frh_farm[f'layer_{idx_layer}'] * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ANO3I'] + \\\n",
    "                                                     df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ANO3J']) \n",
    "      temp_asoil = C * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASOILJ']) + \\\n",
    "                  D * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASOIL'])\n",
    "      temp_aseas = C * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASEASJ']) + \\\n",
    "                  D * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASEAS'])\n",
    "      temp_other = B * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_A25I'] + df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AORAI'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AORPAI'] + df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AORBI'] + \\\n",
    "                  df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_A25J'] + df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AORAJ'] + \\\n",
    "                df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AORPAJ'] + df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AORBJ']) + \\\n",
    "                D * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ACORS'])\n",
    "      temp_aec = C * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AECI'] + df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AECJ'])\n",
    "\n",
    "      temp_COARSE = D * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS']) +\\\n",
    "      D * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "      D * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS'])\n",
    "\n",
    "      species_temp_map = {\n",
    "            'ASO4': temp_aso4,\n",
    "            'ANO3': temp_ano3,\n",
    "            'ASOIL': temp_asoil,\n",
    "            'ASEAS': temp_aseas,\n",
    "            'OTHER': temp_other,\n",
    "            'AEC': temp_aec,\n",
    "            'COARSE': temp_COARSE\n",
    "      }\n",
    "\n",
    "      bext = species_temp_map[species] * thickness\n",
    "      return bext\n",
    "\n",
    "new_layer = [390, 750, 1840, 4060]\n",
    "delta_z = [[40, 50, 70, 100, 130], [180, 240, 330], [440, 600, 800], [1090, 1470, 1500]]\n",
    "\n",
    "layer_mapping = {\n",
    "    0: list(range(5)),\n",
    "    1: list(range(5, 8)),\n",
    "    2: list(range(8, 11)),\n",
    "    3: list(range(11, 14)),\n",
    "}\n",
    "\n",
    "for species in species_list:\n",
    "    for idx, thickness in enumerate(delta_z):\n",
    "        for layer_idx in layer_mapping[idx]:\n",
    "            temp = compute_aod_per_layer_new(species, layer_idx, thickness[layer_idx - layer_mapping[idx][0]])\n",
    "            df_BEXT_spec_imp1_new[f's_{species}_l_{idx}'] += temp\n",
    "\n",
    "df_BEXT_spec_imp1_new = df_BEXT_spec_imp1_new[(df_BEXT_spec_imp1_new['time'] >= start_time) & (df_BEXT_spec_imp1_new['time'] <= end_time)]\n",
    "df_BEXT_spec_imp1_new_merged = pd.merge(data_h['m1'], df_BEXT_spec_imp1_new, on= 'time', how= 'inner')\n",
    "df_BEXT_spec_imp1_new_merged.dropna().reset_index(drop=True, inplace=True)\n",
    "\n",
    "#### CHECK ####\n",
    "temp = 0\n",
    "tot = 0\n",
    "for i in species_list: \n",
    "    for j in range(4):\n",
    "        temp = df_BEXT_spec_imp1_new_merged[f's_{i}_l_{j}']\n",
    "        tot += temp\n",
    "#print(tot.head())\n",
    "#print(data_h['m1']['IMP1F'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMP2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a dataframe of AOD for single species\n",
    "df_aod_species_imp2 = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "df_aod_species_imp2['ASO4']= 0.0 \n",
    "df_aod_species_imp2['ANO3']= 0.0\n",
    "df_aod_species_imp2['ASOIL']= 0.0\n",
    "df_aod_species_imp2['ASEAS']= 0.0\n",
    "df_aod_species_imp2['OTHER']= 0.0\n",
    "df_aod_species_imp2['AEC']= 0.0\n",
    "df_aod_species_imp2['COARSE']= 0.0\n",
    "df_aod_species_imp2['ASOIL_C']= 0.0\n",
    "df_aod_species_imp2['ASEAS_C']= 0.0\n",
    "df_aod_species_imp2['ACORS_C']= 0.0\n",
    "\n",
    "somma = 0.0\n",
    "species_list = ['ASO4', 'ANO3', 'ASEAS', 'ASOIL', 'OTHER', 'AEC', 'COARSE', 'ASOIL_C', 'ASEAS_C', 'ACORS_C']\n",
    "new_layer = [390, 750, 1840, 4060]\n",
    "\n",
    "# defining a dataframe of extinction coefficients for both species and layers \n",
    "df_BEXT_spec_imp2  = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "\n",
    "new_columns_2 = {}\n",
    "\n",
    "for i in species_list: \n",
    "      for j in range(N): \n",
    "            new_columns_2[f's_{i}_l_{j}'] = 0.0\n",
    "\n",
    "df_new_2 = pd.DataFrame(new_columns_2, index=df_BEXT_spec_imp2.index)\n",
    "df_BEXT_spec_imp2 = pd.concat([df_BEXT_spec_imp2, df_new_2], axis=1)\n",
    "\n",
    "# defining a datafame of AOD divided into layers\n",
    "df_aod_layer_imp2 = {}\n",
    "df_aod_layer_imp2 = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "df_aod_layer_imp2_new = {}\n",
    "df_aod_layer_imp2_new = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "\n",
    "for h in range(N):\n",
    "\n",
    "    bext_2_ASO4 =   A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "                    A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}'])\n",
    "    \n",
    "    bext_2_ANO3 =   A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "                    A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}'])\n",
    "    \n",
    "    bext_2_ASOIL =  C1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL'])\n",
    "\n",
    "    bext_2_ASEAS =  C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ']) + \\\n",
    "                    C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS'])\n",
    "    \n",
    "    bext_2_OTHER =  A5 * (df_OrgMas_small[f'layer_{h}']) + A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "                    B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) +\\\n",
    "                    C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS']) + \\\n",
    "                    D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "    \n",
    "    bext_COARSE = C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS']) +\\\n",
    "      C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "      C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS'])\n",
    "    \n",
    "    b_asoil_c = C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL'])\n",
    "    b_aseas_c = C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS'])\n",
    "    b_acors_c = C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS'])\n",
    "    \n",
    "    for i in species_list:\n",
    "            if i == 'ASO4':\n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = bext_2_ASO4\n",
    "            elif i == 'ANO3':\n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = bext_2_ANO3\n",
    "            elif i == 'ASOIL': \n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = bext_2_ASOIL\n",
    "            elif i == 'ASEAS': \n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = bext_2_ASEAS\n",
    "            elif i == 'OTHER':\n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = bext_2_OTHER\n",
    "            elif i == 'COARSE':\n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = bext_COARSE\n",
    "            elif i == 'ASOIL_C':\n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = b_asoil_c\n",
    "            elif i == 'ASEAS_C':\n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = b_aseas_c\n",
    "            elif i == 'ACORS_C':\n",
    "                  df_BEXT_spec_imp2[f's_{i}_l_{h}'] = b_acors_c\n",
    "\n",
    "    aod_ASO4 = bext_2_ASO4 * dz[h:h+1]\n",
    "    aod_ANO3 = bext_2_ANO3 * dz[h:h+1]\n",
    "    aod_ASOIL = bext_2_ASOIL * dz[h:h+1]\n",
    "    aod_ASEAS = bext_2_ASEAS * dz[h:h+1]\n",
    "    aod_OTHER = bext_2_OTHER * dz[h:h+1]\n",
    "    aod_COARSE = bext_COARSE * dz[h:h+1]\n",
    "    aod_ASOIL_C = b_asoil_c * dz[h:h+1]\n",
    "    aod_ASEAS_C = b_aseas_c * dz[h:h+1]\n",
    "    aod_ACORS_C = b_acors_C * dz[h:h+1]\n",
    "\n",
    "    df_aod_species_imp2['ASO4'] += aod_ASO4\n",
    "    df_aod_species_imp2['ANO3'] += aod_ANO3\n",
    "    df_aod_species_imp2['ASOIL'] += aod_ASOIL\n",
    "    df_aod_species_imp2['ASEAS'] += aod_ASEAS\n",
    "    df_aod_species_imp2['OTHER'] += aod_OTHER\n",
    "    df_aod_species_imp2['COARSE'] += aod_COARSE\n",
    "    df_aod_species_imp2['ASOIL_C'] += aod_ASOIL_C\n",
    "    df_aod_species_imp2['ASEAS_C'] += aod_ASEAS_C\n",
    "    df_aod_species_imp2['ACORS_C'] += aod_ACORS_C\n",
    "\n",
    "df_aod_species_imp2_dump = df_aod_species_imp2[(df_aod_species_imp2['time'] >= start_time) & (df_aod_species_imp2['time'] <= end_time)]\n",
    "df_aod_species_imp2_dump.reset_index(drop= True, inplace= True)\n",
    "df_aod_species_imp2_merged = pd.merge(data_h['m1'], df_aod_species_imp2_dump, on= 'time', how= 'inner')\n",
    "df_aod_species_imp2_merged.dropna(inplace= True)\n",
    "df_aod_species_imp2_merged.reset_index(drop= True, inplace= True)\n",
    "\n",
    "Layer = {}\n",
    "\n",
    "for i, j in enumerate(dz):\n",
    "      n = f'layer_{i}'\n",
    "      temp = j\n",
    "      Layer[n] = temp\n",
    "\n",
    "def compute_aod_layer(layer, i):\n",
    "      aodlayer = 0.0            \n",
    "      bext_layer = A1 * (df_frh[f'layer_{i}']['f_S']) * (df_ASO4_small[f'layer_{i}']) + \\\n",
    "                  A2 * (df_frh[f'layer_{i}']['f_L']) * (df_ASO4_large[f'layer_{i}']) + \\\n",
    "                  A3 * (df_frh[f'layer_{i}']['f_S']) * (df_ANO3_small[f'layer_{i}']) + \\\n",
    "                  A4 * (df_frh[f'layer_{i}']['f_L']) * (df_ANO3_large[f'layer_{i}']) + \\\n",
    "                  A5 * (df_OrgMas_small[f'layer_{i}']) + \\\n",
    "                  A6 * (df_OrgMas_large[f'layer_{i}']) + \\\n",
    "                  B1 * (df_FarmRhSpecies_merged[f'layer_{i}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{i}_species_c_AECI']) + \\\n",
    "                  C1 * (df_FarmRhSpecies_merged[f'layer_{i}_species_c_ASOILJ']) + \\\n",
    "                  C2 * (df_frh[f'layer_{i}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{i}_species_c_ASEASJ']) + \\\n",
    "                  C3 * (df_FarmRhSpecies_merged[f'layer_{i}_species_c_ASEAS'] + df_FarmRhSpecies_merged[f'layer_{i}_species_c_ACORS'] + df_FarmRhSpecies_merged[f'layer_{i}_species_c_ASOIL']) + \\\n",
    "                  D1 * (R * df_meteo[f'layer_{i}_T'])/(NO2 * df_meteo[f'layer_{i}_P']) * (df_FarmRhSpecies_merged[f'layer_{i}_species_c_NO2'])\n",
    "      aodlayer = bext_layer * layer\n",
    "      return aodlayer\n",
    "\n",
    "df_FarmRhSpecies_merged_layer = {}\n",
    "layer_columns = [f'{species}_layer_{layer}' for species in species_list for layer in range(0, 13)]\n",
    "df_prova = pd.DataFrame(columns= layer_columns)\n",
    "df_prova = pd.DataFrame(0.0, index= range(len(df_FarmRhSpecies_merged['time'])), columns=layer_columns)\n",
    "df_prove = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "df_FarmRhSpecies_merged_layer = pd.concat([df_prove, df_prova], axis=1)\n",
    "\n",
    "def compute_aod_layer_species(layer, h, species):\n",
    "      temp = 0.0\n",
    "      bext_aso4 =   A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "                        A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}'])\n",
    "    \n",
    "      bext_ano3 =   A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "                        A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}'])\n",
    "    \n",
    "      bext_asoil =  C1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL'])\n",
    "\n",
    "      bext_aseas =  C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ']) + \\\n",
    "                        C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS'])\n",
    "    \n",
    "      bext_other=  A5 * (df_OrgMas_small[f'layer_{h}']) + A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "                        B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) +\\\n",
    "                        C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS']) + \\\n",
    "                        D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "      \n",
    "      bext_aec= B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI'])\n",
    "\n",
    "      bext_coarse = C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS']) +\\\n",
    "      C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "      C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS']) \n",
    "\n",
    "      if species == 'ASO4': \n",
    "            temp = bext_aso4 * layer\n",
    "      elif species == 'ANO3':\n",
    "            temp = bext_ano3 * layer\n",
    "      elif species == 'ASEAS':\n",
    "            temp = bext_aseas * layer\n",
    "      elif species == 'ASOIL':\n",
    "            temp = bext_asoil * layer\n",
    "      elif species == 'OTHER':\n",
    "            temp = bext_other * layer\n",
    "      elif species == 'AEC':\n",
    "            temp = bext_aec * layer\n",
    "      elif species == 'COARSE':\n",
    "            temp = bext_coarse * layer\n",
    "      return temp\n",
    "\n",
    "for i in range(len(Layer)):\n",
    "      df_aod_layer_imp2[i] = compute_aod_layer(Layer[f'layer_{i}'], i)\n",
    "\n",
    "data_dict = {}\n",
    "for k in species_list:\n",
    "    for i in range(len(Layer)):\n",
    "        data_dict[f'{k}_layer_{i}'] = compute_aod_layer_species(Layer[f'layer_{i}'], i, k)\n",
    "\n",
    "df_data_dict = pd.DataFrame(data_dict)\n",
    "df_FarmRhSpecies_merged_layer = pd.concat([df_FarmRhSpecies_merged_layer['time'], df_data_dict], axis=1)\n",
    "\n",
    "# for k in species_list: \n",
    "#       for i in range(len(Layer)):\n",
    "#             df_FarmRhSpecies_merged_layer[f'{k}_layer_{i}'] = compute_aod_layer_species(Layer[f'layer_{i}'], i, k)\n",
    "\n",
    "df_aod_layer_imp2 = df_aod_layer_imp2[(df_aod_layer_imp2['time'] >= start_time) & (df_aod_layer_imp2['time'] <= end_time)]\n",
    "df_aod_layer_imp2.reset_index(drop= True, inplace= True)\n",
    "df_aod_layer_imp2_merged = pd.merge(data_h['m1'], df_aod_layer_imp2, on= 'time', how= 'inner')\n",
    "df_aod_layer_imp2_merged.dropna(inplace= True)\n",
    "df_aod_layer_imp2_merged.reset_index(drop= True, inplace= True)\n",
    "\n",
    "df_FarmRhSpecies_merged_imp2_layer = df_FarmRhSpecies_merged_layer[(df_FarmRhSpecies_merged_layer['time'] >= start_time) & (df_FarmRhSpecies_merged_layer['time'] <= end_time)]\n",
    "df_FarmRhSpecies_merged_imp2_layer_merged = pd.merge(data_h['m1'], df_FarmRhSpecies_merged_imp2_layer, on= 'time', how= 'inner')\n",
    "df_FarmRhSpecies_merged_imp2_layer_merged.dropna(inplace= True)\n",
    "df_FarmRhSpecies_merged_imp2_layer_merged.reset_index(drop= True, inplace= True)\n",
    "\n",
    "# check\n",
    "for i  in range(14): \n",
    "      somma += df_aod_layer_imp2_merged[i]\n",
    "\n",
    "tot_AOD= 0.0\n",
    "\n",
    "for k in species_list: \n",
    "      for i in range(14): \n",
    "            tot_AOD += df_FarmRhSpecies_merged_imp2_layer_merged[f'{k}_layer_{i}']\n",
    "#print(data_h['m1']['IMP2F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aodimp['IMP2F'] = 0.0\n",
    "aodimp['IMP2F_ODR'] = 0.0\n",
    "aodimp['IMP2F_NS'] = 0.0\n",
    "\n",
    "#Costants\n",
    "Rayleigh = 0.0729\n",
    "Temp = 298.15\n",
    "R = 8.314\n",
    "NO2 = 4.6\n",
    "A1 = 2.2e-6\n",
    "A2 = 4.8e-6\n",
    "A3 = 2.4e-6\n",
    "A4 = 5.1e-6\n",
    "A5 = 2.8e-6\n",
    "A6 = 6.1e-6\n",
    "B1 = 1.0e-5\n",
    "C1 = 1.0e-6 \n",
    "C1_fit_ODR = 1.3512e-6\n",
    "C3_fit_ODR = 0.811e-6\n",
    "C1_fit_NS = 1.2804e-6\n",
    "C3_fit_NS = 0.768e-6\n",
    "C2 = 1.7e-6\n",
    "C3 = 6.0e-7\n",
    "D1 = 3.3e-7\n",
    "\n",
    "df_bext_imp2 = {}\n",
    "df_bext_imp2_ODR = {}\n",
    "df_bext_imp2_NS = {}\n",
    "\n",
    "for h in range(N): \n",
    "    column_2 = f'layer_{h}'\n",
    "\n",
    "    bext_2 = A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "            A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}']) + \\\n",
    "            A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "            A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}']) + \\\n",
    "            A5 * (df_OrgMas_small[f'layer_{h}']) + \\\n",
    "            A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "            B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) + \\\n",
    "            C1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + \\\n",
    "            C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ']) + \\\n",
    "            C3 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS'] +\\\n",
    "                    df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "            D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "\n",
    "    df_bext_imp2[column_2] = bext_2\n",
    "    aod2 = (df_bext_imp2[column_2]) * dz[h:h+1]\n",
    "    #aod2 = aod2\n",
    "    aodimp['IMP2F'] += aod2\n",
    "    \n",
    "    # CAMBIARE I COEFFICIENTI DEL FIT CHE MOLTIPLICANO LE VARIE SPECIE E MODIFICARE ASEAS AND DUST AND COARSE MASS = acors\n",
    "\n",
    "    bext_2_ODR = A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "            A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}']) + \\\n",
    "            A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "            A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}']) + \\\n",
    "            A5 * (df_OrgMas_small[f'layer_{h}']) + \\\n",
    "            A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "            B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) + \\\n",
    "            C1_fit_ODR * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + \\\n",
    "            C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ']) + \\\n",
    "            C3_fit_ODR * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS'] +\\\n",
    "                    df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "            D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "\n",
    "    df_bext_imp2_ODR[column_2] = bext_2_ODR\n",
    "    aod2_ODR = (df_bext_imp2_ODR[column_2]) * dz[h:h+1]\n",
    "    #aod2 = aod2\n",
    "    aodimp['IMP2F_ODR'] += aod2_ODR\n",
    "    \n",
    "    bext_2_NS = A1 * (df_frh[f'layer_{h}']['f_S']) * (df_ASO4_small[f'layer_{h}']) + \\\n",
    "            A2 * (df_frh[f'layer_{h}']['f_L']) * (df_ASO4_large[f'layer_{h}']) + \\\n",
    "            A3 * (df_frh[f'layer_{h}']['f_S']) * (df_ANO3_small[f'layer_{h}']) + \\\n",
    "            A4 * (df_frh[f'layer_{h}']['f_L']) * (df_ANO3_large[f'layer_{h}']) + \\\n",
    "            A5 * (df_OrgMas_small[f'layer_{h}']) + \\\n",
    "            A6 * (df_OrgMas_large[f'layer_{h}']) + \\\n",
    "            B1 * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_AECI']) + \\\n",
    "            C1_fit_NS * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOILJ']) + \\\n",
    "            C2 * (df_frh[f'layer_{h}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEASJ']) + \\\n",
    "            C3_fit_NS * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASEAS'] + df_FarmRhSpecies_merged[f'layer_{h}_species_c_ACORS'] +\\\n",
    "                    df_FarmRhSpecies_merged[f'layer_{h}_species_c_ASOIL']) + \\\n",
    "            D1 * (R * df_meteo[f'layer_{h}_T'])/(NO2 * df_meteo[f'layer_{h}_P']) * (df_FarmRhSpecies_merged[f'layer_{h}_species_c_NO2'])\n",
    "\n",
    "    df_bext_imp2_NS[column_2] = bext_2_NS\n",
    "    aod2_NS = (df_bext_imp2_NS[column_2]) * dz[h:h+1]\n",
    "    #aod2 = aod2\n",
    "    aodimp['IMP2F_NS'] += aod2_NS\n",
    "\n",
    "df_aodimp = aodimp[(aodimp['time'] >= start_time) & (aodimp['time'] <= end_time)].copy()\n",
    "df_aodimp.reset_index(drop= True, inplace= True)\n",
    "print(df_aodimp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of new layers and calculation of each species contribution for each layer using IMPROVE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['ASO4', 'ANO3', 'ASEAS', 'ASOIL', 'OTHER', 'AEC', 'COARSE']\n",
    "new_layer = [390, 750, 1840, 4060]\n",
    "delta_z = [[40, 50, 70, 100, 130], [180, 240, 330], [440, 600, 800], [1090, 1470, 1500]]\n",
    "\n",
    "df_BEXT_spec_imp2_new  = pd.DataFrame({'time': df_FarmRhSpecies_merged['time']})\n",
    "for i in species_list: \n",
    "      for idx, number in enumerate(new_layer) : \n",
    "            df_BEXT_spec_imp2_new[f's_{i}_l_{idx}'] = 0.0\n",
    "\n",
    "def compute_aod_per_layer_new_2(species, idx_layer, thickness):\n",
    "\n",
    "      bext = 0.0\n",
    "      bext_aso4 =   A1 * (df_frh[f'layer_{idx_layer}']['f_S']) * (df_ASO4_small[f'layer_{idx_layer}']) + \\\n",
    "                        A2 * (df_frh[f'layer_{idx_layer}']['f_L']) * (df_ASO4_large[f'layer_{idx_layer}'])\n",
    "    \n",
    "      bext_ano3 =   A3 * (df_frh[f'layer_{idx_layer}']['f_S']) * (df_ANO3_small[f'layer_{idx_layer}']) + \\\n",
    "                        A4 * (df_frh[f'layer_{idx_layer}']['f_L']) * (df_ANO3_large[f'layer_{idx_layer}'])\n",
    "    \n",
    "      bext_asoil =  C1 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASOILJ']) + C3 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASOIL'])\n",
    "\n",
    "      bext_aseas =  C2 * (df_frh[f'layer_{idx_layer}']['f_SS']) * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASEASJ']) + \\\n",
    "                        C3 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASEAS'])\n",
    "    \n",
    "      bext_other =  A5 * (df_OrgMas_small[f'layer_{idx_layer}']) + A6 * (df_OrgMas_large[f'layer_{idx_layer}']) + \\\n",
    "                        C3 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ACORS']) + \\\n",
    "                        D1 * (R * df_meteo[f'layer_{idx_layer}_T'])/(NO2 * df_meteo[f'layer_{idx_layer}_P']) * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_NO2'])\n",
    "      \n",
    "      bext_aec = B1 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AECJ'] + df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_AECI'])\n",
    "\n",
    "      bext_coarse = C3 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASEAS']) +\\\n",
    "      C3 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ASOIL']) + \\\n",
    "      C3 * (df_FarmRhSpecies_merged[f'layer_{idx_layer}_species_c_ACORS'])\n",
    "\n",
    "      species_temp_map = {\n",
    "            'ASO4': bext_aso4,\n",
    "            'ANO3': bext_ano3,\n",
    "            'ASOIL': bext_asoil,\n",
    "            'ASEAS': bext_aseas,\n",
    "            'OTHER': bext_other,\n",
    "            'AEC': bext_aec,\n",
    "            'COARSE': bext_coarse\n",
    "      }\n",
    "\n",
    "      bext = species_temp_map[species] * thickness\n",
    "      return bext\n",
    "\n",
    "new_layer = [390, 750, 1840, 4060]\n",
    "delta_z = [[40, 50, 70, 100, 130], [180, 240, 330], [440, 600, 800], [1090, 1470, 1500]]\n",
    "\n",
    "layer_mapping = {\n",
    "    0: list(range(5)),\n",
    "    1: list(range(5, 8)),\n",
    "    2: list(range(8, 11)),\n",
    "    3: list(range(11, 14)),\n",
    "}\n",
    "\n",
    "for species in species_list:\n",
    "    for idx, thickness in enumerate(delta_z):\n",
    "        for layer_idx in layer_mapping[idx]:\n",
    "            temp = compute_aod_per_layer_new_2(species, layer_idx, thickness[layer_idx - layer_mapping[idx][0]])\n",
    "            df_BEXT_spec_imp2_new[f's_{species}_l_{idx}'] += temp\n",
    "\n",
    "df_BEXT_spec_imp2_new = df_BEXT_spec_imp2_new[(df_BEXT_spec_imp2_new['time'] >= start_time) & (df_BEXT_spec_imp2_new['time'] <= end_time)]\n",
    "df_BEXT_spec_imp2_new_merged = pd.merge(data_h['m1'], df_BEXT_spec_imp2_new, on= 'time', how= 'inner')\n",
    "df_BEXT_spec_imp2_new_merged.dropna(inplace=True)\n",
    "df_BEXT_spec_imp2_new_merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#### CHECK ####\n",
    "temp = 0\n",
    "tot = 0\n",
    "for i in species_list: \n",
    "    for j in range(4):\n",
    "        temp = df_BEXT_spec_imp2_new_merged[f's_{i}_l_{j}']\n",
    "        tot += temp\n",
    "#print(tot.head())\n",
    "#print(data_h['m1']['IMP2F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BEXT_h_imp1 = pd.merge(data_h['m1'], df_BEXT_spec_imp1, on= 'time', how= 'inner')\n",
    "df_SPEC_h_imp1 = pd.merge(data_h['m1'], df_aod_species_imp1, on= 'time', how= 'inner')\n",
    "df_LAY_h_imp1 = pd.merge(data_h['m1'], df_FarmRhSpecies_merged_imp1_layer, on= 'time', how= 'inner')\n",
    "\n",
    "df_BEXT_h_imp2 = pd.merge(data_h['m1'], df_BEXT_spec_imp2, on= 'time', how= 'inner')\n",
    "df_SPEC_h_imp2 = pd.merge(data_h['m1'], df_aod_species_imp2, on= 'time', how= 'inner')\n",
    "df_LAY_h_imp2 = pd.merge(data_h['m1'], df_FarmRhSpecies_merged_imp2_layer, on= 'time', how= 'inner')\n",
    "\n",
    "#df_BEXT_h_imp2_4l = pd.merge(data_h['m1'], df_BEXT_spec_imp2_new, on= 'time', how= 'inner')\n",
    "#df_SPEC_h_imp2_4l = pd.merge(data_h['m1'], df_aod_species_imp2_, on= 'time', how= 'inner')\n",
    "df_LAY_h_imp2_4l = pd.merge(data_h['m1'], df_BEXT_spec_imp2_new_merged, on= 'time', how= 'inner')\n",
    "df_LAY_h_imp1_4l = pd.merge(data_h['m1'], df_BEXT_spec_imp1_new_merged, on= 'time', how= 'inner')\n",
    "\n",
    "#Bext_df = df_BEXT_h.groupby(pd.Grouper(key= 'time', freq= 'D')).mean()\n",
    "#Bext_df.reset_index(inplace= True)\n",
    "\n",
    "'''\n",
    "def resample_data_1(df, period):\n",
    "    df_resampled = df.resample(period, on= 'time').mean().dropna()\n",
    "    df_resampled.reset_index(inplace= True)\n",
    "    return df_resampled\n",
    "'''\n",
    "\n",
    "df_BEXT_IMP1 = {\n",
    "    'M1': df_BEXT_h_imp1, \n",
    "    'M3': resample_data(df_BEXT_h_imp1, '3h'),\n",
    "    'M6': resample_data(df_BEXT_h_imp1, '6h'),\n",
    "    'M24': resample_data(df_BEXT_h_imp1, 'D'), \n",
    "    'M30': resample_data(df_BEXT_h_imp1, 'MS')\n",
    "}\n",
    "\n",
    "df_LAY_IMP1 = {\n",
    "    'M1': df_LAY_h_imp1, \n",
    "    'M3': resample_data(df_LAY_h_imp1, '3h'),\n",
    "    'M6': resample_data(df_LAY_h_imp1, '6h'),\n",
    "    'M24': resample_data(df_LAY_h_imp1, 'D'),\n",
    "    'M30': resample_data(df_LAY_h_imp1, 'MS'),\n",
    "    '1D': resample_data(df_LAY_h_imp1_4l, 'D')\n",
    "}\n",
    "\n",
    "df_SPEC_IMP1 = {\n",
    "    'M1': df_SPEC_h_imp1, \n",
    "    'M3': resample_data(df_SPEC_h_imp1, '3h'),\n",
    "    'M6': resample_data(df_SPEC_h_imp1, '6h'),\n",
    "    'M24': resample_data(df_SPEC_h_imp1, 'D'),\n",
    "    'M30': resample_data(df_SPEC_h_imp1, 'MS')\n",
    "}\n",
    "\n",
    "df_BEXT_IMP2 = {\n",
    "    'M1': df_BEXT_h_imp2, \n",
    "    'M3': resample_data(df_BEXT_h_imp2, '3h'),\n",
    "    'M6': resample_data(df_BEXT_h_imp2, '6h'),\n",
    "    'M24': resample_data(df_BEXT_h_imp2, 'D'), \n",
    "    'M30': resample_data(df_BEXT_h_imp2, 'MS')\n",
    "}\n",
    "\n",
    "df_LAY_IMP2 = {\n",
    "    'M1': df_LAY_h_imp2, \n",
    "    'M3': resample_data(df_LAY_h_imp2, '3h'),\n",
    "    'M6': resample_data(df_LAY_h_imp2, '6h'),\n",
    "    'M24': resample_data(df_LAY_h_imp2, 'D'),\n",
    "    'M30': resample_data(df_LAY_h_imp2, 'MS'),\n",
    "    '1D': resample_data(df_LAY_h_imp2_4l, 'D')\n",
    "}\n",
    "\n",
    "df_SPEC_IMP2 = {\n",
    "    'M1': df_SPEC_h_imp2, \n",
    "    'M3': resample_data(df_SPEC_h_imp2, '3h'),\n",
    "    'M6': resample_data(df_SPEC_h_imp2, '6h'),\n",
    "    'M24': resample_data(df_SPEC_h_imp2, 'D'),\n",
    "    'M30': resample_data(df_SPEC_h_imp2, 'MS')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time vs LMP aod (3h-24h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "t = Data['1D']['time']\n",
    "farm = Data['1D']['FARM']\n",
    "imp1 = Data['1D']['IMP1F']\n",
    "imp2 = Data['1D']['IMP2F']\n",
    "lmp = Data['1D']['LMP']\n",
    "ang = Data['1D']['ang_440_870']\n",
    "\n",
    "# # t = Data['1H']['time']\n",
    "# # farm = Data['1H']['FARM']\n",
    "# # imp1 = Data['1H']['IMP1F']\n",
    "# # imp2 = Data['1H']['IMP2F']\n",
    "imp1_odr = Data['1D']['IMP1F_ODR']\n",
    "imp2_odr = Data['1D']['IMP2F_ODR']\n",
    "# # lmp = Data['1H']['LMP']\n",
    "# # ang = Data['1H']['ang_440_870']\n",
    "\n",
    "# mar = Data['1D'][(Data['1D']['time'].dt.month == 3) & (Data['1D']['time'].dt.day == 27)] \n",
    "# t_mar = mar['time']\n",
    "# lmp_mar = mar['LMP']\n",
    "# imp2_mar = mar['IMP2F_ODR']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(lmp, ang, s=10, c=ang,  cmap=\"plasma_r\", marker= 'o')\n",
    "plt.xlabel(r\"$\\tau_{OBS}$\", fontsize=16)\n",
    "#plt.ylabel(r\"$\\alpha_{(440-870)nm}$\", fontsize=16)\n",
    "plt.title(\"Aleria_MF (ANG, daily)\", fontweight=\"bold\")\n",
    "plt.colorbar().set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "plt.grid(True)\n",
    "#plt.savefig(\"/home/andtoro/figure/lmp_ang_daily_part2.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "#plt.close()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "\n",
    "# plt.scatter(t_mar, lmp_mar, s= 10, c= '#f3752b', marker= 'o', alpha= 0.5)\n",
    "# plt.scatter(t_mar, imp2_mar, s= 10,  c= '#050505', marker= 'o', alpha= 0.4)\n",
    "plt.scatter(t, lmp, s= 10,  c= '#f3752b', marker= 'o', alpha= 0.5)\n",
    "plt.scatter(t, farm, s= 10,  c= '#050505', marker= 'o', alpha= 0.5)\n",
    "plt.scatter(t, imp1, s= 10,  c= '#3f88c5', marker= 's', alpha=0.5)\n",
    "plt.scatter(t, imp2, s= 10,  c= '#157f1f', marker= 's', alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.legend(labels= [r'OBS', r'FARM',  r' IMP1F', r'IMP2F'])\n",
    "#plt.tight_layout()\n",
    "plt.xlim(t.min(), t.max())\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(rf'{name_save_fig} (daily)', fontweight= 'bold')\n",
    "plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "plt.xlabel(r'Time [yyyy-mm]', fontweight= \"bold\")\n",
    "if save_fig:\n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure/{name_save_fig}_obs_mods_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#plt.close()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize= (12, 8), sharex= True, sharey= True)\n",
    "\n",
    "ax1.scatter(t, lmp,  s= 10, c= '#f3752b', marker= 'o', alpha= 0.7)\n",
    "ax1.set_ylabel(r'$\\tau_{OBS}$', fontsize= 16)\n",
    "ax1.set_title(rf'{name_save_fig} (daily)', fontweight= 'bold')\n",
    "ax1.grid(True)\n",
    "ax2.scatter(t, farm, s= 10, c=  '#050505', marker= 'o', alpha=0.7)\n",
    "ax2.set_ylabel(r'$\\tau_{FARM}$', fontsize= 16)\n",
    "ax2.grid(True)\n",
    "ax3.scatter(t, imp1, s= 10, c=  '#3f88c5', marker= 's', alpha=0.7)\n",
    "ax3.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "ax3.grid(True)\n",
    "ax4.scatter(t, imp2, s= 10, c=  '#157f1f', marker= 's', alpha=0.7)\n",
    "ax4.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "ax4.grid(True)\n",
    "ax4.set_xlabel(r'Time [yyyy-mm]', fontweight= \"bold\")\n",
    "# ax5.scatter(t, imp1_odr, s= 10, c=  'red', marker= 's')\n",
    "# ax5.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "# ax5.grid(True)\n",
    "# ax6.scatter(t, imp2_odr, s= 10, c=  'blue', marker= 's')\n",
    "# ax6.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "# ax6.grid(True)\n",
    "# ax6.set_xlabel(r'Time [yyyy-mm]', fontsize= 16)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    ax.set_xlim(t.min(), t.max())\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "if save_fig:\n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure/{name_save_fig}_obs_mods_1_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#plt.close()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "\n",
    "plt.scatter(t, lmp, s= 10, c= ang, cmap= 'plasma_r', marker= 'o')\n",
    "#plt.plot(time, hmix/max(hmix), linestyle= '-.', color= 'black')\n",
    "plt.grid(True)\n",
    "plt.legend(labels= [r'OBS'])\n",
    "plt.colorbar().set_label(r'$\\alpha_{440-870}$', fontsize= 16)\n",
    "#plt.tight_layout()\n",
    "plt.xlim(t.min(), t.max())\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(rf'{name_save_fig} (daily)', fontweight= 'bold')\n",
    "plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "plt.xlabel(r'Time [yyyy-mm]', fontweight= \"bold\")\n",
    "if save_fig:\n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure/{name_save_fig}_obs_ang_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Variables\n",
    "# t = Data['1H']['time']\n",
    "# farm = Data['1H']['FARM']\n",
    "# lmp = Data['1H']['LMP']\n",
    "# ang = Data['1H']['ang_440_870']\n",
    "\n",
    "# plt.figure(figsize= (10, 6))\n",
    "\n",
    "# plt.scatter(t, lmp, s= 10, c= '#f3752b', marker= 'o')\n",
    "# plt.scatter(t, farm, s= 10,  c= '#050505', marker= 'o')\n",
    "# plt.grid(True)\n",
    "# plt.legend(labels= [r'LMP', r'FARM'])\n",
    "# plt.xlim(t.min(), t.max())\n",
    "# plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.title(r'Observations and model (1D)', fontweight= 'bold')\n",
    "# plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "# plt.xlabel(r'Time [yyyy-mm]', fontweight= 'bold')\n",
    "# #plt.savefig(\"/home/andtoro/figure/time_FARM_LMP_1D_unito.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# # plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize= (10, 6), sharex= True, sharey= True)\n",
    "\n",
    "# ax1.scatter(t, lmp,  s= 10, c= '#f3752b', marker= 'o')\n",
    "# ax1.set_ylabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "# ax1.set_title(r'Observations and model (1D)', fontweight= 'bold')\n",
    "# ax1.grid(True)\n",
    "# ax2.scatter(t, farm, s= 10, c=  '#050505', marker= 'o')\n",
    "# ax2.set_ylabel(r'$\\tau_{FARM}$', fontsize= 16)\n",
    "# ax2.grid(True)\n",
    "# ax2.set_xlabel(r'Time [yyyy-mm]', fontweight= 'bold')\n",
    "\n",
    "# for ax in [ax1, ax2]:\n",
    "#     ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "#     ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "#     ax.set_xlim(t.min(), t.max())\n",
    "#     plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# #plt.savefig(\"/home/andtoro/figure/time_FARM_LMP_1D_separato.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# # plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize= (10, 6))\n",
    "\n",
    "# plt.scatter(t, lmp, s= 10, c= ang, cmap= 'plasma_r', marker= 'o')\n",
    "# #plt.plot(time, hmix/max(hmix), linestyle= '-.', color= 'black')\n",
    "# plt.grid(True)\n",
    "# plt.legend(labels= [r'LMP'])\n",
    "# plt.colorbar().set_label(r'$\\alpha_{(440-870)}nm$', fontsize= 16)\n",
    "# plt.xlim(t.min(), t.max())\n",
    "# plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.title(r'LMP data with ANG associated (1H)', fontweight= 'bold')\n",
    "# plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "# plt.xlabel(r'Time [yyyy-mm]', fontweight= 'bold')\n",
    "# #plt.savefig(\"/home/andtoro/figure/time_LMP_FARM_ANG_1H.pdf\", format=\"pdf\",  bbox_inches=\"tight\")\n",
    "# #plt.tight_layout()\n",
    "# #plt.show()\n",
    "# #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot separato\n",
    "# fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize= (15, 12), sharex= True, sharey= True)\n",
    "\n",
    "# ax1.scatter(Data['1H']['time'], Data['1H']['LMP'],  s= 5, c= '#f3752b', marker= 'o', label= 'obs', alpha=0.5)\n",
    "# ax1.scatter(Data['1H']['time'], Data['1H']['FARM'], s= 5, c= '#050505', marker= 'o', label= 'sim', alpha=0.4)\n",
    "# ax1.scatter(Data['1H']['time'], Data['1H']['IMP1F'], s= 5, c= '#3f88c5', marker= 'o', label= 'imp1', alpha=0.5)\n",
    "# ax1.scatter(Data['1H']['time'], Data['1H']['IMP2F'], s= 5, c= '#157f1f', marker= 'o', label= 'imp2', alpha=0.4)\n",
    "# ax1.set_title(r'1H', fontweight= 'bold')\n",
    "# ax1.set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "# ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y'))\n",
    "# ax1.xaxis.set_major_locator(mdates.MonthLocator(interval= 1))\n",
    "# ax1.tick_params(labelsize= '7', labelrotation= 45)\n",
    "# ax1.grid(True)\n",
    "\n",
    "# ax2.scatter(Data['3H']['time'], Data['3H']['LMP'],  s= 5, c= '#f3752b', marker= 'o', label= 'obs', alpha=0.5)\n",
    "# ax2.scatter(Data['3H']['time'], Data['3H']['FARM'], s= 5, c= '#050505', marker= 'o', label= 'sim', alpha=0.4)\n",
    "# ax2.scatter(Data['3H']['time'], Data['3H']['IMP1F'], s= 5, c= '#3f88c5', marker= 'o', label= 'imp1', alpha=0.5)\n",
    "# ax2.scatter(Data['3H']['time'], Data['3H']['IMP2F'], s= 5, c= '#157f1f', marker= 'o', label= 'imp2', alpha=0.4)\n",
    "# ax2.set_title(r'3H', fontweight= 'bold')\n",
    "# ax2.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y'))\n",
    "# ax2.xaxis.set_major_locator(mdates.MonthLocator(interval= 1))\n",
    "# ax2.tick_params(labelsize= '7', labelrotation= 45)\n",
    "# ax2.grid(True)\n",
    "\n",
    "# ax3.scatter(Data['6H']['time'], Data['6H']['LMP'],  s= 5, c= '#f3752b', marker= 'o', label= 'obs', alpha=0.5)\n",
    "# ax3.scatter(Data['6H']['time'], Data['6H']['FARM'], s= 5, c= '#050505', marker= 'o', label= 'sim', alpha=0.4)\n",
    "# ax3.scatter(Data['6H']['time'], Data['6H']['IMP1F'], s= 5, c= '#3f88c5', marker= 'o', label= 'imp1', alpha=0.5)\n",
    "# ax3.scatter(Data['6H']['time'], Data['6H']['IMP2F'], s= 5, c= '#157f1f', marker= 'o', label= 'imp2', alpha=0.4)\n",
    "# ax3.set_title(r'6H', fontweight= 'bold')\n",
    "# ax3.set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "# ax3.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y'))\n",
    "# ax3.xaxis.set_major_locator(mdates.MonthLocator(interval= 1))\n",
    "# ax3.tick_params(labelsize= '7', labelrotation= 45)\n",
    "# ax3.grid(True)\n",
    "\n",
    "# ax4.scatter(Data['1D']['time'], Data['1D']['LMP'],  s= 5, c= '#f3752b', marker= 'o', label= 'obs', alpha=0.5)\n",
    "# ax4.scatter(Data['1D']['time'], Data['1D']['FARM'], s= 5, c= '#050505', marker= 'o', label= 'sim', alpha=0.4)\n",
    "# ax4.scatter(Data['1D']['time'], Data['1D']['IMP1F'], s= 5, c= '#3f88c5', marker= 'o', label= 'imp1', alpha=0.5)\n",
    "# ax4.scatter(Data['1D']['time'], Data['1D']['IMP2F'], s= 5, c= '#157f1f', marker= 'o', label= 'imp2', alpha=0.4)\n",
    "# ax4.set_title(r'1D', fontweight= 'bold')\n",
    "# ax4.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y'))\n",
    "# ax4.xaxis.set_major_locator(mdates.MonthLocator(interval= 1))\n",
    "# ax4.tick_params(labelsize= '7', labelrotation= 45)\n",
    "# ax4.grid(True)\n",
    "\n",
    "# #for label in ax6.get_xticklabels():\n",
    "# #    label.set_fontweight('bold')\n",
    "# #    label.set_fontfamily('sans-serif') \n",
    "\n",
    "# ax4.grid(True)\n",
    "# fig.legend(loc='upper right', labels= ['LMP', 'FARM', 'IMP1F', 'IMP2F'], bbox_to_anchor=(0.55, 0.89), ncol=1, fancybox=True, shadow=True)\n",
    "# start_date = pd.to_datetime('2023-09-01')\n",
    "# end_date = pd.to_datetime('2024-09-01')\n",
    "# plt.xlim(start_date, end_date)\n",
    "# plt.xlabel(r'Time [dd/mm/yyyy]', x= -0.1, fontweight= 'bold')\n",
    "# #plt.tight_layout()\n",
    "\n",
    "# #plt.savefig(\"/home/andrea/enea_project/lmp_dust_enea/figure_old/lmp_mods_averages.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "# #plt.show()\n",
    "# # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PBL on Lampedusa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = Data['1D']['time']\n",
    "hmix = Data['1D']['HMIX']\n",
    "\n",
    "hmix_dump = Data['1H'].resample('MS', on= 'time').mean()\n",
    "time_month = hmix_dump.index.to_numpy()\n",
    "hmix_month = hmix_dump['HMIX']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(time_month, hmix_month, linestyle= '--', color= 'black')\n",
    "plt.xlabel('Time [yyyy-mm]', fontweight= 'bold')\n",
    "plt.xlim(time_month.min(), time_month.max())\n",
    "plt.ylabel('Altitude [m]', fontweight= 'bold')\n",
    "plt.title('Boundary layer (months average)', fontweight= 'bold')\n",
    "#plt.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure_old/{name_save_fig}_pbl_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errorbar LMP and differences between averages behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = data['data24h']['time']\n",
    "time_1 = data['data1h']['time']\n",
    "aod_obs = data['data24h']['LMP']\n",
    "aod_obs_1 = data['data1h']['LMP']\n",
    "#err_obs = data['data24h']['err_day']\n",
    "fluct = data['data24h']['err_day_new']\n",
    "err = data['data24h']['err_new']\n",
    "err_obs_1 = data['data1h']['err_1h_new']\n",
    "err_obs = data['data24h']['err_day_new']\n",
    "errore_relativo = (err_obs/aod_obs) * 100\n",
    "errore_relativo_1 = (err_obs_1/aod_obs_1) * 100\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(time_1, aod_obs_1, s= 5, marker= 'o', c= 'red', label= 'LMP')\n",
    "#plt.fill_between(time, aod_obs - fluct, aod_obs + fluct,  color= 'red, alpha= 0.6)\n",
    "#plt.errorbar(time, aod_obs, yerr= err, c= 'red, capsize= 5, linestyle= '')\n",
    "plt.errorbar(time_1, aod_obs_1, yerr= err_obs_1, c= 'red', capsize= 5, linestyle= '', alpha= 0.5)\n",
    "plt.scatter(time, aod_obs, s= 5, marker= 'o', c= 'blue', label= 'LMP')\n",
    "#plt.fill_between(time, aod_obs - fluct, aod_obs + fluct,  color= 'blue, alpha= 0.6)\n",
    "#plt.errorbar(time, aod_obs, yerr= err, c= 'blue, capsize= 5, linestyle= '')\n",
    "plt.errorbar(time, aod_obs, yerr= fluct, c= 'blue', capsize= 5, linestyle= '', alpha= 0.5)\n",
    "plt.title(f'Observations with uncertainty ({name_save_fig})', fontweight= 'bold')\n",
    "plt.xlim(time.min(), time.max())\n",
    "plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "plt.xlabel('Time [yyyy-mm]', fontweight= 'bold')\n",
    "plt.legend(['Hourly data', 'Daily data'])\n",
    "#date_formatter = DateFormatter('%Y/%m')\n",
    "#plt.gca().xaxis.set_major_formatter(date_formatter)\n",
    "#plt.gcf().autofmt_xdate() \n",
    "#plt.tight_layout()\n",
    "plt.grid(True)\n",
    "if save_fig:\n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure_old/{name_save_fig}_errorbar_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "\n",
    "plt.plot(Data['1H']['time'], Data['1H']['LMP'], c= 'red', linestyle= ':', label= 'LMP (1h)', alpha= 0.5)\n",
    "#plt.plot(Data['3H']['time'], Data['3H']['LMP'], c= 'red', linestyle= '-.', label= 'LMP (3h)', alpha= 0.6)\n",
    "plt.plot(Data['1D']['time'], Data['1D']['LMP'], c= 'blue',  linestyle= '-', label= 'LMP (24h)', alpha= 0.5)\n",
    "plt.xlabel('Time [yyyy-mm]', fontweight= 'bold')\n",
    "plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "plt.xlim(Data['1D']['time'].min(), Data['1D']['time'].max())\n",
    "plt.legend()\n",
    "plt.title('Data averages', fontweight= 'bold')\n",
    "plt.grid(True)\n",
    "#plt.tight_layout()\n",
    "#plt.savefig(\"/home/andtoro/figure/1H_1D_diff.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "\n",
    "plt.scatter(aod_obs_1, errore_relativo_1, c= 'red', marker= 's', alpha= 0.6)\n",
    "plt.scatter(aod_obs, errore_relativo, c= 'blue', marker= 's', alpha= 0.6)\n",
    "#plt.yscale('log')\n",
    "plt.xlabel(r'$\\tau$',fontsize= 16)\n",
    "plt.ylabel(r'$\\frac{\\Delta\\tau}{\\tau}\\%$', fontsize= 16)\n",
    "plt.title(f'Relative error percentage ({name_save_fig})', fontweight= 'bold')\n",
    "plt.legend(['Hourly data', 'Daily data'])\n",
    "plt.grid(True)\n",
    "#plt.tight_layout()\n",
    "if save_fig: \n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure_old/{name_save_fig}_errorbar_rel_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data divided into season and associated with ANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season = {\n",
    "#     'fall': fall_24h, \n",
    "#     'winter': winter_24h, \n",
    "#     'spring': spring_24h,\n",
    "#     'summer':  summer_24h\n",
    "# }\n",
    "\n",
    "# # plot separato\n",
    "# fig, ax = plt.subplots(2, 2, figsize= (12, 8), sharey= True, sharex= False)\n",
    "# ax = ax.ravel()\n",
    "\n",
    "# norm = mcolors.Normalize(vmin=0., vmax=2.) \n",
    "# cmap = cm.plasma_r\n",
    "\n",
    "# for i, season_name in enumerate(season):\n",
    "#     data3 = season[season_name]\n",
    "\n",
    "#     ax[i].scatter(data3['time'], data3['LMP'], s=10, c= data3['ang_440_870'], cmap= 'plasma_r', marker= 'o')\n",
    "#     #ax[i].set_ylabel(r'$\\tau$')\n",
    "#     #ax[i].set_xlabel(r'Time [dd-mm-yyyy]')\n",
    "#     ax[i].set_title(season_name.capitalize(), fontweight= 'bold')\n",
    "#     ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%m/%y'))\n",
    "#     ax[i].grid(True)\n",
    "#     #ax[i].tick_params(labelsize= '7', labelrotation= 45)\n",
    "#     ax[i].set_xlim(data3['time'].min(), data3['time'].max())\n",
    "\n",
    "#     if i >= 2:\n",
    "#         ax[i].set_xlabel('Time [mm/yy]', fontweight=\"bold\")\n",
    "\n",
    "\n",
    "# ax[0].set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "# ax[2].set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "# fig.legend(loc='upper right', labels= ['LMP'], bbox_to_anchor=(0.80, 0.92), ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "# cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax= ax, orientation='vertical')\n",
    "# cbar.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "# fig.suptitle(r'Season with ANG associated', fontweight= 'bold', fontsize= 16, x= 0.45, y= 0.94)\n",
    "# # plt.savefig(\"/home/andrea/enea_project/lmp_dust_enea/figure_old/lmp_ang_seasons.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed data divivded into Desert Dust (DD), Biomass Burning anthropogenic or natural (BB), and Mixed (MX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12, 8))\n",
    "\n",
    "colors = {\n",
    "    'DD': '#f7b538',\n",
    "    'BB': '#dd0426',\n",
    "    'MX': '#798071'\n",
    "}\n",
    "markers = {\n",
    "    'DD': 'p', \n",
    "    'BB': 'd',\n",
    "    'MX': 's'\n",
    "}\n",
    "\n",
    "plt.scatter(DeDu24['time'], DeDu24['LMP'], marker= 'p', c= colors['DD'], s= 15, alpha= 0.8)\n",
    "plt.scatter(BioBu24['time'], BioBu24['LMP'], marker= 'd', c= colors['BB'] , s= 15, alpha= 0.8)\n",
    "plt.scatter(Mix24['time'], Mix24['LMP'], marker= 's', c= colors['MX'], s= 15, alpha= 0.7)\n",
    "plt.xlabel('Time [yyyy-mm]', fontweight=\"bold\")\n",
    "plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "plt.xlim(data_h['m24']['time'].min(), data_h['m24']['time'].max())\n",
    "plt.title(f'{name_save_fig}', fontweight= 'bold')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.legend(labels= ['DD', 'BB', 'MX'], loc= 'best', shadow= True, fancybox= True,)\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure_old/{name_save_fig}_dd_bb_mx_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(4, 1, figsize=(12, 8), sharex= True, sharey= True)\n",
    "\n",
    "aerosols = ['DD', 'BB', 'MX']\n",
    "data_type = ['LMP', 'FARM', 'IMP1F', 'IMP2F']\n",
    "\n",
    "aero_type = {\n",
    "    'DD': DeDu,\n",
    "    'BB': BioBu, \n",
    "    'MX': Mix\n",
    "}\n",
    "\n",
    "aero_type24 = {\n",
    "    'DD': DeDu24,\n",
    "    'BB': BioBu24, \n",
    "    'MX': Mix24\n",
    "}\n",
    "\n",
    "for i in range(4): \n",
    "    for j in aerosols:\n",
    "        ax[i].scatter(aero_type24[j]['time'], aero_type24[j][data_type[i]], c= colors[j], label= f'{j}', marker= markers[j], s= 10, alpha= 0.8)\n",
    "        if i == 3:\n",
    "            ax[i].set_xlabel('Time [yyyy-mm]', fontweight=\"bold\")\n",
    "        elif i == 2:\n",
    "            ax[i].set_ylabel(r'$\\tau$', fontsize= 16, y=1.2)\n",
    "        ax[i].grid(True)\n",
    "        if data_type[i] == \"LMP\":\n",
    "            ax[i].set_title(f\"OBS({name_save_fig})\", fontweight= 'bold')\n",
    "        else:\n",
    "            ax[i].set_title(data_type[i], fontweight= 'bold')\n",
    "    ax[i].set_xlim(data_h['m3']['time'].min(), data_h['m3']['time'].max())\n",
    "\n",
    "fig.legend(aerosols, loc='upper center', ncol=len(aerosols), bbox_to_anchor=(0.8, 0.90), fancybox= True, shadow= True)\n",
    "#plt.tight_layout(rect=[0, 0, 0.95, 0.96])  # Adjust layout to fit the legend\n",
    "if save_fig:\n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure_old/{name_save_fig}_obs_mods_dd_bb_mx_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(4, 1, figsize=(12, 12), sharex=True, sharey=True)\n",
    "\n",
    "# aerosols = ['DD', 'MX', 'BB']\n",
    "# data_type = ['LMP', 'FARM', 'IMP1F', 'IMP2F']\n",
    "# colors = {\n",
    "#     'DD': '#f7b538',\n",
    "#     'BB': '#dd0426',\n",
    "#     'MX': '#798071'\n",
    "# }\n",
    "\n",
    "# aero_type = {\n",
    "#     'DD': DeDu,\n",
    "#     'BB': BioBu,\n",
    "#     'MX': Mix\n",
    "# }\n",
    "# aero_type24 = {\n",
    "#     'DD': DeDu24,\n",
    "#     'BB': BioBu24, \n",
    "#     'MX': Mix24\n",
    "# }\n",
    "\n",
    "# for i in range(4):\n",
    "#     for j in aerosols:\n",
    "#         ax[i].set_title(data_type[i], fontweight= 'bold')\n",
    "#         data = aero_type24[j][data_type[i]]\n",
    "\n",
    "#         # Calculate bin width: (max - min) / sqrt(number of data points)\n",
    "#         bin_width = (data.max() - data.min()) / np.sqrt(len(data))\n",
    "#         bins = np.arange(data.min(), data.max() + bin_width, bin_width)\n",
    "        \n",
    "#         # Plot the histogram with custom bins and separation lines\n",
    "#         ax[i].hist(data, bins=bins, color=colors[j], label=j, alpha=0.7, edgecolor='black')\n",
    "        \n",
    "#         if i == 3:  # Only set the x-axis label for the last subplot\n",
    "#             ax[i].set_xlabel(r'$\\tau$', fontsize= 16)\n",
    "#         ax[i].grid(True)\n",
    "#     ax[i].set_xlim(data_h['m24']['LMP'].min(), data_h['m24']['LMP'].max())\n",
    "# ax[1].set_ylabel('Number of occurencies', fontweight= 'bold', y= -0.2, fontsize= 16)\n",
    "# # Create a single legend outside the subplots\n",
    "# fig.legend(aerosols, loc='upper center', ncol=len(aerosols), bbox_to_anchor=(0.8, 0.96))\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the legend\n",
    "# #plt.savefig(\"/home/andtoro/figure/histograms_DD_BB_MX_MODS_time.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "\n",
    "# # Define the seasonal data dictionaries\n",
    "# seasonal_data_DD = {\n",
    "#     'Fall': fall_24h_DD,\n",
    "#     'Winter': winter_24h_DD,\n",
    "#     'Spring': spring_24h_DD,\n",
    "#     'Summer': summer_24h_DD\n",
    "# }\n",
    "\n",
    "# seasonal_data_BB = {\n",
    "#     'Fall': fall_24h_BB,\n",
    "#     'Winter': winter_24h_BB,\n",
    "#     'Spring': spring_24h_BB,\n",
    "#     'Summer': summer_24h_BB\n",
    "# }\n",
    "\n",
    "# seasonal_data_MX = {\n",
    "#     'Fall': fall_24h_MX,\n",
    "#     'Winter': winter_24h_MX,\n",
    "#     'Spring': spring_24h_MX,\n",
    "#     'Summer': summer_24h_MX\n",
    "# }\n",
    "\n",
    "# # Mapping for easy iteration\n",
    "# seasonal_data = {\n",
    "#     'DD': seasonal_data_DD,\n",
    "#     'BB': seasonal_data_BB,\n",
    "#     'MX': seasonal_data_MX\n",
    "# }\n",
    "\n",
    "# data_type = ['LMP', 'FARM', 'IMP1F', 'IMP2F']\n",
    "# aerosols = ['DD','MX', 'BB']\n",
    "# colors = {\n",
    "#     'DD': '#f7b538',\n",
    "#     'BB': '#dd0426',\n",
    "#     'MX': '#798071'\n",
    "# }\n",
    "\n",
    "# # Loop through each subplot (season)\n",
    "# for i, season in enumerate(['Fall', 'Winter', 'Spring', 'Summer']):\n",
    "#     ax_i = ax.flat[i]\n",
    "    \n",
    "#     # Loop through each aerosol and data type for the current season\n",
    "#     for aerosol in aerosols:\n",
    "#         for j, data_column in enumerate(data_type):\n",
    "#             # Get the data for the aerosol and the season\n",
    "#             data_ = seasonal_data[aerosol][season][data_column]\n",
    "#             if np.any(np.isnan(data_)):\n",
    "#                 print(\"Data contains NaN values.\")\n",
    "#                 continue\n",
    "#             # Calculate bin width for histogram\n",
    "#             bin_width = (data_.max() - data_.min()) / np.sqrt(len(data_))\n",
    "#             if np.any(np.isnan(bin_width)) or bin_width == 0:\n",
    "#                 bin_width = 0.1\n",
    "#             else:\n",
    "#                 bins = np.arange(data_.min(), data_.max() + bin_width, bin_width)\n",
    "        \n",
    "#             # Plot histogram for the current aerosol and data type\n",
    "#         ax_i.hist(data_, bins=bins, color=colors[aerosol], label=f'{aerosol} - {data_column}', alpha=0.7, edgecolor='black')\n",
    "#         if (i == 2 or i == 3):\n",
    "#             ax_i.set_xlabel(r'$\\tau$', fontsize= 16)\n",
    "#         if (i == 0 or i == 2):\n",
    "#             ax_i.set_ylabel('Number of occurrences', fontweight= 'bold')\n",
    "    \n",
    "#     ax_i.set_title(f\"{season}\", fontweight= 'bold')\n",
    "#     ax_i.grid(True)\n",
    "\n",
    "# # Create a legend outside the subplots\n",
    "# fig.legend(aerosols, loc='upper center', ncol=len(aerosols), bbox_to_anchor=(0.5, 0.96))\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "# #plt.savefig(\"/home/andtoro/figure/histograms_DD_BB_MX_MODS_tau_season.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "\n",
    "# # Define the seasonal data dictionaries\n",
    "# seasonal_data_DD = {\n",
    "#     'Fall': fall_24h_DD,\n",
    "#     'Winter': winter_24h_DD,\n",
    "#     'Spring': spring_24h_DD,\n",
    "#     'Summer': summer_24h_DD\n",
    "# }\n",
    "\n",
    "# seasonal_data_BB = {\n",
    "#     'Fall': fall_24h_BB,\n",
    "#     'Winter': winter_24h_BB,\n",
    "#     'Spring': spring_24h_BB,\n",
    "#     'Summer': summer_24h_BB\n",
    "# }\n",
    "\n",
    "# seasonal_data_MX = {\n",
    "#     'Fall': fall_24h_MX,\n",
    "#     'Winter': winter_24h_MX,\n",
    "#     'Spring': spring_24h_MX,\n",
    "#     'Summer': summer_24h_MX\n",
    "# }\n",
    "\n",
    "# # Mapping for easy iteration\n",
    "# seasonal_data = {\n",
    "#     'DD': seasonal_data_DD,\n",
    "#     'BB': seasonal_data_BB,\n",
    "#     'MX': seasonal_data_MX\n",
    "# }\n",
    "\n",
    "# data_type = ['LMP', 'FARM', 'IMP1F', 'IMP2F']\n",
    "# aerosols = ['DD', 'MX', 'BB']\n",
    "\n",
    "# # Loop through each subplot (season)\n",
    "# for i, season in enumerate(['Fall', 'Winter', 'Spring', 'Summer']):\n",
    "#     ax_i = ax.flat[i]\n",
    "    \n",
    "#     # Loop through each aerosol and data type for the current season\n",
    "#     for aerosol in aerosols:\n",
    "#         # Get the data for the aerosol and the season\n",
    "#         data = seasonal_data[aerosol][season]['ang_440_870']\n",
    "#         if np.any(np.isnan(data)):\n",
    "#             print(\"Data contains NaN values.\")\n",
    "#             continue\n",
    "#         # Calculate bin width for histogram\n",
    "#         bin_width = (data.max() - data.min()) / np.sqrt(len(data))\n",
    "#         if np.any(np.isnan(bin_width)) or bin_width == 0:\n",
    "#             bin_width = 0.1\n",
    "#         else:\n",
    "#             bins = np.arange(data.min(), data.max() + bin_width, bin_width)\n",
    "        \n",
    "#         # Plot histogram for the current aerosol and data type\n",
    "#         ax_i.hist(data, bins=bins, color=colors[aerosol], label=f'{aerosol} - {data_column}', alpha=0.6, edgecolor='black')\n",
    "#         if (i == 2 or i == 3):\n",
    "#             ax_i.set_xlabel(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "#         if (i == 0 or i == 2):\n",
    "#             ax_i.set_ylabel('Number of occurrences', fontweight= 'bold')\n",
    "    \n",
    "#     ax_i.set_title(f\"{season}\", fontweight= 'bold')\n",
    "#     ax_i.grid(True)\n",
    "\n",
    "# # Create a legend outside the subplots\n",
    "# fig.legend(aerosols, loc='upper center', ncol=len(aerosols), bbox_to_anchor=(0.51, 0.96))\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "# #plt.savefig(\"/home/andtoro/project_enea/plot_final/histograms_DD_BB_MX_MODS_ang_season.pdf\", format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp_obs = Data['1D']['LMP']\n",
    "pred_farm = Data['1D']['FARM']\n",
    "pred_imp1f = Data['1D']['IMP1F']\n",
    "pred_imp2f = Data['1D']['IMP2F']\n",
    "\n",
    "index_obs = range(len(lmp_obs))\n",
    "errors_aod = Data['1D']['err_day_new']\n",
    "errors_farm = Data['1D']['errFarm_24']\n",
    "errors_imp1 = Data['1D']['err_IMP1_24']\n",
    "errors_imp2 = Data['1D']['err_IMP2_24']\n",
    "\n",
    "mean_obs = np.mean(lmp_obs)\n",
    "\n",
    "res_1 = (lmp_obs - pred_farm)\n",
    "res_2 = (lmp_obs - pred_imp1f)\n",
    "res_3 = (lmp_obs - pred_imp2f)\n",
    "\n",
    "res_1_mean = np.mean(res_1)\n",
    "res_2_mean = np.mean(res_2)\n",
    "res_3_mean = np.mean(res_3)\n",
    "\n",
    "def calculate_variance(residuals):\n",
    "    n = len(residuals)  # Number of observations\n",
    "    residuals_mean = np.mean(residuals)\n",
    "    variance = np.sum((residuals - residuals_mean)**2) / n\n",
    "    return variance\n",
    "\n",
    "var_1 = calculate_variance(res_1)\n",
    "var_2 = calculate_variance(res_2)\n",
    "var_3 = calculate_variance(res_3)\n",
    "\n",
    "err_1 = np.sqrt((errors_aod**2) + (errors_farm)**2)\n",
    "err_2 = np.sqrt((errors_aod**2) + (errors_imp1)**2)\n",
    "err_3 = np.sqrt((errors_aod**2) + (errors_imp2)**2)\n",
    "\n",
    "sigma_1 = np.sqrt(var_1)\n",
    "sigma_2 = np.sqrt(var_2)\n",
    "sigma_3 = np.sqrt(var_3)\n",
    "\n",
    "oBs = range(len(lmp_obs))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 8), sharex= True, sharey= True)\n",
    "\n",
    "#ax1.scatter(lmp_obs, res_1, color='#2e4057', s=10, label= f'$\\\\sigma_{{FARM}}: {sigma_1:.4f}$\\n$\\\\mu_{{LMP}}: {mean_obs:.4f}$')\n",
    "ax1.errorbar(lmp_obs, res_1, yerr= err_1, color='#2e4057', marker= 'o', markersize= 3, capsize= 5, linestyle= '')\n",
    "ax1.axhline(0, color='#f18f01', linestyle='--', linewidth=1.5)\n",
    "#ax1.set_xlabel('LMP',fontweight=\"bold\")\n",
    "ax1.set_ylabel('Residuals', fontweight=\"bold\")\n",
    "ax1.set_title('FARM',fontweight=\"bold\")\n",
    "ax1.grid(True)\n",
    "\n",
    "#ax2.scatter(lmp_obs, res_2, color='#2e4057', s=10, label= f'$\\\\sigma_{{IMP1F}}: {sigma_2:.4f}$')\n",
    "ax2.errorbar(lmp_obs, res_2, yerr= err_2, color='#2e4057', marker= 'o', markersize= 3, capsize= 5, linestyle= '')\n",
    "ax2.axhline(0, color='#f18f01', linestyle='--', linewidth=1.5)\n",
    "ax2.set_xlabel('LMP',fontweight=\"bold\")\n",
    "#ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('IMP1F',fontweight=\"bold\")\n",
    "ax2.grid(True)\n",
    "\n",
    "#ax3.scatter(lmp_obs, res_3, color='#2e4057', s=10, label= f'$\\\\sigma_{{IMP2F}}: {sigma_3:.4f}$')\n",
    "ax3.errorbar(lmp_obs, res_3, yerr= err_3, color='#2e4057', marker= 'o', markersize= 3, capsize= 5, linestyle= '')\n",
    "ax3.axhline(0, color='#f18f01', linestyle='--', linewidth=1.5)\n",
    "#ax3.set_xlabel('LMP',fontweight=\"bold\")\n",
    "#ax3.set_ylabel('Residuals')\n",
    "ax3.set_title('IMP2F',fontweight=\"bold\")\n",
    "ax3.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "plt.setp(ax1.get_xticklabels(), visible=True)\n",
    "plt.setp(ax2.get_xticklabels(), visible=True)\n",
    "plt.setp(ax3.get_xticklabels(), visible=True)\n",
    "\n",
    "plt.setp(ax1.get_yticklabels(), visible=True)\n",
    "plt.setp(ax2.get_yticklabels(), visible=True)\n",
    "plt.setp(ax3.get_yticklabels(), visible=True)\n",
    "\n",
    "#plt.savefig(\"/home/andtoro/figure/residuals.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 8), sharex= True, sharey= True)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    axes = axes.ravel()\n",
    "    res = eval(f'res_{i}')\n",
    "    counts, bin_edges = np.histogram(res, bins=20)\n",
    "    normalized_counts = counts / np.sum(counts)\n",
    "\n",
    "    axes[i-1].bar(bin_edges[:-1], normalized_counts, width=np.diff(bin_edges), color='#4a2545', edgecolor='black')\n",
    "\n",
    "    if i == 1:\n",
    "        axes[i-1].set_xlabel('Error Values for FARM ')\n",
    "    elif i == 2: \n",
    "        axes[i-1].set_xlabel('Error Values for IMP1F')\n",
    "    elif i == 3: \n",
    "        axes[i-1].set_xlabel('Error Values for IMP2F')\n",
    "    \n",
    "    axes[i-1].set_ylabel('Normalized Frequency')\n",
    "    axes[i-1].set_title('Histogram of Errors')\n",
    "    axes[i-1].grid(True)\n",
    "    axes[i-1].tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "    #axes[i-1].axis('off')\n",
    "\n",
    "#if len(axes) > 3:\n",
    "    #fig.delaxes(axes[3])\n",
    "plt.setp(axes[0].get_xticklabels(), visible=True)\n",
    "plt.setp(axes[1].get_xticklabels(), visible=True) \n",
    "plt.setp(axes[2].get_xticklabels(), visible=True)\n",
    "plt.setp(axes[0].get_yticklabels(), visible=True)\n",
    "plt.setp(axes[1].get_yticklabels(), visible=True) \n",
    "plt.setp(axes[2].get_yticklabels(), visible=True)\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "imp1odr = Data['1D']['IMP1F_ODR']\n",
    "imp2odr = Data['1D']['IMP2F_ODR']\n",
    "imp1ns = Data['1D']['IMP1F_NS']\n",
    "imp2ns = Data['1D']['IMP2F_NS']\n",
    "\n",
    "# Compute residuals\n",
    "res_1 = lmp_obs - pred_farm\n",
    "res_2 = lmp_obs - pred_imp1f\n",
    "res_3 = lmp_obs - pred_imp2f\n",
    "\n",
    "# Compute errors\n",
    "err_1 = np.sqrt(errors_aod**2 + errors_farm**2)\n",
    "err_2 = np.sqrt(errors_aod**2 + errors_imp1**2)\n",
    "err_3 = np.sqrt(errors_aod**2 + errors_imp2**2)\n",
    "\n",
    "# Set up figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# Define plot settings\n",
    "models = [\"FARM\", \"IMP1F\", \"IMP2F\"]\n",
    "residuals = [res_1, res_2, res_3]\n",
    "errors = [err_1, err_2, err_3]\n",
    "colors = ['#050505', '#3f88c5', '#157f1f']  # Blue, Orange, Green\n",
    "\n",
    "for ax, model, res, err, color in zip(axes, models, residuals, errors, colors):\n",
    "    ax.errorbar(lmp_obs, res, yerr=err, fmt='o', color=color, alpha=0.7, capsize=4)\n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=1.2, alpha=0.8)\n",
    "    \n",
    "    ax.set_title(model, fontweight=\"bold\", fontsize=13)\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "\n",
    "# Shared labels\n",
    "axes[1].set_xlabel(f\"{name_save_fig} (Observed)\", fontweight=\"bold\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Residuals\", fontweight=\"bold\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_fig:\n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure/{name_save_fig}_res_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot between models with statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs = Data['1D']['LMP'].to_numpy()\n",
    "data_farm = Data['1D']['FARM'].to_numpy()\n",
    "data_imp1f = Data['1D']['IMP1F'].to_numpy()\n",
    "data_imp2f = Data['1D']['IMP2F'].to_numpy()\n",
    "data_imp1f_odr = Data['1D']['IMP1F_ODR'].to_numpy()\n",
    "data_imp2f_odr = Data['1D']['IMP2F_ODR'].to_numpy()\n",
    "data_imp1f_ns = Data['1D']['IMP1F_NS'].to_numpy()\n",
    "data_imp2f_ns = Data['1D']['IMP2F_NS'].to_numpy()\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Calculate Bias\n",
    "    bias = np.mean(y_true - y_pred)\n",
    "\n",
    "    # Calculate Correlation\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "    # Calculate NMSE\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    var_y = np.var(y_true)\n",
    "    #nmse = mse / var_y if var_y != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "    # Calculate Variance\n",
    "    variance = var_y\n",
    "    return bias, corr, rmse, variance, mse\n",
    "\n",
    "# Calculate metrics for each comparison\n",
    "metrics_farm = calculate_metrics(data_obs, data_farm)\n",
    "metrics_imp1f = calculate_metrics(data_obs, data_imp1f)\n",
    "metrics_imp2f = calculate_metrics(data_obs, data_imp2f)\n",
    "metrics_imp1f_odr = calculate_metrics(data_obs, data_imp1f_odr)\n",
    "metrics_imp2f_odr = calculate_metrics(data_obs, data_imp2f_odr)\n",
    "metrics_imp1f_ns = calculate_metrics(data_obs, data_imp1f_ns)\n",
    "metrics_imp2f_ns = calculate_metrics(data_obs, data_imp2f_ns)\n",
    "\n",
    "# Print the results\n",
    "print(\"Metrics for AOD (FARM):\")\n",
    "print(f'Bias: {metrics_farm[0]}, Correlation: {metrics_farm[1]}, RMSE: {metrics_farm[2]}, Variance: {metrics_farm[3]}, N: {len(data_obs)}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP1F):\")\n",
    "print(f'Bias: {metrics_imp1f[0]}, Correlation: {metrics_imp1f[1]}, RMSE: {metrics_imp1f[2]}, Variance: {metrics_imp1f[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP2F):\")\n",
    "print(f'Bias: {metrics_imp2f[0]}, Correlation: {metrics_imp2f[1]}, RMSE: {metrics_imp2f[2]}, Variance: {metrics_imp2f[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP1F_ODR):\")\n",
    "print(f'Bias: {metrics_imp1f_odr[0]}, Correlation: {metrics_imp1f_odr[1]}, RMSE: {metrics_imp1f_odr[2]}, Variance: {metrics_imp1f_odr[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP2F_ODR):\")\n",
    "print(f'Bias: {metrics_imp2f_odr[0]}, Correlation: {metrics_imp2f_odr[1]}, RMSE: {metrics_imp2f_odr[2]}, Variance: {metrics_imp2f_odr[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP1F_NS):\")\n",
    "print(f'Bias: {metrics_imp1f_ns[0]}, Correlation: {metrics_imp1f_ns[1]}, RMSE: {metrics_imp1f_ns[2]}, Variance: {metrics_imp1f_ns[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP2F_NS):\")\n",
    "print(f'Bias: {metrics_imp2f_ns[0]}, Correlation: {metrics_imp2f_ns[1]}, RMSE: {metrics_imp2f_ns[2]}, Variance: {metrics_imp2f_ns[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "data_obs = Data['1D']['LMP'].to_numpy()\n",
    "data_farm = Data['1D']['FARM'].to_numpy()\n",
    "data_imp1f = Data['1D']['IMP1F'].to_numpy()\n",
    "data_imp2f = Data['1D']['IMP2F'].to_numpy()\n",
    "data_imp1f_odr = Data['1D']['IMP1F_ODR'].to_numpy()\n",
    "data_imp2f_odr = Data['1D']['IMP2F_ODR'].to_numpy()\n",
    "data_imp1f_ns = Data['1D']['IMP1F_NS'].to_numpy()\n",
    "data_imp2f_ns = Data['1D']['IMP2F_NS'].to_numpy()\n",
    "\n",
    "data_dd = DeDu24['LMP'].to_numpy()\n",
    "data_farm_dd = DeDu24['FARM'].to_numpy()\n",
    "data_imp2f_odr_dd = DeDu24['IMP2F_ODR'].to_numpy()\n",
    "data_imp2f_ns_dd = DeDu24['IMP2F_NS'].to_numpy()\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, n, p):\n",
    "    # Calculate Bias\n",
    "    bias = np.mean(y_true - y_pred)\n",
    "\n",
    "    # Calculate Correlation\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "    # Calculate Variance\n",
    "    variance = np.var(y_true)\n",
    "\n",
    "    # Calculate R² (Coefficient of Determination)\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)  # Total Sum of Squares (TSS)\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)  # Residual Sum of Squares (RSS)\n",
    "    r2 = 1 - (ss_residual / ss_total) if ss_total != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "    # Calculate Adjusted R²\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1)) if n > p + 1 else np.nan  # Avoid invalid adjustment\n",
    "\n",
    "    return bias, corr, rmse, variance, r2, adjusted_r2\n",
    "\n",
    "# Define number of observations (n) and number of parameters (p)\n",
    "n = len(data_obs)  # 49 data points\n",
    "p = 2  # Two parameters in the regression model\n",
    "\n",
    "n_d = len(data_dd)\n",
    "\n",
    "# Calculate metrics for each comparison\n",
    "metrics_farm = calculate_metrics(data_obs, data_farm, n, p)\n",
    "metrics_imp1f = calculate_metrics(data_obs, data_imp1f, n, p)\n",
    "metrics_imp2f = calculate_metrics(data_obs, data_imp2f, n, p)\n",
    "metrics_imp1f_odr = calculate_metrics(data_obs, data_imp1f_odr, n, p)\n",
    "metrics_imp2f_odr = calculate_metrics(data_obs, data_imp2f_odr, n, p)\n",
    "metrics_imp1f_ns = calculate_metrics(data_obs, data_imp1f_ns, n, p)\n",
    "metrics_imp2f_ns = calculate_metrics(data_obs, data_imp2f_ns, n, p)\n",
    "\n",
    "metrics_imp2fodr_dd = calculate_metrics(data_dd, data_imp2f_odr_dd, n_d, p)\n",
    "metrics_imp2fns_dd = calculate_metrics(data_dd, data_imp2f_ns_dd, n_d, p)\n",
    "metrics_farm_dd = calculate_metrics(data_dd, data_farm_dd, n_d, p)\n",
    "\n",
    "# Print the results\n",
    "def print_metrics(name, metrics):\n",
    "    print(f\"\\nMetrics for AOD ({name}):\")\n",
    "    print(f'Bias: {metrics[0]:.4f}, Correlation: {metrics[1]:.4f}, RMSE: {metrics[2]:.4f}, '\n",
    "          f'Variance: {metrics[3]:.4f}, R²: {metrics[4]:.4f}, Adjusted R²: {metrics[5]:.4f}, N: {n}')\n",
    "\n",
    "print_metrics(\"FARM\", metrics_farm)\n",
    "print_metrics(\"IMP1F\", metrics_imp1f)\n",
    "print_metrics(\"IMP2F\", metrics_imp2f)\n",
    "print_metrics(\"IMP1F_ODR\", metrics_imp1f_odr)\n",
    "print_metrics(\"IMP2F_ODR\", metrics_imp2f_odr)\n",
    "print_metrics(\"IMP1F_NS\", metrics_imp1f_ns)\n",
    "print_metrics(\"IMP2F_NS\", metrics_imp2f_ns)\n",
    "print_metrics(\"asa\", metrics_farm_dd)\n",
    "\n",
    "print(len(data_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separato\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize= (18, 8), sharex= True, sharey= True)\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(dato1.max(), dato2.max())\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(Data['1D']['LMP'], Data['1D']['FARM'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "# ax1.set_xlabel(r'OBS', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'FARM', fontweight= 'bold')\n",
    "bisec(ax1, Data['1D']['LMP'], Data['1D']['FARM'])\n",
    "ax1.set_xlim(left= 0)\n",
    "ax1.set_ylim(bottom= 0)\n",
    "ax1.legend([f'Bias: {metrics_farm[0]:.3f}\\nCorr: {metrics_farm[1]:.3f}\\nRMSE: {metrics_farm[2]:.3f}\\n R2: {metrics_farm[4]:.3f}']) \n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(Data['1D']['LMP'], Data['1D']['IMP1F'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax2.set_xlabel(rf'OBS({name_save_fig})', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP1F', fontweight= 'bold')\n",
    "bisec(ax2, Data['1D']['LMP'], Data['1D']['IMP1F'])\n",
    "ax2.set_xlim(left= 0)\n",
    "ax2.set_ylim(bottom= 0)\n",
    "ax2.legend([f'Bias: {metrics_imp1f[0]:.3f}\\nCorr: {metrics_imp1f[1]:.3f}\\nRMSE: {metrics_imp1f[2]:.3f}\\n R2: {metrics_imp1f[4]:.3f}'])\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.scatter(Data['1D']['LMP'], Data['1D']['IMP2F'], c= Data['1D']['ang_440_870'], s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "# ax3.set_xlabel(r'OBS', fontweight= 'bold')\n",
    "ax3.set_ylabel(r'IMP2F', fontweight= 'bold')\n",
    "bisec(ax3, Data['1D']['LMP'], Data['1D']['IMP2F'])\n",
    "ax3.set_xlim(left= 0,  right= 1.2)\n",
    "ax3.set_ylim(bottom= 0, top= 1.2)\n",
    "ax3.legend([f'Bias: {metrics_imp2f[0]:.3f}\\nCorr: {metrics_imp2f[1]:.3f}\\nRMSE: {metrics_imp2f[2]:.3f}\\nR2: {metrics_imp2f[4]:.3f}'])\n",
    "ax3.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=Data['1D']['ang_440_870'].min(), vmax=Data['1D']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2, ax3], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "if save_fig: \n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure/scatter_plot_{name_save_fig}_imp1_imp2_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confronto tra FARM e IMPROVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separato\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (18, 8), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(dato1.max(), dato2.max())\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(Data['1D']['FARM'], Data['1D']['IMP1F'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax1.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'IMP1F', fontweight= 'bold')\n",
    "bisec(ax1, Data['1D']['FARM'], Data['1D']['IMP1F'])\n",
    "ax1.set_xlim(left= 0)\n",
    "ax1.set_ylim(bottom= 0)\n",
    "ax1.legend([f'FARM-IMP1F']) \n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(Data['1D']['FARM'], Data['1D']['IMP2F'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax2.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP2F', fontweight= 'bold')\n",
    "bisec(ax2, Data['1D']['FARM'], Data['1D']['IMP2F'])\n",
    "ax2.set_xlim(left= 0)\n",
    "ax2.set_ylim(bottom= 0)\n",
    "ax2.legend([f'FARM-IMP2F'])\n",
    "ax2.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=Data['1D']['ang_440_870'].min(), vmax=Data['1D']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "#plt.savefig('/home/andtoro/figure/scatter_FARM_IMP1F_IMP2F.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confrontro tra FARM e IMPROVE con i nuovi coefficienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separato\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (18, 8), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(dato1.max(), dato2.max())\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(Data['1D']['FARM'], Data['1D']['IMP1F_ODR'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax1.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'IMP1F_ODR', fontweight= 'bold')\n",
    "bisec(ax1, Data['1D']['FARM'], Data['1D']['IMP1F_ODR'])\n",
    "ax1.set_xlim(left= 0)\n",
    "ax1.set_ylim(bottom= 0)\n",
    "ax1.legend([f'FARM-IMP1F_ODR']) \n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(Data['1D']['FARM'], Data['1D']['IMP2F_ODR'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax2.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP2F_ODR', fontweight= 'bold')\n",
    "bisec(ax2, Data['1D']['FARM'], Data['1D']['IMP2F_ODR'])\n",
    "ax2.set_xlim(left= 0)\n",
    "ax2.set_ylim(bottom= 0)\n",
    "ax2.legend([f'FARM-IMP2F_ODR'])\n",
    "ax2.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=Data['1D']['ang_440_870'].min(), vmax=Data['1D']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "if save_fig: \n",
    "    plt.savefig(f'/home/andrea/enea_project/lmp_dust_enea/figure/{name_save_fig}_farm_imp_odr_full.png', format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separato\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (18, 8), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(dato1.max(), dato2.max())\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(Data['1D']['FARM'], Data['1D']['IMP1F_NS'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax1.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'IMP1F_NS', fontweight= 'bold')\n",
    "bisec(ax1, Data['1D']['FARM'], Data['1D']['IMP1F_NS'])\n",
    "ax1.set_xlim(left= 0)\n",
    "ax1.set_ylim(bottom= 0)\n",
    "ax1.legend([f'FARM-IMP1F_NS']) \n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(Data['1D']['FARM'], Data['1D']['IMP2F_NS'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax2.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP2F_NS', fontweight= 'bold')\n",
    "bisec(ax2, Data['1D']['FARM'], Data['1D']['IMP2F_NS'])\n",
    "ax2.set_xlim(left= 0)\n",
    "ax2.set_ylim(bottom= 0)\n",
    "ax2.legend([f'FARM-IMP2F_NS'])\n",
    "ax2.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=Data['1D']['ang_440_870'].min(), vmax=Data['1D']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "if save_fig:\n",
    "    plt.savefig(f'/home/andrea/enea_project/lmp_dust_enea/figure/{name_save_fig}_farm_imp_ns_full.png', format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separato\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize= (18, 8), sharex= True, sharey= True)\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(max(dato1), max(dato2))\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(Data['1D']['LMP'], Data['1D']['FARM'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "# ax1.set_xlabel(r'OBS', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'FARM', fontweight= 'bold')\n",
    "bisec(ax1, Data['1D']['LMP'], Data['1D']['FARM'])\n",
    "ax1.set_xlim(left= 0, right= 1.6)\n",
    "ax1.set_ylim(bottom= 0, top= 1.6)\n",
    "ax1.legend([f'Bias: {metrics_farm[0]:.3f}\\nCorr: {metrics_farm[1]:.3f}\\nRMSE: {metrics_farm[2]:.3f}\\nR2: {metrics_farm[4]:.3f}'], loc= 'lower right')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(Data['1D']['LMP'], Data['1D']['IMP1F_ODR'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "\n",
    "ax2.set_xlabel(fr'OBS({name_save_fig})', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP1F_ODR', fontweight= 'bold')\n",
    "bisec(ax2, Data['1D']['LMP'], Data['1D']['IMP1F_ODR'])\n",
    "ax2.set_xlim(left= 0, right= 1.6)\n",
    "ax2.set_ylim(bottom= 0, top= 1.6)\n",
    "ax2.legend([f'Bias: {metrics_imp1f_odr[0]:.3f}\\nCorr: {metrics_imp1f_odr[1]:.3f}\\nRMSE: {metrics_imp1f_odr[2]:.3f}\\nR2: {metrics_imp1f_odr[4]:.3f}'], loc= 'lower right')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.scatter(Data['1D']['LMP'], Data['1D']['IMP2F_ODR'], c= Data['1D']['ang_440_870'], s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "# ax3.set_xlabel(r'OBS', fontweight= 'bold')\n",
    "ax3.set_ylabel(r'IMP2F_ODR', fontweight= 'bold')\n",
    "bisec(ax3, Data['1D']['LMP'], Data['1D']['IMP2F_ODR'])\n",
    "ax3.set_xlim(left= 0, right= 1.5)\n",
    "ax3.set_ylim(bottom= 0, top= 1.5)\n",
    "ax3.legend([f'Bias: {metrics_imp2f_odr[0]:.3f}\\nCorr: {metrics_imp2f_odr[1]:.3f}\\nRMSE: {metrics_imp2f_odr[2]:.3f}\\nR2: {metrics_imp2f_odr[4]:.3f}'], loc= 'lower right')\n",
    "ax3.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=Data['1D']['ang_440_870'].min(), vmax=Data['1D']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2, ax3], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "if save_fig: \n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure/scatter_plot_{name_save_fig}_imp1_imp2_odr_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separato\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize= (18, 8), sharex= True, sharey= True)\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(max(dato1), max(dato2))\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(Data['1D']['LMP'], Data['1D']['FARM'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "# ax1.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'FARM', fontweight= 'bold')\n",
    "bisec(ax1, Data['1D']['LMP'], Data['1D']['FARM'])\n",
    "ax1.set_xlim(left= 0, right= 1.6)\n",
    "ax1.set_ylim(bottom= 0, top= 1.6)\n",
    "ax1.legend([f'LMP-FARM\\nBias: {metrics_farm[0]:.3f}\\nCorr: {metrics_farm[1]:.3f}\\nRMSE: {metrics_farm[2]:.3f}\\nR2: {metrics_farm[4]:.3f}'], loc= 'lower right')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(Data['1D']['LMP'], Data['1D']['IMP1F_NS'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "\n",
    "ax2.set_xlabel(rf'OBS({name_save_fig})', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP1F_NS', fontweight= 'bold')\n",
    "bisec(ax2, Data['1D']['LMP'], Data['1D']['IMP1F_NS'])\n",
    "ax2.set_xlim(left= 0, right= 1.6)\n",
    "ax2.set_ylim(bottom= 0, top= 1.6)\n",
    "ax2.legend([f'LMP-IMP1F\\nBias: {metrics_imp1f_ns[0]:.3f}\\nCorr: {metrics_imp1f_ns[1]:.3f}\\nRMSE: {metrics_imp1f_ns[2]:.3f}\\nR2: {metrics_imp1f_ns[4]:.3f}'], loc= 'lower right')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.scatter(Data['1D']['LMP'], Data['1D']['IMP2F_NS'], c= Data['1D']['ang_440_870'], s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "# ax3.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax3.set_ylabel(r'IMP2F_NS', fontweight= 'bold')\n",
    "bisec(ax3, Data['1D']['LMP'], Data['1D']['IMP2F_NS'])\n",
    "ax3.set_xlim(left= 0, right= 1.5)\n",
    "ax3.set_ylim(bottom= 0, top= 1.5)\n",
    "ax3.legend([f'LMP-IMP2F\\nBias: {metrics_imp2f_ns[0]:.3f}\\nCorr: {metrics_imp2f_ns[1]:.3f}\\nRMSE: {metrics_imp2f_ns[2]:.3f}\\nR2: {metrics_imp2f_ns[4]:.3f}'], loc= 'lower right')\n",
    "ax3.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=Data['1D']['ang_440_870'].min(), vmax=Data['1D']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2, ax3], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "if save_fig: \n",
    "    plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure/scatter_plot_{name_save_fig}_imp1_imp2_ns_full.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals FARM, IMP2F_ODR, IMP2F_NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separato\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize= (18, 8), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(max(dato1), max(dato2))\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(Data['1D']['LMP'], Data['1D']['FARM'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax1.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'FARM', fontweight= 'bold')\n",
    "bisec(ax1, Data['1D']['LMP'], Data['1D']['FARM'])\n",
    "ax1.set_xlim(left= 0, right= 1.6)\n",
    "ax1.set_ylim(bottom= 0, top= 1.6)\n",
    "ax1.legend([f'LMP-FARM\\nBias: {metrics_farm[0]:.3f}\\nCorr: {metrics_farm[1]:.3f}\\nRMSE: {metrics_farm[2]:.3f}\\nR2: {metrics_farm[4]:.3f}'], loc= 'lower right')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(Data['1D']['LMP'], Data['1D']['IMP2F_ODR'], c= Data['1D']['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "\n",
    "ax2.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP2F_ODR', fontweight= 'bold')\n",
    "bisec(ax2, Data['1D']['LMP'], Data['1D']['IMP2F_ODR'])\n",
    "ax2.set_xlim(left= 0, right= 1.6)\n",
    "ax2.set_ylim(bottom= 0, top= 1.6)\n",
    "ax2.legend([f'LMP-IMP2F\\nBias: {metrics_imp2f_odr[0]:.3f}\\nCorr: {metrics_imp2f_odr[1]:.3f}\\nRMSE: {metrics_imp2f_odr[2]:.3f}\\nR2: {metrics_imp2f_odr[4]:.3f}'], loc= 'lower right')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.scatter(Data['1D']['LMP'], Data['1D']['IMP2F_NS'], c= Data['1D']['ang_440_870'], s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax3.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax3.set_ylabel(r'IMP2F_NS', fontweight= 'bold')\n",
    "bisec(ax3, Data['1D']['LMP'], Data['1D']['IMP2F_NS'])\n",
    "ax3.set_xlim(left= 0, right= 1.75)\n",
    "ax3.set_ylim(bottom= 0, top= 1.75)\n",
    "ax3.legend([f'LMP-IMP2F\\nBias: {metrics_imp2f_ns[0]:.3f}\\nCorr: {metrics_imp2f_ns[1]:.3f}\\nRMSE: {metrics_imp2f_ns[2]:.3f}\\nR2: {metrics_imp2f_ns[4]:.3f}'], loc= 'lower right')\n",
    "ax3.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=Data['1D']['ang_440_870'].min(), vmax=Data['1D']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2, ax3], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "#plt.savefig('/home/andtoro/figure/scatter_FARM_IMP2Fodr_IMP2Fns.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plot new coefficients on DD data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_new_coef = pd.merge(DeDu24, df_daylight_50, on='time', how='inner')\n",
    "# Filter DeDu24 based on the 'time' values in df_daylight_50\n",
    "filtered_DeDu24 = DeDu24[DeDu24['time'].isin(df_daylight_50['time'])]\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, n, p):\n",
    "    # Calculate Bias\n",
    "    bias = np.mean(y_true - y_pred)\n",
    "\n",
    "    # Calculate Correlation\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "    # Calculate Variance\n",
    "    variance = np.var(y_true)\n",
    "\n",
    "    # Calculate R² (Coefficient of Determination)\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)  # Total Sum of Squares (TSS)\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)  # Residual Sum of Squares (RSS)\n",
    "    r2 = 1 - (ss_residual / ss_total) if ss_total != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "    # Calculate Adjusted R²\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1)) if n > p + 1 else np.nan  # Avoid invalid adjustment\n",
    "\n",
    "    return bias, corr, rmse, variance, r2, adjusted_r2\n",
    "\n",
    "data_F = filtered_DeDu24['LMP']\n",
    "FarmF = calculate_metrics(data_F, filtered_DeDu24['FARM'], len(data_F), 2)\n",
    "Imp2fOdr = calculate_metrics(data_F, filtered_DeDu24['IMP2F_ODR'], len(data_F), 2)\n",
    "Imp2fNs = calculate_metrics(data_F, filtered_DeDu24['IMP2F_NS'], len(data_F), 2)\n",
    "\n",
    "# plot separato\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize= (18, 8), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(max(dato1), max(dato2))\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(data_F, filtered_DeDu24['FARM'], c= filtered_DeDu24['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax1.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'FARM', fontweight= 'bold')\n",
    "bisec(ax1, data_F, farm_DD)\n",
    "ax1.set_xlim(left= 0, right= 1.6)\n",
    "ax1.set_ylim(bottom= 0, top= 1.6)\n",
    "ax1.legend([f'LMP-FARM\\nBias: {FarmF[0]:.3f}\\nCorr: {FarmF[1]:.3f}\\nRMSE: {FarmF[2]:.3f}\\nR2: {FarmF[4]:.3f}'], loc= 'upper right')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(data_F, filtered_DeDu24['IMP2F_ODR'], c= filtered_DeDu24['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "\n",
    "ax2.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP2F_ODR', fontweight= 'bold')\n",
    "bisec(ax2, data_F, filtered_DeDu24['IMP2F_ODR'])\n",
    "ax2.set_xlim(left= 0, right= 1.6)\n",
    "ax2.set_ylim(bottom= 0, top= 1.6)\n",
    "ax2.legend([f'LMP-IMP2F\\nBias: {Imp2fOdr[0]:.3f}\\nCorr: {Imp2fOdr[1]:.3f}\\nRMSE: {Imp2fOdr[2]:.3f}\\nR2: {Imp2fOdr[4]:.3f}'], loc= 'upper right')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.scatter(data_F, filtered_DeDu24['IMP2F_NS'], c= filtered_DeDu24['ang_440_870'], s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax3.set_xlabel(r'LMP', fontweight= 'bold')\n",
    "ax3.set_ylabel(r'IMP2F_NS', fontweight= 'bold')\n",
    "bisec(ax3, data_F, filtered_DeDu24['IMP2F_NS'])\n",
    "ax3.set_xlim(left= 0, right= 1.0)\n",
    "ax3.set_ylim(bottom= 0, top= 1.0)\n",
    "ax3.legend([f'LMP-IMP2F\\nBias: {Imp2fNs[0]:.3f}\\nCorr: {Imp2fNs[1]:.3f}\\nRMSE: {Imp2fNs[2]:.3f}\\nR2: {Imp2fNs[4]:.3f}'], loc= 'upper right')\n",
    "ax3.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=filtered_DeDu24['ang_440_870'].min(), vmax=filtered_DeDu24['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2, ax3], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "#plt.savefig('/home/andtoro/figure/scatter_FARM_IMP2Fodr_IMP2Fns_DD.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_new_coef = pd.merge(DeDu24, df_daylight_50, on='time', how='inner')\n",
    "# Filter DeDu24 based on the 'time' values in df_daylight_50\n",
    "filtered_DeDu24 = DeDu24[DeDu24['time'].isin(df_daylight_50['time'])]\n",
    "\n",
    "data_F = filtered_DeDu24['LMP']\n",
    "FarmF = calculate_metrics(data_F, filtered_DeDu24['FARM'], len(data_F), 2)\n",
    "Imp2fOdr = calculate_metrics(data_F, filtered_DeDu24['IMP2F_ODR'], len(data_F), 2)\n",
    "Imp2fNs = calculate_metrics(data_F, filtered_DeDu24['IMP2F_NS'], len(data_F), 2)\n",
    "\n",
    "# plot separato\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (18, 8), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(max(dato1), max(dato2))\n",
    "    \n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    \n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(filtered_DeDu24['FARM'], filtered_DeDu24['IMP1F'], c= filtered_DeDu24['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "ax1.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax1.set_ylabel(r'IMP1F', fontweight= 'bold')\n",
    "bisec(ax1, farm_DD, filtered_DeDu24['IMP1F'])\n",
    "ax1.set_xlim(left= 0, right= 1.6)\n",
    "ax1.set_ylim(bottom= 0, top= 1.6)\n",
    "ax1.legend([f'FARM-IMP1F'], loc= 'upper right')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(filtered_DeDu24['FARM'], filtered_DeDu24['IMP2F'], c= filtered_DeDu24['ang_440_870'],  s= 10, cmap= 'plasma_r', marker= 'o')\n",
    "\n",
    "ax2.set_xlabel(r'FARM', fontweight= 'bold')\n",
    "ax2.set_ylabel(r'IMP2F', fontweight= 'bold')\n",
    "bisec(ax2, farm_DD, filtered_DeDu24['IMP2F'])\n",
    "ax2.set_xlim(left= 0, right= 1.6)\n",
    "ax2.set_ylim(bottom= 0, top= 1.6)\n",
    "ax2.legend([f'FARM-IMP2F'], loc= 'upper right')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "#fig.delaxes(ax4)\n",
    "norm_1 = mcolors.Normalize(vmin=filtered_DeDu24['ang_440_870'].min(), vmax=filtered_DeDu24['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='plasma_r'), ax=[ax1, ax2], orientation='horizontal', fraction=0.05, pad=0.08, location= 'bottom')\n",
    "cbar_1.set_label(r'$\\alpha_{(440-870)nm}$', fontsize= 16)\n",
    "\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "#plt.savefig('/home/andtoro/figure/scatter_FARM_IMP1F_IMP2F_DD.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot for each sub-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_DD = DeDu24['LMP']\n",
    "obs_BB = BioBu24['LMP']\n",
    "obs_MX = Mix24['LMP']\n",
    "farm_DD = DeDu24['FARM']\n",
    "farm_BB = BioBu24['FARM']\n",
    "farm_MX = Mix24['FARM']\n",
    "imp1_DD = DeDu24['IMP1F']\n",
    "imp1_BB = BioBu24['IMP1F']\n",
    "imp1_MX = Mix24['IMP1F']\n",
    "imp2_DD = DeDu24['IMP2F']\n",
    "imp2_BB = BioBu24['IMP2F']\n",
    "imp2_MX = Mix24['IMP2F']\n",
    "\n",
    "colors = {\n",
    "    'DD': '#f7b538',\n",
    "    'BB': '#8c001a',\n",
    "    'MX': '#c2c5bb'\n",
    "}\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize= (12, 12), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(dato1.max(), dato2.max())\n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "ax4.set_aspect('equal', adjustable='box')\n",
    "ax5.set_aspect('equal', adjustable='box')\n",
    "ax6.set_aspect('equal', adjustable='box')\n",
    "ax7.set_aspect('equal', adjustable='box')\n",
    "ax8.set_aspect('equal', adjustable='box')\n",
    "ax9.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(obs_DD, farm_DD, c=colors['DD'], s=10, marker='o', alpha= 0.7)\n",
    "ax1.grid(True)\n",
    "ax1.set_title('FARM', fontweight= 'bold')\n",
    "#ax1.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax1.set_ylabel(r'$\\tau_{FARM}$', fontsize= 16)\n",
    "ax1.legend([f'Bias: {metrics_farm_DD[0]:.3f}\\nCorr: {metrics_farm_DD[1]:.3f}\\nRMSE: {metrics_farm_DD[2]:.3f}'], loc= 'upper right')\n",
    "bisec(ax1, obs_DD, farm_DD)\n",
    "\n",
    "ax2.scatter(obs_DD, imp1_DD, c=colors['DD'], s=10, marker='o', alpha= 0.7)\n",
    "ax2.grid(True)\n",
    "ax2.set_title('IMP1F', fontweight= 'bold')\n",
    "#ax2.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax2.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "ax2.legend([f'Bias: {metrics_imp1f_DD[0]:.3f}\\nCorr: {metrics_imp1f_DD[1]:.3f}\\nRMSE: {metrics_imp1f_DD[2]:.3f}'], loc= 'upper right')\n",
    "bisec(ax2, obs_DD, farm_DD)\n",
    "\n",
    "ax3.scatter(obs_DD, imp2_DD, c=colors['DD'], s=10, marker='o', alpha= 0.7)\n",
    "ax3.grid(True)\n",
    "ax3.set_title('IMP2F', fontweight= 'bold')\n",
    "#ax3.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax3.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "ax3.legend([f'Bias: {metrics_imp2f_DD[0]:.3f}\\nCorr: {metrics_imp2f_DD[1]:.3f}\\nRMSE: {metrics_imp2f_DD[2]:.3f}'], loc= 'upper right')\n",
    "bisec(ax3, obs_DD, farm_DD)\n",
    "ax3.text(1.05, 0.5, f'#DD={len(obs_DD)}', transform=ax3.transAxes, fontweight= 'bold', fontsize=12, color= colors['DD'], verticalalignment='center', horizontalalignment='left', rotation=90)\n",
    "\n",
    "ax4.scatter(obs_BB, farm_BB, c=colors['BB'], s=10, marker='o', alpha= 0.7)\n",
    "ax4.grid(True)\n",
    "#ax4.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "ax4.set_ylabel(r'$\\tau_{MOD}$', fontsize= 16)\n",
    "ax4.legend([f'Bias: {metrics_farm_BB[0]:.3f}\\nCorr: {metrics_farm_BB[1]:.3f}\\nRMSE: {metrics_farm_BB[2]:.3f}'], loc= 'best')\n",
    "bisec(ax4, obs_BB, farm_BB)\n",
    "\n",
    "ax5.scatter(obs_BB, imp1_BB, c=colors['BB'], s=10, marker='o', alpha= 0.7)\n",
    "ax5.grid(True)\n",
    "#ax5.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax5.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "ax5.legend([f'Bias: {metrics_imp1f_BB[0]:.3f}\\nCorr: {metrics_imp1f_BB[1]:.3f}\\nRMSE: {metrics_imp1f_BB[2]:.3f}'], loc= 'best')\n",
    "bisec(ax5, obs_BB, imp1_BB)\n",
    "\n",
    "ax6.scatter(obs_BB, imp2_BB, c=colors['BB'], s=10, marker='o', alpha= 0.7)\n",
    "ax6.grid(True)\n",
    "#ax6.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax6.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "ax6.legend([f'Bias: {metrics_imp2f_BB[0]:.3f}\\nCorr: {metrics_imp2f_BB[1]:.3f}\\nRMSE: {metrics_imp2f_BB[2]:.3f}'], loc= 'best')\n",
    "bisec(ax6, obs_BB, imp2_BB)\n",
    "ax6.text(1.05, 0.5, f'#BB={len(obs_BB)}', transform=ax6.transAxes, fontweight= 'bold', fontsize=12, color= colors['BB'], verticalalignment='center', horizontalalignment='left', rotation=90)\n",
    "\n",
    "ax7.scatter(obs_MX, farm_MX, c=colors['MX'], s=10, marker='o', alpha= 0.7)\n",
    "ax7.grid(True)\n",
    "#ax7.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax7.set_ylabel(r'$\\tau_{FARM}$', fontsize= 16)\n",
    "ax7.legend([f'Bias: {metrics_farm_MX[0]:.3f}\\nCorr: {metrics_farm_MX[1]:.3f}\\nRMSE: {metrics_farm_MX[2]:.3f}'], loc= 'best')\n",
    "bisec(ax7, obs_MX, farm_MX)\n",
    "\n",
    "ax8.scatter(obs_MX, imp1_MX, c=colors['MX'], s=10, marker='o', alpha= 0.7)\n",
    "ax8.grid(True)\n",
    "ax8.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax8.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "ax8.legend([f'Bias: {metrics_imp1f_MX[0]:.3f}\\nCorr: {metrics_imp1f_MX[1]:.3f}\\nRMSE: {metrics_imp1f_MX[2]:.3f}'], loc= 'best')\n",
    "bisec(ax8, obs_MX, farm_MX)\n",
    "\n",
    "ax9.scatter(obs_MX, imp2_MX, c=colors['MX'], s=10, marker='o', alpha= 0.7)\n",
    "ax9.grid(True)\n",
    "#ax9.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax9.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "ax9.legend([f'Bias: {metrics_imp2f_MX[0]:.3f}\\nCorr: {metrics_imp2f_MX[1]:.3f}\\nRMSE: {metrics_imp2f_MX[2]:.3f}'], loc= 'best')\n",
    "bisec(ax9, obs_MX, farm_MX)\n",
    "ax9.text(1.05, 0.5, f'#MX={len(obs_MX)}', transform=ax9.transAxes, fontweight= 'bold', fontsize=12, color= colors['MX'], verticalalignment='center', horizontalalignment='left', rotation=90)\n",
    "'''\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "norm_1 = mcolors.Normalize(vmin=data_h['m3']['ang_440_870'].min(), vmax=data_h['m3']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='magma'), ax=[ax1, ax2, ax3], orientation='vertical')\n",
    "cbar_1.set_label(r'$\\alpha_{440-870}$')\n",
    "'''\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/home/andrea/enea_project/lmp_dust_enea/figure_old/scatter_plot_lmp_imp1_imp2_dd_bb_mx.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_DD = DeDu24['LMP']\n",
    "obs_BB = BioBu24['LMP']\n",
    "obs_MX = Mix24['LMP']\n",
    "farm_DD = DeDu24['FARM']\n",
    "farm_BB = BioBu24['FARM']\n",
    "farm_MX = Mix24['FARM']\n",
    "\n",
    "imp1_odr_DD = DeDu24['IMP1F_ODR']\n",
    "imp1_odr_BB = BioBu24['IMP1F_ODR']\n",
    "imp1_odr_MX = Mix24['IMP1F_ODR']\n",
    "imp2_odr_DD = DeDu24['IMP2F_ODR']\n",
    "imp2_odr_BB = BioBu24['IMP2F_ODR']\n",
    "imp2_odr_MX = Mix24['IMP2F_ODR']\n",
    "\n",
    "colors = {\n",
    "    'DD': '#f7b538',\n",
    "    'BB': '#8c001a',\n",
    "    'MX': '#c2c5bb'\n",
    "}\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize= (12, 12), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(max(dato1), max(dato2))\n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "ax4.set_aspect('equal', adjustable='box')\n",
    "ax5.set_aspect('equal', adjustable='box')\n",
    "ax6.set_aspect('equal', adjustable='box')\n",
    "ax7.set_aspect('equal', adjustable='box')\n",
    "ax8.set_aspect('equal', adjustable='box')\n",
    "ax9.set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax1.scatter(obs_DD, farm_DD, c=colors['DD'], s=10, marker='o', alpha= 0.7)\n",
    "ax1.grid(True)\n",
    "ax1.set_title('FARM', fontweight= 'bold')\n",
    "#ax1.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax1.set_ylabel(r'$\\tau_{FARM}$', fontsize= 16)\n",
    "ax1.legend([f'Bias: {metrics_farm_DD[0]:.3f}\\nCorr: {metrics_farm_DD[1]:.3f}\\nRMSE: {metrics_farm_DD[2]:.3f}\\nVar: {metrics_farm_DD[4]:.3f}'], loc= 'upper right')\n",
    "bisec(ax1, obs_DD, farm_DD)\n",
    "\n",
    "ax2.scatter(obs_DD, imp1_odr_DD, c=colors['DD'], s=10, marker='s', alpha= 0.7)\n",
    "ax2.grid(True)\n",
    "ax2.set_title('IMP1F_ODR', fontweight= 'bold')\n",
    "#ax2.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax2.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "ax2.legend([f'Bias: {metrics_imp1f_odr_DD[0]:.3f}\\nCorr: {metrics_imp1f_odr_DD[1]:.3f}\\nRMSE: {metrics_imp1f_odr_DD[2]:.3f}\\nVar: {metrics_imp1f_odr_DD[4]:.3f}'], loc= 'upper right')\n",
    "bisec(ax2, obs_DD, imp1_odr_DD)\n",
    "\n",
    "ax3.scatter(obs_DD, imp2_odr_DD, c=colors['DD'], s=10, marker='s', alpha= 0.7)\n",
    "ax3.grid(True)\n",
    "ax3.set_title('IMP2F_ODR', fontweight= 'bold')\n",
    "#ax3.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax3.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "ax3.legend([f'Bias: {metrics_imp2f_odr_DD[0]:.3f}\\nCorr: {metrics_imp2f_odr_DD[1]:.3f}\\nRMSE: {metrics_imp2f_odr_DD[2]:.3f}\\nVar: {metrics_imp2f_odr_DD[4]:.3f}'], loc= 'upper right')\n",
    "bisec(ax3, obs_DD, imp2_odr_DD)\n",
    "ax3.text(1.05, 0.5, f'#DD={len(obs_DD)}', transform=ax3.transAxes, fontweight= 'bold', fontsize=12, color= colors['DD'], verticalalignment='center', horizontalalignment='left', rotation=90)\n",
    "\n",
    "ax4.scatter(obs_BB, farm_BB, c=colors['BB'], s=10, marker='o', alpha= 0.7)\n",
    "ax4.grid(True)\n",
    "#ax4.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "ax4.set_ylabel(r'$\\tau_{MOD}$', fontsize= 16)\n",
    "ax4.legend([f'Bias: {metrics_farm_BB[0]:.3f}\\nCorr: {metrics_farm_BB[1]:.3f}\\nRMSE: {metrics_farm_BB[2]:.3f}\\nVar: {metrics_farm_BB[4]:.3f}'], loc= 'best')\n",
    "bisec(ax4, obs_BB, farm_BB)\n",
    "\n",
    "ax5.scatter(obs_BB, imp1_odr_BB, c=colors['BB'], s=10, marker='s', alpha= 0.7)\n",
    "ax5.grid(True)\n",
    "#ax5.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax5.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "ax5.legend([f'Bias: {metrics_imp1f_odr_BB[0]:.3f}\\nCorr: {metrics_imp1f_odr_BB[1]:.3f}\\nRMSE: {metrics_imp1f_odr_BB[2]:.3f}\\nVar: {metrics_imp1f_odr_BB[4]:.3f}'], loc= 'best')\n",
    "bisec(ax5, obs_BB, imp1_odr_BB)\n",
    "\n",
    "ax6.scatter(obs_BB, imp2_odr_BB, c=colors['BB'], s=10, marker='s', alpha= 0.7)\n",
    "ax6.grid(True)\n",
    "#ax6.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax6.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "ax6.legend([f'Bias: {metrics_imp2f_odr_BB[0]:.3f}\\nCorr: {metrics_imp2f_odr_BB[1]:.3f}\\nRMSE: {metrics_imp2f_odr_BB[2]:.3f}\\nVar: {metrics_imp2f_odr_BB[4]:.3f}'], loc= 'best')\n",
    "bisec(ax6, obs_BB, imp2_odr_BB)\n",
    "ax6.text(1.05, 0.5, f'#BB={len(obs_BB)}', transform=ax6.transAxes, fontweight= 'bold', fontsize=12, color= colors['BB'], verticalalignment='center', horizontalalignment='left', rotation=90)\n",
    "\n",
    "ax7.scatter(obs_MX, farm_MX, c=colors['MX'], s=10, marker='o', alpha= 0.7)\n",
    "ax7.grid(True)\n",
    "#ax7.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax7.set_ylabel(r'$\\tau_{FARM}$', fontsize= 16)\n",
    "ax7.legend([f'Bias: {metrics_farm_MX[0]:.3f}\\nCorr: {metrics_farm_MX[1]:.3f}\\nRMSE: {metrics_farm_MX[2]:.3f}\\nVar: {metrics_farm_MX[4]:.3f}'], loc= 'best')\n",
    "bisec(ax7, obs_MX, farm_MX)\n",
    "\n",
    "ax8.scatter(obs_MX, imp1_odr_MX, c=colors['MX'], s=10, marker='s', alpha= 0.7)\n",
    "ax8.grid(True)\n",
    "ax8.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax8.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "ax8.legend([f'Bias: {metrics_imp1f_odr_MX[0]:.3f}\\nCorr: {metrics_imp1f_odr_MX[1]:.3f}\\nRMSE: {metrics_imp1f_odr_MX[2]:.3f}\\nVar: {metrics_imp1f_odr_MX[4]:.3f}'], loc= 'best')\n",
    "bisec(ax8, obs_MX, imp1_odr_MX)\n",
    "\n",
    "ax9.scatter(obs_MX, imp2_odr_MX, c=colors['MX'], s=10, marker='s', alpha= 0.7)\n",
    "ax9.grid(True)\n",
    "#ax9.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "#ax9.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "ax9.legend([f'Bias: {metrics_imp2f_odr_MX[0]:.3f}\\nCorr: {metrics_imp2f_odr_MX[1]:.3f}\\nRMSE: {metrics_imp2f_odr_MX[2]:.3f}\\nVar: {metrics_imp2f_odr_MX[4]:.3f}'], loc= 'best')\n",
    "bisec(ax9, obs_MX, imp2_odr_MX)\n",
    "ax9.text(1.05, 0.5, f'#MX={len(obs_MX)}', transform=ax9.transAxes, fontweight= 'bold', fontsize=12, color= colors['MX'], verticalalignment='center', horizontalalignment='left', rotation=90)\n",
    "'''\n",
    "ax1.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax2.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "ax3.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=True)\n",
    "\n",
    "norm_1 = mcolors.Normalize(vmin=data_h['m3']['ang_440_870'].min(), vmax=data_h['m3']['ang_440_870'].max())\n",
    "cbar_1 = fig.colorbar(cm.ScalarMappable(norm=norm_1, cmap='magma'), ax=[ax1, ax2, ax3], orientation='vertical')\n",
    "cbar_1.set_label(r'$\\alpha_{440-870}$')\n",
    "'''\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/home/andrea/enea_project/lmp_dust_enea/figure_old/scatter_plot_lmp_imp1_imp2_dd_bb_mx_odr.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot divided by season for each sub-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_obs_DD = fall_24h_DD['LMP']\n",
    "fall_obs_BB = fall_24h_BB['LMP']\n",
    "fall_obs_MX = fall_24h_MX['LMP']\n",
    "fall_farm_DD = fall_24h_DD['FARM']\n",
    "fall_farm_BB = fall_24h_BB['FARM']\n",
    "fall_farm_MX = fall_24h_MX['FARM']\n",
    "fall_imp1_DD = fall_24h_DD['IMP1F']\n",
    "fall_imp1_BB = fall_24h_BB['IMP1F']\n",
    "fall_imp1_MX = fall_24h_MX['IMP1F']\n",
    "fall_imp2_DD = fall_24h_DD['IMP2F']\n",
    "fall_imp2_BB = fall_24h_BB['IMP2F']\n",
    "fall_imp2_MX = fall_24h_MX['IMP2F']\n",
    "\n",
    "winter_obs_DD = winter_24h_DD['LMP']\n",
    "winter_obs_BB = winter_24h_BB['LMP']\n",
    "winter_obs_MX = winter_24h_MX['LMP']\n",
    "winter_farm_DD = winter_24h_DD['FARM']\n",
    "winter_farm_BB = winter_24h_BB['FARM']\n",
    "winter_farm_MX = winter_24h_MX['FARM']\n",
    "winter_imp1_DD = winter_24h_DD['IMP1F']\n",
    "winter_imp1_BB = winter_24h_BB['IMP1F']\n",
    "winter_imp1_MX = winter_24h_MX['IMP1F']\n",
    "winter_imp2_DD = winter_24h_DD['IMP2F']\n",
    "winter_imp2_BB = winter_24h_BB['IMP2F']\n",
    "winter_imp2_MX = winter_24h_MX['IMP2F']\n",
    "\n",
    "spring_obs_DD = spring_24h_DD['LMP']\n",
    "spring_obs_BB = spring_24h_BB['LMP']\n",
    "spring_obs_MX = spring_24h_MX['LMP']\n",
    "spring_farm_DD = spring_24h_DD['FARM']\n",
    "spring_farm_BB = spring_24h_BB['FARM']\n",
    "spring_farm_MX = spring_24h_MX['FARM']\n",
    "spring_imp1_DD = spring_24h_DD['IMP1F']\n",
    "spring_imp1_BB = spring_24h_BB['IMP1F']\n",
    "spring_imp1_MX = spring_24h_MX['IMP1F']\n",
    "spring_imp2_DD = spring_24h_DD['IMP2F']\n",
    "spring_imp2_BB = spring_24h_BB['IMP2F']\n",
    "spring_imp2_MX = spring_24h_MX['IMP2F']\n",
    "\n",
    "summer_obs_DD = summer_24h_DD['LMP']\n",
    "summer_obs_BB = summer_24h_BB['LMP']\n",
    "summer_obs_MX = summer_24h_MX['LMP']\n",
    "summer_farm_DD = summer_24h_DD['FARM']\n",
    "summer_farm_BB = summer_24h_BB['FARM']\n",
    "summer_farm_MX = summer_24h_MX['FARM']\n",
    "summer_imp1_DD = summer_24h_DD['IMP1F']\n",
    "summer_imp1_BB = summer_24h_BB['IMP1F']\n",
    "summer_imp1_MX = summer_24h_MX['IMP1F']\n",
    "summer_imp2_DD = summer_24h_DD['IMP2F']\n",
    "summer_imp2_BB = summer_24h_BB['IMP2F']\n",
    "summer_imp2_MX = summer_24h_MX['IMP2F']\n",
    "\n",
    "colors = {\n",
    "    'DD': '#f7b538',\n",
    "    'BB': '#8c001a',\n",
    "    'MX': '#c2c5bb'\n",
    "}\n",
    "\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8), (ax9, ax10, ax11, ax12)) = plt.subplots(3, 4, figsize= (12, 8), sharex= True, sharey= True)\n",
    "\n",
    "def bisec(ax, dato1, dato2):\n",
    "    x_min = 0\n",
    "    x_max = max(max(dato1), max(dato2))\n",
    "    xdata = np.linspace(x_min, x_max, 100)\n",
    "    ydata = xdata\n",
    "    ax.plot(xdata, ydata, linestyle='--', color='gray')\n",
    "\n",
    "ax1.set_title('FALL', fontweight= 'bold')\n",
    "ax1.scatter(fall_obs_DD, fall_farm_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax1.scatter(fall_obs_MX, fall_farm_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax1.scatter(fall_obs_BB, fall_farm_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax1.grid(True)\n",
    "ax1.set_ylabel(r'$\\tau_{FARM}$', fontsize= 16)\n",
    "#legend_text = ()\n",
    "# Aggiunta della legenda\n",
    "#leg = ax1.legend([legend_text], fancybox= True, shadow= True, bbox_to_anchor= [0.6, 0.7], ncol=3, frameon= True)\n",
    "#leg.set_title(\"Fall\", prop={'size': 12, 'weight': 'bold'})\n",
    "#plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "bisec(ax1, obs_DD, farm_DD)\n",
    "\n",
    "ax2.set_title('WINTER', fontweight= 'bold')\n",
    "ax2.scatter(winter_obs_DD, winter_farm_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax2.scatter(winter_obs_MX, winter_farm_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax2.scatter(winter_obs_BB, winter_farm_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax2.grid(True)\n",
    "bisec(ax2, obs_DD, farm_DD)\n",
    "\n",
    "ax3.set_title('SPRING', fontweight= 'bold')\n",
    "ax3.scatter(spring_obs_DD, spring_farm_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax3.scatter(spring_obs_MX, spring_farm_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax3.scatter(spring_obs_BB, spring_farm_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax3.grid(True)\n",
    "bisec(ax3, obs_DD, farm_DD)\n",
    "\n",
    "ax4.set_title('SUMMER', fontweight= 'bold')\n",
    "ax4.scatter(summer_obs_DD, summer_farm_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax4.scatter(summer_obs_MX, summer_farm_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax4.scatter(summer_obs_BB, summer_farm_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax4.grid(True)\n",
    "bisec(ax4, obs_DD, farm_DD)\n",
    "\n",
    "ax5.scatter(fall_obs_DD, fall_imp1_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax5.scatter(fall_obs_MX, fall_imp1_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax5.scatter(fall_obs_BB, fall_imp1_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax5.grid(True)\n",
    "ax5.set_ylabel(r'$\\tau_{IMP1F}$', fontsize= 16)\n",
    "bisec(ax5, obs_DD, imp1_DD)\n",
    "\n",
    "ax6.scatter(winter_obs_DD, winter_imp1_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax6.scatter(winter_obs_MX, winter_imp1_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax6.scatter(winter_obs_BB, winter_imp1_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax6.grid(True)\n",
    "bisec(ax6, obs_DD, imp1_DD)\n",
    "\n",
    "ax7.scatter(spring_obs_DD, spring_imp1_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax7.scatter(spring_obs_MX, spring_imp1_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax7.scatter(spring_obs_BB, spring_imp1_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax7.grid(True)\n",
    "bisec(ax7, obs_DD, imp1_DD)\n",
    "\n",
    "ax8.scatter(summer_obs_DD, summer_imp1_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax8.scatter(summer_obs_MX, summer_imp1_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax8.scatter(summer_obs_BB, summer_imp1_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax8.grid(True)\n",
    "bisec(ax8, obs_DD, imp1_DD)\n",
    "\n",
    "ax9.scatter(fall_obs_DD, fall_imp2_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax9.scatter(fall_obs_MX, fall_imp2_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax9.scatter(fall_obs_BB, fall_imp2_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax9.grid(True)\n",
    "#ax9.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "ax9.set_ylabel(r'$\\tau_{IMP2F}$', fontsize= 16)\n",
    "bisec(ax9, obs_DD, imp2_DD)\n",
    "\n",
    "ax10.scatter(winter_obs_DD, winter_imp2_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax10.scatter(winter_obs_MX, winter_imp2_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax10.scatter(winter_obs_BB, winter_imp2_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax10.grid(True)\n",
    "ax10.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16, x=1.0)\n",
    "bisec(ax10, obs_DD, imp2_DD)\n",
    "\n",
    "ax11.scatter(spring_obs_DD, spring_imp2_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax11.scatter(spring_obs_MX, spring_imp2_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax11.scatter(spring_obs_BB, spring_imp2_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax11.grid(True)\n",
    "#ax11.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "bisec(ax11, obs_DD, imp2_DD)\n",
    "\n",
    "ax12.scatter(summer_obs_DD, summer_imp2_DD, c=colors['DD'], s=10, marker='o', label= 'DD', alpha= 0.7)\n",
    "ax12.scatter(summer_obs_MX, summer_imp2_MX, c=colors['MX'], s=10, marker='o', label= 'MX', alpha= 0.7)\n",
    "ax12.scatter(summer_obs_BB, summer_imp2_BB, c=colors['BB'], s=10, marker='o', label= 'BB', alpha= 0.7)\n",
    "ax12.grid(True)\n",
    "#ax12.set_xlabel(r'$\\tau_{LMP}$', fontsize= 16)\n",
    "bisec(ax12, obs_DD, imp2_DD)\n",
    "\n",
    "fig.legend(['DD', 'MX', 'BB'] , bbox_to_anchor= [0.57, 0.95], fancybox= True, shadow= True)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/home/andrea/enea_project/lmp_dust_enea/figure_old/scatter_plot_lmp_imp1_imp2_seasons.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = ['DD', 'BB', 'MX']\n",
    "# table_metrics = {\n",
    "#      'DD': metrics_df_DD,\n",
    "#      'BB': metrics_df_BB,\n",
    "#      'MX': metrics_df_MX\n",
    "# }\n",
    "# colors_table = {\n",
    "#     'DD': '#d0cd94',\n",
    "#     'BB': '#e08e45',\n",
    "#     'MX': '#acbdba'\n",
    "# }\n",
    "# def create_table(ax, data, title, color):\n",
    "#     ax.axis(\"off\")  # Rimuove gli assi\n",
    "#     table = Table(ax, bbox=[0, 0, 1, 1])  # Crea la tabella\n",
    "\n",
    "#     # Intestazione delle colonne\n",
    "#     for col_idx, col_name in enumerate(data.columns):\n",
    "#         table.add_cell(0, col_idx, width=0.2, height=0.1, text=col_name, loc=\"center\", facecolor=\"lightgreen\")\n",
    "\n",
    "#     # Righe con i dati\n",
    "#     for row_idx, row in enumerate(data.itertuples(index=False), start=1):\n",
    "#         for col_idx, value in enumerate(row):\n",
    "#         # Controllo del tipo di dato\n",
    "#             if isinstance(value, float):\n",
    "#                 text = f\"{value:.2f}\"  # Formatta i numeri con due cifre decimali\n",
    "#             else:\n",
    "#                 text = str(value)  # Converti altri tipi in stringa\n",
    "#             table.add_cell(row_idx, col_idx, width=0.2, height=0.1, text=text, loc=\"center\", facecolor=color)\n",
    "\n",
    "#     # Aggiungi la tabella e il titolo\n",
    "#     ax.set_title(title, fontweight=\"bold\")\n",
    "#     ax.add_table(table)\n",
    "\n",
    "# # Creazione delle subplot\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "# fig.subplots_adjust(hspace=0.5, wspace=0.4)\n",
    "\n",
    "# # Creazione delle tabelle\n",
    "# titles = [\"DD\", \"BB\", \"MX\"]\n",
    "# for i, cat in enumerate(categories):\n",
    "#     data = table_metrics[cat]  # Ottieni il DataFrame corrispondente\n",
    "#     create_table(ax[i], data, titles[i], colors_table[cat])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"/home/andtoro/figure/tables_metrics_LMP_MODS_DD_BB_MX.pdf\", format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of DD events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize= (12, 8))\n",
    "\n",
    "# DD_m9 = DeDu24[(DeDu24['time'].dt.year == 2023) & (DeDu24['time'].dt.month == 9)]\n",
    "# BB_m9 = BioBu24[(BioBu24['time'].dt.year == 2023) & (BioBu24['time'].dt.month == 9)]\n",
    "\n",
    "# plt.scatter(september23D['time'], september23D['LMP'], marker= 'o', s= 20, c= '#8cbcb9')\n",
    "# plt.scatter(BB_m9['time'], BB_m9['LMP'], c= '#dea54b', marker= '*', s= 50)\n",
    "# plt.grid(True)\n",
    "# plt.legend(labels= ['LMP', 'BB events'], loc= 'best', fancybox= True, shadow= True)\n",
    "# plt.xlabel('Time [days]', fontweight= 'bold')\n",
    "# plt.ylabel(r'$\\tau_{LMP}$', fontweight= 'bold', fontsize= 15)\n",
    "# plt.title('Biomass Burning events, September 2023', fontweight= 'bold')\n",
    "# ax = plt.gca()\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "# ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "# plt.xlim(september23D['time'].min(), september23D['time'].max())\n",
    "\n",
    "# for _, row in BB_m9.iterrows():\n",
    "#     plt.annotate(\n",
    "#         f\"{row['time'].date()}\",  # Display the date\n",
    "#         (row['time'], row['LMP']),\n",
    "#         textcoords=\"offset points\",\n",
    "#         xytext=(5, 10),  # Offset text above the point\n",
    "#         bbox=dict(boxstyle=\"round, pad=0.2\", edgecolor=\"black\", facecolor=\"orange\"),\n",
    "#         ha='right',\n",
    "#         arrowprops=dict(arrowstyle=\"->\", color='black')  # Optional: Add an arrow\n",
    "#     )\n",
    "\n",
    "# #plt.savefig(f\"/home/andtoro/figure/BB_ev_sep23.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# fig, ax = plt.subplots(4, 1, figsize=(12, 8),sharex= True, sharey= True)\n",
    "\n",
    "# mod= ['LMP', 'AOD', 'IMP1F', 'IMP2F']\n",
    "\n",
    "# for i in range(4):\n",
    "#     ax[i].scatter(september23D['time'], september23D[mod[i]], marker= 'o', s= 20, c= '#2f4858')\n",
    "#     ax[i].grid(True)\n",
    "#     ax[i].legend(labels= [mod[i]], loc= 'best', fancybox= True, shadow= True)\n",
    "#     ax[i].set_xlim(september23D['time'].min(), september23D['time'].max())\n",
    "\n",
    "# ax[1].set_ylabel(r'$\\tau$', fontweight= 'bold', fontsize= 18, y= 0.0)\n",
    "# ax[-1].set_xlabel('Time [days]', fontweight='bold')\n",
    "# ax[-1].xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "# ax[-1].xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "# fig.suptitle('Biomass Burning event, September 2023: models comparison', fontweight='bold')\n",
    "# #plt.tight_layout()\n",
    "# #plt.savefig(f\"/home/andtoro/figure/BB_ev_sep23_comparison.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(3, 1, figsize=(12, 8),sharex= True, sharey= True)\n",
    "\n",
    "# mod= ['FARM', 'IMP1F', 'IMP2F']\n",
    "\n",
    "# for i in range(3):\n",
    "\n",
    "#     ax[i].scatter(september23D['time'], (september23D['LMP'] - september23D[mod[i]]), marker= 'o', s= 20, c= '#2f4858')\n",
    "#     ax[i].grid(True)\n",
    "#     ax[i].legend(labels= [mod[i]], loc= 'best', fancybox= True, shadow= True)\n",
    "#     ax[i].set_xlim(september23D['time'].min(), september23D['time'].max())\n",
    "#     ax[i].axhline(y=0, color='#f26419', linestyle='-', linewidth=1) \n",
    "\n",
    "# ax[1].set_ylabel(r'$\\tau_{LMP}$', fontweight= 'bold', fontsize= 18)\n",
    "# ax[-1].set_xlabel('Time [days]', fontweight='bold')\n",
    "# ax[-1].xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "# ax[-1].xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "# fig.suptitle('Biomass Burning event, September 2023: bias (obs - mod)', fontweight='bold')\n",
    "# #plt.tight_layout()\n",
    "# #plt.savefig(f\"/home/andtoro/figure/BB_ev_bias.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_m9 = DeDu24[(DeDu24['time'].dt.year == 2023) & (DeDu24['time'].dt.month == 9)]\n",
    "DD_m10 = DeDu24[(DeDu24['time'].dt.year == 2023) & (DeDu24['time'].dt.month == 10)]\n",
    "DD_m11 = DeDu24[(DeDu24['time'].dt.year == 2023) & (DeDu24['time'].dt.month == 11)]\n",
    "DD_m12 = DeDu24[(DeDu24['time'].dt.year == 2023) & (DeDu24['time'].dt.month == 12)]\n",
    "DD_m1 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 1)]\n",
    "DD_m2 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 2)]\n",
    "DD_m3 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 3)]\n",
    "DD_m4 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 4)]\n",
    "DD_m5 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 5)]\n",
    "DD_m6 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 6)]\n",
    "DD_m7 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 7)]\n",
    "DD_m8 = DeDu24[(DeDu24['time'].dt.year == 2024) & (DeDu24['time'].dt.month == 8)]\n",
    "\n",
    "# Function to create scatter plots for a single metric\n",
    "def plot_events(month_data, events_data, month_name, year_file, metric='LMP'):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(month_data['time'], month_data[metric], marker='o', s=20, c='#8cbcb9', label=f'{metric}')\n",
    "    plt.scatter(events_data['time'], events_data[metric], c='#dea54b', marker='*', s=50, label='DD events')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right', fancybox=True, shadow=True)\n",
    "    plt.xlabel('Time [days]', fontweight='bold')\n",
    "    plt.ylabel(r'$\\tau$', fontsize=16)\n",
    "    plt.title(f'{month_name} {year_file}', fontweight='bold')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "    plt.xlim(month_data['time'].min(), month_data['time'].max())\n",
    "\n",
    "    for _, row in events_data.iterrows():\n",
    "        plt.annotate(\n",
    "            f\"{row['time'].date()}\",\n",
    "            (row['time'], row[metric]),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(5, 10),\n",
    "            bbox=dict(boxstyle=\"round, pad=0.2\", edgecolor=\"black\", facecolor=\"lightyellow\"),\n",
    "            ha='right',\n",
    "            arrowprops=dict(arrowstyle=\"->\", color='black')\n",
    "        )\n",
    "    #plt.savefig(f\"/home/andtoro/figure/DD_ev_{month_name}_{year_file}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Function to compare multiple metrics\n",
    "def compare_metrics(month_data, month_name, year_file, metrics):\n",
    "    fig, ax = plt.subplots(len(metrics), 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax[i].scatter(month_data['time'], month_data[metric], marker='o', s=20, c='#2f4858')\n",
    "        ax[i].grid(True)\n",
    "        ax[i].legend(labels=[metric], loc='best', fancybox=True, shadow=True)\n",
    "        ax[i].set_xlim(month_data['time'].min(), month_data['time'].max())\n",
    "\n",
    "    ax[len(metrics) // 2].set_ylabel(r'$\\tau$', fontsize=16, y=1.0)\n",
    "    ax[-1].set_xlabel('Time [days]', fontweight='bold')\n",
    "    ax[-1].xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "    ax[-1].xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "    fig.suptitle(f'{month_name} {year_file}', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"/home/andtoro/figure/DD_compare_{month_name}_{year_file}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Function for bias analysis\n",
    "def bias_analysis(month_data, month_name, year_file, metrics, reference_metric='LMP'):\n",
    "    fig, ax = plt.subplots(len(metrics), 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax[i].scatter(month_data['time'], (month_data[reference_metric] - month_data[metric]),\n",
    "                      marker='o', s=20, c='#2f4858')\n",
    "        ax[i].grid(True)\n",
    "        ax[i].legend(labels=[metric], loc='best', fancybox=True, shadow=True)\n",
    "        ax[i].set_xlim(month_data['time'].min(), month_data['time'].max())\n",
    "        ax[i].axhline(y=0, color='#f26419', linestyle='-', linewidth=1)\n",
    "\n",
    "    ax[len(metrics) // 2].set_ylabel(r'$\\tau$', fontsize=16)\n",
    "    ax[-1].set_xlabel('Time [days]', fontweight='bold')\n",
    "    ax[-1].xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "    ax[-1].xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "    fig.suptitle(f'{month_name} {year_file}', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"/home/andtoro/figure/DD_bias_{month_name}_{year_file}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for October\n",
    "\n",
    "plot_events(september23D, DD_m9, \"September\", 2023)\n",
    "compare_metrics(september23D, \"September\", 2023, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(september23D, \"September\", 2023, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(october23D, DD_m10, \"October\", 2023)\n",
    "compare_metrics(october23D, \"October\", 2023, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(october23D, \"October\", 2023, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(november23D, DD_m11, \"November\", 2023)\n",
    "compare_metrics(november23D, \"November\", 2023, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(november23D, \"November\", 2023, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(december23D, DD_m12, \"December\", 2023)\n",
    "compare_metrics(december23D, \"December\", 2023, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(december23D, \"December\", 2023, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(january24D, DD_m1, \"January\", 2024)\n",
    "compare_metrics(january24D, \"January\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(january24D, \"January\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(february24D, DD_m2, \"February\", 2024)\n",
    "compare_metrics(february24D, \"February\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(february24D, \"February\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(march24D, DD_m3, \"March\", 2024)\n",
    "compare_metrics(march24D, \"March\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(march24D, \"March\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(april24D, DD_m4, \"April\", 2024)\n",
    "compare_metrics(april24D, \"April\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(april24D, \"April\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(may24D, DD_m5, \"May\", 2024)\n",
    "compare_metrics(may24D, \"May\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(may24D, \"May\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(june24D, DD_m6, \"June\", 2024)\n",
    "compare_metrics(june24D, \"June\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(june24D, \"June\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(july24D, DD_m7, \"July\", 2024)\n",
    "compare_metrics(july24D, \"July\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(july24D, \"July\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n",
    "\n",
    "plot_events(august24D, DD_m8, \"August\", 2024)\n",
    "compare_metrics(august24D, \"August\", 2024, metrics=['LMP', 'FARM', 'IMP1F', 'IMP2F'])\n",
    "bias_analysis(august24D, \"August\", 2024, metrics=['FARM', 'IMP1F', 'IMP2F'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10), sharex= False, sharey= True)\n",
    "ax = axes.ravel()\n",
    "fig.suptitle(\"Desert Dust events\", fontsize=16, fontweight= 'bold', y=0.95)\n",
    "\n",
    "Month12 = ['Sep23', 'Oct23', 'Nov23', 'Dec23', 'Jan24', 'Feb24', 'Mar24', 'Apr24', 'May24', 'Jun24', 'Jul24', 'Aug24']\n",
    "DDD_ev = {\n",
    "    'Sep23': DD_m9,\n",
    "    'Oct23': DD_m10,\n",
    "    'Nov23': DD_m11,\n",
    "    'Dec23': DD_m12,\n",
    "    'Jan24': DD_m1,\n",
    "    'Feb24': DD_m2,\n",
    "    'Mar24': DD_m3,\n",
    "    'Apr24': DD_m4,\n",
    "    'May24': DD_m5,\n",
    "    'Jun24': DD_m6,\n",
    "    'Jul24': DD_m7,\n",
    "    'Aug24': DD_m8\n",
    "}\n",
    "# Plot data for each month in the grid\n",
    "months = {\n",
    "    'Sep23': september23D,\n",
    "    'Oct23': october23D,\n",
    "    'Nov23': november23D,\n",
    "    'Dec23': december23D,\n",
    "    'Jan24': january24D,\n",
    "    'Feb24': february24D,\n",
    "    'Mar24': march24D,\n",
    "    'Apr24': april24D,\n",
    "    'May24': may24D,\n",
    "    'Jun24': june24D,\n",
    "    'Jul24': july24D,\n",
    "    'Aug24': august24D\n",
    "    }\n",
    "\n",
    "for i, month in enumerate(Month12):\n",
    "\n",
    "    ax[i].scatter(months[month]['time'], months[month]['LMP'], marker= 'o', s= 10, color= '#035e7b')\n",
    "\n",
    "    for _, row in DDD_ev[month].iterrows():\n",
    "        ax[i].annotate(\n",
    "            \"DD\",\n",
    "            (row['time'], row['LMP']),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize= 10,\n",
    "            xytext=(5, 10),\n",
    "            bbox=dict(boxstyle=\"round, pad=0.2\", edgecolor=\"black\", facecolor=\"lightyellow\"),\n",
    "            ha='right',\n",
    "            arrowprops=dict(arrowstyle=\"->\", color='black')\n",
    "        )\n",
    "    ax[i].set_title(Month12[i], fontweight= 'bold')\n",
    "    ax[i].grid(True)\n",
    "    ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%d'))\n",
    "    ax[i].xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "'''\n",
    "magnified_months = [0, 4, 11]  # Indices of the months to magnify\n",
    "fig2, mag_axes = plt.subplots(1, len(magnified_months), figsize=(12, 4))\n",
    "fig2.suptitle(\"Events of interest\", fontsize=16, fontweight= 'bold')\n",
    "\n",
    "for i, ax in zip(magnified_months, mag_axes):\n",
    "    ax.plot(x, data[i])\n",
    "    ax.set_title(months[i], fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "'''\n",
    "# Adjust layout and show\n",
    "fig.text(0.5, 0.03, 'Time [days]', ha='center', fontsize=18, fontweight='bold')\n",
    "fig.text(0.08, 0.5, r'$\\tau$', va='center', rotation='vertical', fontsize=18)\n",
    "#plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "# plt.savefig(\"/home/andrea/enea_project/lmp_dust_enea/figure_old/dd_events_23_24.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $b_{ext}$ for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ['40', '50', '70', '100', '130', '180', '240', '330', '440', '600', '800', '1090', '1470', '1500']\n",
    "colors_name = {\n",
    "    'ASO4': '#b20d30',\n",
    "    'ANO3': '#8d9f87',\n",
    "    'ASOIL': '#c17817',\n",
    "    'ASEAS': '#3f84e5',\n",
    "    'OTHER': '#3f784c',\n",
    "    'AEC': '#d90368'\n",
    "}\n",
    "species_bext = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER', 'AEC']\n",
    "# plots by species for each leayer\n",
    "time = df_BEXT_IMP1['M24']['time']\n",
    "\n",
    "alt = ['(0-40)m', '(40-90)m', '(90-160)m', '(160-260)m', '(260-390)m', '(390-570)m', '(570-810)m', '(810-1140)m', '(1140-1580)m', \n",
    "        '(1580-2180)m', '(2180-2980)m', '(2980-4070)m', '(4070-5540)m', '(5540-7040)m']\n",
    "#subplots\n",
    "for i in species_bext:\n",
    "    fig, ax = plt.subplots(3, 5, figsize=(18, 11), sharex= True, sharey= True)\n",
    "    ax = ax.ravel() \n",
    "    for h, j in enumerate(z):\n",
    "        if h < 14: \n",
    "            ax[h].plot(time, df_BEXT_IMP2['M24'][f's_{i}_l_{h}'], color= colors_name[f'{i}'], linestyle= '-.', label= alt[h])\n",
    "            ax[h].legend(loc= 'upper right')\n",
    "            ax[h].grid(True)\n",
    "            ax[h].set_ylim(0, 0.00035)\n",
    "            #ax[h].xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "        if h >= 9: \n",
    "            ax[h].tick_params(axis='x', rotation=45)\n",
    "            ax[h].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "            ax[h].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "            #ax[h].set_xlim(0, None)\n",
    "        #tick_positions = list(range(len(time)))  # Positions for each data point\n",
    "        #tick_labels = [t.strftime('%b') for t in time]  # Short month names\n",
    "        #ax[9].set_xticks(tick_positions[::30])  # Show every 30th tick\n",
    "        #ax[9].set_xticklabels(tick_labels[::30], fontsize=8)\n",
    "    for h in range(len(z), len(ax)):\n",
    "        ax[h].set_axis_off()\n",
    "        fig.delaxes(ax[h])\n",
    "    \n",
    "    if i == \"ASOIL\":\n",
    "        fig.suptitle('Extinction Coefficient for DUST', fontweight='bold', y= 0.9)\n",
    "    else:\n",
    "        fig.suptitle(f'Extinction Coefficient for {i}', fontweight='bold', y= 0.9)\n",
    "    fig.text(0.05, 0.52, r'$b_{ext} [m^{-1}]$', va='center', rotation='vertical', fontsize=12)\n",
    "    #plt.setp(ax, ylim=(0, 0.00025), xlim= (0, None))\n",
    "    #plt.savefig(f\"/home/andtoro/figure/bext_subplot_24h_{i}_IMP2.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    # plt.savefig(f\"/home/andrea/enea_project/lmp_dust_enea/figure_old/lmp_bext_subplot_24h_{i}_imp2.png\", format=\"png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACORS and contributions of ACORS, ASOIL, ASEAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_concentration_1 = {\n",
    "    \"ASOIL\": (df_SPEC_IMP1['M24']['ASOIL_C']/df_SPEC_IMP1['M24']['COARSE']) * 100, \n",
    "    \"ASEAS\": (df_SPEC_IMP1['M24']['ASEAS_C']/df_SPEC_IMP1['M24']['COARSE']) * 100,\n",
    "    \"ACORS\": (df_SPEC_IMP1['M24']['ACORS_C']/df_SPEC_IMP1['M24']['COARSE']) * 100\n",
    "}\n",
    "\n",
    "spec_concentration_2 = {\n",
    "    \"ASOIL\": (df_SPEC_IMP2['M24']['ASOIL_C']/df_SPEC_IMP2['M24']['COARSE']) * 100, \n",
    "    \"ASEAS\": (df_SPEC_IMP2['M24']['ASEAS_C']/df_SPEC_IMP2['M24']['COARSE']) * 100,\n",
    "    \"ACORS\": (df_SPEC_IMP2['M24']['ACORS_C']/df_SPEC_IMP2['M24']['COARSE']) * 100\n",
    "}\n",
    "\n",
    "label_color = {\n",
    "    'ASOIL': '#ce8147', \n",
    "    'ASEAS': '#6a8eae', \n",
    "    'ACORS': '#0a0f0d'\n",
    "}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Create a single figure and axis\n",
    "\n",
    "x = range(len(spec_concentration_1))  # X positions for bars\n",
    "width = 4  # Bar width\n",
    "\n",
    "for i, j in enumerate(label_color):\n",
    "    ax.bar(df_SPEC_IMP1['M24']['time'], spec_concentration_1[f'{j}'], width=width, edgecolor=\"white\", \n",
    "           linewidth=0.5, color=label_color[j], label=j, alpha= 0.8)\n",
    "    \n",
    "ax.set_ylabel(\"Concentration (%)\", fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel(\"Time [yyyy-mm]\", fontsize=16, fontweight='bold')\n",
    "ax.set_title(\"Species Contribution to the COARSE MASS\", fontsize=16, fontweight='bold')\n",
    "ax.grid(False)\n",
    "ax.legend()\n",
    "\n",
    "#plt.savefig(\"/home/andtoro/figure/ACORS_concentrations.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_color = {\n",
    "#     'ASOIL': '#ff9999', \n",
    "#     'ASEAS': '#66b3ff', \n",
    "#     'ACORS': '#99ff99'\n",
    "# }\n",
    "# for i, j in enumerate(label_color):\n",
    "#     print(i, j, label_color[f'{j}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap for species (ASOIL, ASO4, ANO3, ASEAS, OTHER, AEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heat = df_LAY_IMP2['M24'][(df_LAY_IMP2['M24']['time'].dt.year == 2024) & (df_LAY_IMP2['M24']['time'].dt.month == 3 )]\n",
    "#df_heat = df_LAY_IMP2['M30']\n",
    "year_heat = df_LAY_IMP2['M30']['time'].dt.year\n",
    "month_heat = df_LAY_IMP2['M30']['time'].dt.month\n",
    "day_heat = df_LAY_IMP2['M30']['time'].dt.day\n",
    "\n",
    "alt = ['(0-40)m', '(40-90)m', '(90-160)m', '(160-260)m', '(260-390)m', '(390-570)m', '(570-810)m', '(810-1140)m', '(1140-1580)m', \n",
    "        '(1580-2180)m', '(2180-2980)m', '(2980-4070)m', '(4070-5540)m', '(5540-7040)m']\n",
    "\n",
    "year_heat = df_LAY_IMP2['M30']['time'].dt.year.to_numpy()\n",
    "month_heat = df_LAY_IMP2['M30']['time'].dt.month.to_numpy()\n",
    "day_heat = df_LAY_IMP2['M24'][(df_LAY_IMP2['M24']['time'].dt.year == 2024) & (df_LAY_IMP2['M24']['time'].dt.month == 3 )]['time'].dt.day.to_numpy()\n",
    "\n",
    "df_map = df_heat.drop(['time', 'REL', 'HMIX', 'AOD', 'FARM', '675nm', '500nm', 'LMP',\n",
    "       'err_550', '440nm', 'pw', 'ang_440_870', 'ang_440_675', 'ang_500_870',\n",
    "       'year', 'month', 'day', 'h', 'm', 's', 'n', 'IMP1F', 'IMP2F',], axis = 1)\n",
    "\n",
    "def select_type_and_concat(df, type):\n",
    "    columns = [f'{type}_layer_{i}' for i in range(13, -1, -1)]\n",
    "    return pd.concat([df[col] for col in columns], axis=1)\n",
    "\n",
    "dzT = np.array(dz)[::-1]\n",
    "dza = np.array(alt)[::-1]\n",
    "h = np.array(alt)\n",
    "\n",
    "fig = plt.figure(figsize= (18, 11))\n",
    "df_ASOIL = select_type_and_concat(df_map, 'ASOIL')\n",
    "fig = sns.heatmap(df_ASOIL.T, vmin= 0, vmax= 0.0538157813064139, cmap= 'Oranges', annot= False, xticklabels= day_heat, yticklabels= dza, linecolor= 'white', linewidth= 0.5)\n",
    "plt.title('ASOIL-Aug24')\n",
    "#plt.savefig('/home/andtoro/project_enea/heatmaps/sep23/ASOIL_0824.pdf', format= 'pdf')\n",
    "\n",
    "fig = plt.figure(figsize= (18, 11))\n",
    "df_AEC = select_type_and_concat(df_map, 'AEC')\n",
    "fig = sns.heatmap(df_ASOIL.T, vmin= 0, vmax= 0.0538157813064139, cmap= 'Oranges', annot= False, xticklabels= day_heat, yticklabels= dza, linecolor= 'white', linewidth= 0.5)\n",
    "plt.title('AEC-Sep23')\n",
    "#plt.savefig('/home/andtoro/project_enea/heatmaps/sep23/AEC_0923.pdf', format= 'pdf')\n",
    "\n",
    "fig = plt.figure(figsize= (18, 11))\n",
    "df_ASEAS = select_type_and_concat(df_map, 'ASEAS')\n",
    "fig = sns.heatmap(df_ASEAS.T, vmin= 0, vmax= 0.0538157813064139, cmap= 'Oranges', annot= False, xticklabels= day_heat, yticklabels= dza, linecolor= 'white', linewidth= 0.5)\n",
    "plt.title('ASEAS-September')\n",
    "#plt.savefig('/home/andtoro/project_enea/heatmaps/sep23/ASEAS_0923.pdf', format= 'pdf')\n",
    "\n",
    "fig = plt.figure(figsize= (18, 11))\n",
    "df_ASO4 = select_type_and_concat(df_map, 'ASO4')\n",
    "fig = sns.heatmap(df_ASO4.T, vmin= 0, vmax= 0.0538157813064139, cmap= 'Oranges', annot= False, xticklabels= day_heat, yticklabels= dza, linecolor= 'white', linewidth= 0.5)\n",
    "plt.title('ASO4-September')\n",
    "#plt.savefig('/home/andtoro/project_enea/heatmaps/sep23/ASO4_0923.pdf', format= 'pdf')\n",
    "\n",
    "fig = plt.figure(figsize= (18, 11))\n",
    "df_ANO3 = select_type_and_concat(df_map, 'ANO3')\n",
    "fig = sns.heatmap(df_ANO3.T, vmin= 0, vmax= 0.0538157813064139, cmap= 'Oranges', annot= False, xticklabels= day_heat, yticklabels= dza, linecolor= 'white', linewidth= 0.5)\n",
    "plt.title('ANO3-September')\n",
    "#plt.savefig('/home/andtoro/project_enea/heatmaps/sep23/ANO3_0923.pdf', format= 'pdf')\n",
    "\n",
    "fig = plt.figure(figsize= (18, 11))\n",
    "df_OTHER = select_type_and_concat(df_map, 'OTHER')\n",
    "fig = sns.heatmap(df_OTHER.T, vmin= 0, vmax=0.0538157813064139, cmap= 'Oranges', annot= False, xticklabels= day_heat, yticklabels= dza, linecolor= 'white', linewidth= 0.5)\n",
    "plt.title('OTHER-September')\n",
    "#plt.savefig('/home/andtoro/project_enea/heatmaps/sep23/OTHER_0923.pdf', format= 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def select_type_and_concat(df, layer_type):\n",
    "    columns = [f'{layer_type}_layer_{i}' for i in range(13, -1, -1)]\n",
    "    return pd.concat([df[col] for col in columns], axis=1)\n",
    "\n",
    "# Reverse altitude data for plotting\n",
    "dzT = np.array(dz)[::-1]\n",
    "dza = np.array(alt)[::-1]\n",
    "h = np.array(alt)\n",
    "\n",
    "# Create a grid of 5x12 subplots\n",
    "fig, axes = plt.subplots(5, 12, figsize=(25, 15), constrained_layout=True, sharex= True, sharey= True)\n",
    "layer_types = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER']\n",
    "vmin, vmax = 0, 0.0538157813064139\n",
    "cmap = plt.cm.Oranges\n",
    "\n",
    "# Loop through each layer type and each month\n",
    "for i, layer_type in enumerate(layer_types):\n",
    "    for month in range(1, 13):\n",
    "\n",
    "        if (9 <= month <= 12):\n",
    "            df_heat = df_LAY['M24'][(df_LAY['M24']['time'].dt.month == month) & (df_LAY['M24']['time'].dt.year == 2023)]\n",
    "            day_heat = df_LAY['M24'][(df_LAY['M24']['time'].dt.month == month) & (df_LAY['M24']['time'].dt.year == 2023)]['time'].dt.day.to_numpy()\n",
    "        else: \n",
    "            df_heat = df_LAY['M24'][(df_LAY['M24']['time'].dt.month == month) & (df_LAY['M24']['time'].dt.year == 2024)]\n",
    "            day_heat = df_LAY['M24'][(df_LAY['M24']['time'].dt.month == month) & (df_LAY['M24']['time'].dt.year == 2024)]['time'].dt.day.to_numpy()\n",
    "        \n",
    "        df_map = df_heat.drop(['time', 'REL', 'HMIX', 'AOD', 'FARM', '675nm', '500nm', 'LMP',\\\n",
    "                               'err_550', '440nm', 'pw', 'ang_440_870', 'ang_440_675', 'ang_500_870',\\\n",
    "                               'year', 'month', 'day', 'h', 'm', 's', 'n', 'IMP1F', 'IMP2F'], axis=1)\n",
    "        df_layer = select_type_and_concat(df_map, layer_type)\n",
    "        \n",
    "        # Create heatmap in the corresponding subplot\n",
    "        ax = axes[i, month - 1]\n",
    "        sns.heatmap(df_layer.T, ax=ax, vmin=vmin, vmax=vmax, cmap='Oranges', annot=False, xticklabels=day_heat, yticklabels=dza if (month == 1) else [], cbar=False, \\\n",
    "                    linecolor='white', linewidth=0.5)\n",
    "        \n",
    "        if i == 4:  # Last row (i = 4)\n",
    "            ax.set_xlabel('Day', fontsize=8, orientation= 'vertical')\n",
    "        #if month == 1:  # First column (month == 1)\n",
    "        #    ax.set_ylabel('Altitude', fontsize=8)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "fig.suptitle('Heatmaps for Different Layers Across Months', fontsize=16)\n",
    "#fig.tight_layout(pad= 2.0)\n",
    "fig.colorbar(sm, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "#plt.savefig('/home/andtoro/project_enea/heatmaps/layer_months_grid.pdf', format='pdf')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import calendar \n",
    "# def select_type_and_concat(df, layer_type):\n",
    "#     columns = [f'{layer_type}_layer_{i}' for i in range(13, -1, -1)]\n",
    "#     return pd.concat([df[col] for col in columns], axis=1)\n",
    "\n",
    "# # Reverse altitude data for plotting\n",
    "# dzT = np.array(dz)[::-1]\n",
    "# dza = np.array(alt)[::-1]\n",
    "# h = np.array(alt)\n",
    "\n",
    "# #custom_month_order = list(range(9, 13)) + list(range(1, 9))  # [9, 10, 11, 12, 1, 2, ..., 8]\n",
    "# #custom_month_labels = [calendar.month_abbr[m] for m in custom_month_order]\n",
    "# #custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug']\n",
    "# custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May']\n",
    "\n",
    "# # Create a grid of 5x12 subplots\n",
    "# fig, axes = plt.subplots(6, 1, figsize=(20, 10), constrained_layout=True, sharex= True, sharey= True)\n",
    "# layer_types = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER', 'AEC']\n",
    "# vmin, vmax = 0, 0.0538157813064139\n",
    "# cmap = plt.cm.Oranges\n",
    "\n",
    "# # Loop through each layer type and each month\n",
    "# for i, layer_type in enumerate(layer_types):\n",
    "#     df_heat = df_LAY_IMP2['M24']\n",
    "#     day_heat = df_LAY_IMP2['M24']['time'].dt.day.to_numpy()\n",
    "#     df_map = df_heat.drop(['time', 'REL', 'HMIX', 'AOD', 'FARM', '675nm', '500nm', 'LMP',\\\n",
    "#             'err_550', 'ang_440_870', 'ang_440_675',\\\n",
    "#             'year', 'month', 'day', 'h', 'm', 's', 'n', 'IMP1F', 'IMP2F'], axis=1)\n",
    "#     df_layer = select_type_and_concat(df_map, layer_type)\n",
    "#     ax = axes[i]\n",
    "#     sns.heatmap(df_layer.T, ax=ax, vmin=vmin, vmax=vmax, cmap='Oranges', annot=False, xticklabels= day_heat, yticklabels=dza, cbar=False, \\\n",
    "#         linecolor=None, linewidth=0.5)\n",
    "#     if layer_type == \"ASOIL\": \n",
    "#          ax.set_ylabel(\"DUST\", fontsize= 16, fontweight= 'bold')\n",
    "#     else:\n",
    "#          ax.set_ylabel(f'{layer_type}', fontsize= 16, fontweight= 'bold')\n",
    "#         #ax.set_xticklabels([])\n",
    "#     if i == 5:  # Last row (i = 4)\n",
    "#         #for k, month in enumerate(custom_labels):\n",
    "#             num_days = len(df_LAY_IMP2['M24']['time'].dt.day.to_numpy())\n",
    "#             tick_positions = list(range(1, num_days, 25))\n",
    "#             #tick_labels = [custom_labels[k] for _ in tick_positions]\n",
    "#             ax.set_xticks(tick_positions)\n",
    "#             ax.set_xticklabels(custom_labels, fontsize=12, fontweight=\"bold\")\n",
    "#     else:\n",
    "#         ax.tick_params(labelbottom=False)\n",
    "\n",
    "# sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# sm.set_array([])\n",
    "# fig.suptitle('Heatmaps for Different Layers Across Months', fontsize=16, fontweight=\"bold\")\n",
    "# #fig.tight_layout(pad= 2.0)\n",
    "# fig.colorbar(sm, ax=axes, orientation='vertical', fraction=0.02, pad=0.04, label= 'AOD of the species linked to the layer')\n",
    "# #cbar.set_label('AOD of the species linked to the layer')\n",
    "# #fig.text(0.05, 0.52, 'Layers', va='center', rotation='vertical', fontsize=16, fontweight= 'bold')\n",
    "# fig.text(0.5, -0.03, 'Months', ha='center', fontsize=16, fontweight= 'bold')\n",
    "# #plt.savefig('/home/andtoro/figure/heatmap_layer_months_grid_IMP2.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import calendar \n",
    "# from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# def select_type_and_concat(df, layer_type, norm):\n",
    "#     columns = [f's_{layer_type}_l_{i}' for i in range(3, -1, -1)]\n",
    "#     df_new = pd.DataFrame()\n",
    "#     for col in columns:\n",
    "#         df_new[col]= (df[col]/norm)\n",
    "#     return df_new\n",
    "\n",
    "# # Reverse altitude data for plotting\n",
    "# alt = ['(0-40)m', '(40-90)m', '(90-160)m', '(160-260)m', '(260-390)m', '(390-570)m', '(570-810)m', '(810-1140)m', '(1140-1580)m', \n",
    "#          '(1580-2180)m', '(2180-2980)m', '(2980-4070)m', '(4070-5540)m', '(5540-7040)m']\n",
    "# dzT = np.array(dz)[::-1]\n",
    "# dza = np.array(alt)[::-1]\n",
    "# h = np.array(alt)\n",
    "# dz_new = np.array(['(0-390)m', '(390-1140)m', '(1140-2980)m', '(2980-7040)m'])[::-1]\n",
    "# #custom_month_order = list(range(9, 13)) + list(range(1, 9))  # [9, 10, 11, 12, 1, 2, ..., 8]\n",
    "# #custom_month_labels = [calendar.month_abbr[m] for m in custom_month_order]\n",
    "# #custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug']\n",
    "# custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr']\n",
    "\n",
    "# # Create a grid of 5x12 subplots\n",
    "# fig, axes = plt.subplots(6, 1, figsize=(20, 10), constrained_layout=True, sharex= True, sharey= True)\n",
    "# layer_types = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER', 'AEC']\n",
    "# vmin, vmax = 0, 1\n",
    "# colors = [\"#d73027\", \"#fc8d59\", \"#fee08b\", \"#d9ef8b\", \"#91cf60\", \"#1a9850\"]\n",
    "# cmap = ListedColormap(colors)\n",
    "\n",
    "# # Define the boundaries for the discrete bins\n",
    "# bounds = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "# norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# #cmap = LinearSegmentedColormap.from_list(\"my_pal\", color_palette)\n",
    "# # bounds = np.linspace(0, 1, len(color_palette) + 1)  # Adjust as needed\n",
    "# # norm = BoundaryNorm(boundaries=bounds, ncolors=len(color_palette))\n",
    "# #cmap = sns.color_palette(palette=\"tab10\", n_colors=10, desat=None, as_cmap=True)# reverse palette by adding _r\n",
    "# #cmap = sns.cubehelix_palette(start=.5, rot=-.75, dark=0, light=.95, reverse=False, as_cmap=True)\n",
    "# #cmap = sns.dark_palette(\"#69d\", reverse=True, as_cmap=True)\n",
    "# #cmap = sns.light_palette(\"seagreen_r\", reverse=True, as_cmap=True)\n",
    "\n",
    "# # Loop through each layer type and each month\n",
    "# for i, layer_type in enumerate(layer_types):\n",
    "#     df_heat = df_LAY_IMP2['1D']\n",
    "#     day_heat = df_LAY_IMP2['1D']['time'].dt.day.to_numpy()\n",
    "#     df_map = df_heat.drop(['time', 'REL_x', 'HMIX_x', 'AOD_x', 'FARM_x', '675nm_x', '500nm_x',\n",
    "#        'LMP_x', 'err_550_x', 'ang_440_870_x',\n",
    "#        'ang_440_675_x', 'year_x', 'month_x', 'day_x', 'h_x',\n",
    "#        'm_x', 's_x', 'n_x', 'IMP1F_x', 'IMP2F_x', 'err_1h_x', 'REL_y',\n",
    "#        'HMIX_y', 'AOD_y', 'FARM_y', '675nm_y', '500nm_y', 'LMP_y', 'err_550_y',\n",
    "#        'ang_440_870_y', 'ang_440_675_y',\n",
    "#        'year_y', 'month_y', 'day_y', 'h_y', 'm_y', 's_y', 'n_y', 'IMP1F_y',\n",
    "#        'IMP2F_y', 'err_1h_y'], axis=1)\n",
    "#     df_layer = select_type_and_concat(df_map, layer_type, df_LAY_IMP2['1D']['IMP2F_x'])\n",
    "#     ax = axes[i]\n",
    "#     sns.heatmap(df_layer.T,\n",
    "#                 ax=ax,\n",
    "#                 vmin=vmin,\n",
    "#                 vmax=vmax,\n",
    "#                 cmap=cmap,\n",
    "#                 norm=norm,\n",
    "#                 annot=False,\n",
    "#                 xticklabels=day_heat,\n",
    "#                 yticklabels=dz_new,\n",
    "#                 cbar=False,\n",
    "#                 #cbar_kws={'ticks': range(10)},\n",
    "#                 linecolor=None,\n",
    "#                 linewidth=0.5\n",
    "#                 )\n",
    "#     if layer_type == \"ASOIL\":\n",
    "#         ax.set_ylabel(\"DUST\", fontsize= 16, fontweight= 'bold')\n",
    "#     else:\n",
    "#         ax.set_ylabel(f'{layer_type}', fontsize= 16, fontweight= 'bold')\n",
    "#         #ax.set_xticklabels([])\n",
    "#     if i == 5:  # Last row (i = 4)\n",
    "#         #for k, month in enumerate(custom_labels):\n",
    "#             num_days = len(df_LAY_IMP2['1D']['time'].dt.day.to_numpy())\n",
    "#             print(num_days)\n",
    "#             exit\n",
    "#             tick_positions = list(range(1, num_days, 25))\n",
    "#             #tick_labels = [custom_labels[k] for _ in tick_positions]\n",
    "#             ax.set_xticks(tick_positions)\n",
    "#             ax.set_xticklabels(custom_labels, fontsize=16)\n",
    "#     else:\n",
    "#         ax.tick_params(labelbottom=False)\n",
    "\n",
    "\n",
    "# fig, ax = plt.gcf(), plt.gca()\n",
    "# cbar = fig.colorbar(\n",
    "#     plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "#     ax=ax,\n",
    "#     boundaries=bounds,\n",
    "#     ticks=bounds[:-1]  # Show tick marks only for the bins\n",
    "# )\n",
    "# cbar.ax.set_ylabel('Value', rotation=270, labelpad=25, fontsize=16, fontweight= 'bold')\n",
    "# fig.suptitle('Heatmaps for Different Layers Across Months', fontsize=16, fontweight= 'bold')\n",
    "# fig.text(0.5, -0.03, 'Months', ha='center', fontsize=16, fontweight= 'bold')\n",
    "# #plt.savefig('/home/andtoro/project_enea/heatmaps/layer_months_grid.pdf', format='pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "def select_type_and_concat(df, layer_type, norm):\n",
    "    \"\"\"\n",
    "    Normalize and concatenate columns for a specific layer type.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        layer_type (str): Layer type to select (e.g., 'ASOIL', 'ASEAS').\n",
    "        norm (float): Normalization factor.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Normalized DataFrame for the specified layer type.\n",
    "    \"\"\"\n",
    "    columns = [f's_{layer_type}_l_{i}' for i in range(3, -1, -1)]\n",
    "    df_new = pd.DataFrame()\n",
    "    for col in columns:\n",
    "        df_new[col] = df[col] / norm\n",
    "    return df_new\n",
    "\n",
    "alt = ['(0-40)m', '(40-90)m', '(90-160)m', '(160-260)m', '(260-390)m', '(390-570)m', '(570-810)m', '(810-1140)m', '(1140-1580)m', \n",
    "         '(1580-2180)m', '(2180-2980)m', '(2980-4070)m', '(4070-5540)m', '(5540-7040)m']\n",
    "# Reverse altitude data for plotting\n",
    "dzT = np.array(dz)[::-1]\n",
    "dza = np.array(alt)[::-1]\n",
    "h = np.array(alt)\n",
    "dz_new = np.array(['(0-390)m', '(390-1140)m', '(1140-2980)m', '(2980-7040)m'])[::-1]\n",
    "custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug']\n",
    "\n",
    "# Create a grid of 6x1 subplots\n",
    "fig, axes = plt.subplots(6, 1, figsize=(20, 10), constrained_layout=True, sharex=True, sharey=True)\n",
    "layer_types = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER', 'AEC']\n",
    "vmin, vmax = 0, 1\n",
    "colors = [\"#d73027\", \"#fc8d59\", \"#fee08b\", \"#d9ef8b\", \"#91cf60\", \"#1a9850\"]\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Loop through each layer type and plot heatmaps\n",
    "for i, layer_type in enumerate(layer_types):\n",
    "    df_heat = df_LAY_IMP2['1D']\n",
    "    day_heat = df_heat['time'].dt.day.to_numpy()\n",
    "    df_map = df_heat.drop(['time', 'REL_x', 'HMIX_x', 'AOD_x', 'FARM_x', '675nm_x', '500nm_x',\n",
    "                           'LMP_x', 'err_550_x', '440nm_x', 'pw_x', 'ang_440_870_x',\n",
    "                           'ang_440_675_x', 'ang_500_870_x', 'year_x', 'month_x', 'day_x', 'h_x',\n",
    "                           'm_x', 's_x', 'n_x', 'IMP1F_x', 'IMP2F_x', 'err_1h_x', 'REL_y',\n",
    "                           'HMIX_y', 'AOD_y', 'FARM_y', '675nm_y', '500nm_y', 'LMP_y', 'err_550_y',\n",
    "                           '440nm_y', 'pw_y', 'ang_440_870_y', 'ang_440_675_y', 'ang_500_870_y',\n",
    "                           'year_y', 'month_y', 'day_y', 'h_y', 'm_y', 's_y', 'n_y', 'IMP1F_y',\n",
    "                           'IMP2F_y', 'err_1h_y'], axis=1)\n",
    "    df_layer = select_type_and_concat(df_map, layer_type, df_heat['IMP2F_x'])\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(df_layer.T,\n",
    "                ax=ax,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                annot=False,\n",
    "                xticklabels=day_heat,\n",
    "                yticklabels=dz_new,\n",
    "                cbar=False,\n",
    "                linecolor=None,\n",
    "                linewidth=0.5)\n",
    "    if layer_type == \"ASOIL\":\n",
    "        ax.set_ylabel(\"DUST\", fontsize=16, fontweight='bold')\n",
    "    else: \n",
    "        ax.set_ylabel(f'{layer_type}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Add month labels to the last row\n",
    "    if i == 5:\n",
    "        num_days = len(day_heat)\n",
    "        tick_positions = list(range(1, num_days, 25))\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(custom_labels, fontsize=16)\n",
    "    else:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "\n",
    "# Add a shared colorbar\n",
    "cbar = fig.colorbar(\n",
    "    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "    ax=axes,\n",
    "    boundaries=bounds,\n",
    "    ticks=bounds[:-1]\n",
    ")\n",
    "cbar.ax.set_ylabel('Value', rotation=270, labelpad=25, fontsize=16, fontweight='bold')\n",
    "\n",
    "# Add titles and labels\n",
    "fig.suptitle('Heatmaps for Different Layers Across Months', fontsize=16, fontweight='bold')\n",
    "fig.text(0.5, -0.03, 'Months', ha='center', fontsize=16, fontweight='bold')\n",
    "#plt.savefig('/home/andtoro/figure/heatmap_layer_new_grid.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define a grid of subplots\n",
    "fig, axes = plt.subplots(6, 1, figsize=(20, 10), constrained_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "def select_type_and_concat(df, layer_type, norm):\n",
    "    \"\"\"\n",
    "    Normalize and concatenate columns for a specific layer type.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        layer_type (str): Layer type to select (e.g., 'ASOIL', 'ASEAS').\n",
    "        norm (float): Normalization factor.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Normalized DataFrame for the specified layer type.\n",
    "    \"\"\"\n",
    "    columns = [f's_{layer_type}_l_{i}' for i in range(3, -1, -1)]\n",
    "    df_new = pd.DataFrame()\n",
    "    for col in columns:\n",
    "        df_new[col] = df[col] / norm\n",
    "    return df_new\n",
    "\n",
    "colors = [\n",
    "    \"#FFFFFF\",  # White\n",
    "    \"#FF0000\",  # Red\n",
    "    \"#FF7F00\",  # Orange\n",
    "    \"#FFFF00\",  # Yellow\n",
    "    \"#00FF00\",  # Green\n",
    "    \"#0000FF\",  # Blue\n",
    "    \"#4B0082\",  # Indigo\n",
    "    \"#9400D3\",  # Violet\n",
    "    \"#800080\",  # Purple\n",
    "    \"#4B0082\"   # Darker Indigo\n",
    "]\n",
    "layer_types = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER', 'AEC']\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "dz_new = np.array(['(0-390)m', '(390-1140)m', '(1140-2980)m', '(2980-7040)m'])[::-1]\n",
    "custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug']\n",
    "\n",
    "# Heatmap plotting loop\n",
    "for i, layer_type in enumerate(layer_types):\n",
    "    df_layer = select_type_and_concat(df_LAY_IMP2['1D'], layer_type, df_LAY_IMP2['1D']['IMP2F_x'])\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(\n",
    "        df_layer.T,\n",
    "        ax=ax,\n",
    "        vmin=0, vmax=1, cmap=cmap, norm=norm,\n",
    "        annot=False, xticklabels=day_heat, yticklabels=dz_new,\n",
    "        cbar=False, linewidth=0.01, linecolor=\"gray\"\n",
    "    )\n",
    "    if layer_type == \"ASOIL\":\n",
    "        ax.set_ylabel(\"DUST\", fontsize=16, fontweight='bold')\n",
    "    else:\n",
    "        ax.set_ylabel(layer_type, fontsize=16, fontweight='bold')\n",
    "    if i == 5:  # Last row for month labels\n",
    "        tick_positions = list(range(1, 295, 25))\n",
    "        #tick_positions = np.linspace(1, len(day_heat), len(custom_labels), dtype=int)\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(custom_labels, fontsize=16)\n",
    "    else:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(\n",
    "    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "    ax=axes, orientation='vertical', fraction=0.02, pad=0.04\n",
    ")\n",
    "cbar.set_label(r'$\\frac{\\tau_{LAYER}}{\\tau_{COLUMN}}$', rotation=270, labelpad=15, fontsize=12)\n",
    "\n",
    "# Add title and axis labels\n",
    "fig.suptitle('Heatmaps for Different Layers Across Months', fontsize=16, fontweight=\"bold\")\n",
    "fig.text(0.5, -0.03, 'Months', ha='center', fontsize=16, fontweight='bold')\n",
    "#plt.savefig('/home/andtoro/figure/heatmap_layer_new_color_grid_IMP1.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "sep_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 9) & (df_LAY_IMP1['1D']['time'].dt.year == 2023)].count()\n",
    "oct_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 10) & (df_LAY_IMP1['1D']['time'].dt.year == 2023)].count()\n",
    "nov_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 11) & (df_LAY_IMP1['1D']['time'].dt.year == 2023)].count()\n",
    "dec_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 12) & (df_LAY_IMP1['1D']['time'].dt.year == 2023)].count()\n",
    "jan_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 1) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "feb_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 2) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "mar_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 3) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "apr_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 4) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "may_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 5) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "jun_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 6) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "jul_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 7) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "aug_d = df_LAY_IMP1['1D'][(df_LAY_IMP1['1D']['time'].dt.month == 8) & (df_LAY_IMP1['1D']['time'].dt.year == 2024)].count()\n",
    "\n",
    "# Define a grid of subplots\n",
    "fig, axes = plt.subplots(6, 1, figsize=(20, 10), constrained_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "def select_type_and_concat(df, layer_type, norm):\n",
    "    \"\"\"\n",
    "    Normalize and concatenate columns for a specific layer type.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        layer_type (str): Layer type to select (e.g., 'ASOIL', 'ASEAS').\n",
    "        norm (float): Normalization factor.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Normalized DataFrame for the specified layer type.\n",
    "    \"\"\"\n",
    "    columns = [f's_{layer_type}_l_{i}' for i in range(3, -1, -1)]\n",
    "    df_new = pd.DataFrame()\n",
    "    for col in columns:\n",
    "        df_new[col] = df[col] / norm\n",
    "    return df_new\n",
    "\n",
    "colors = [\n",
    "    \"#FFFFFF\",  # White\n",
    "    \"#FF0000\",  # Red\n",
    "    \"#FF7F00\",  # Orange\n",
    "    \"#FFFF00\",  # Yellow\n",
    "    \"#00FF00\",  # Green\n",
    "    \"#0000FF\",  # Blue\n",
    "    \"#4B0082\",  # Indigo\n",
    "    \"#9400D3\",  # Violet\n",
    "    \"#800080\",  # Purple\n",
    "    \"#4B0082\"   # Darker Indigo\n",
    "]\n",
    "layer_types = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER', 'AEC']\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "dz_new = np.array(['(0-390)m', '(390-1140)m', '(1140-2980)m', '(2980-7040)m'])[::-1]\n",
    "custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug']\n",
    "\n",
    "# Heatmap plotting loop\n",
    "for i, layer_type in enumerate(layer_types):\n",
    "    df_layer = select_type_and_concat(df_LAY_IMP1['1D'], layer_type, df_LAY_IMP1['1D']['IMP1F_x'])\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(\n",
    "        df_layer.T,\n",
    "        ax=ax,\n",
    "        vmin=0, vmax=1, cmap=cmap, norm=norm,\n",
    "        annot=False, xticklabels=day_heat, yticklabels=dz_new,\n",
    "        cbar=False, linewidth=0.01, linecolor=\"gray\"\n",
    "    )\n",
    "    if layer_type == \"ASOIL\":\n",
    "        ax.set_ylabel(\"DUST\", fontsize=16, fontweight='bold')\n",
    "    else:\n",
    "        ax.set_ylabel(layer_type, fontsize=16, fontweight='bold')\n",
    "    if i == 5:  # Last row for month labels\n",
    "        # Calculate midpoints for each month's data\n",
    "        month_lengths = [sep_d['time'], oct_d['time'], nov_d['time'], dec_d['time'],\n",
    "                        jan_d['time'], feb_d['time'], mar_d['time'], apr_d['time'], may_d['time'], jun_d['time'],\n",
    "                        jul_d['time'], aug_d['time']]\n",
    "        start = 0\n",
    "        midpoints = []\n",
    "        endpoints = []\n",
    "        for m_len in month_lengths:\n",
    "            end = start + m_len - 1\n",
    "            mid = (start + end) / 2\n",
    "            midpoints.append(mid)\n",
    "            endpoints.append(end)\n",
    "            start += m_len\n",
    "        ax.set_xticks(endpoints)\n",
    "        ax.set_xticklabels(custom_labels, fontsize=16)\n",
    "    else:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(\n",
    "    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "    ax=axes, orientation='vertical', fraction=0.02, pad=0.04\n",
    ")\n",
    "cbar.set_label(r'$\\frac{\\tau_{LAYER}}{\\tau_{COLUMN}}$', rotation=360, labelpad=15, fontsize=18)\n",
    "\n",
    "# Add title and axis labels\n",
    "fig.suptitle('Heatmaps for Different Layers Across Months', fontsize=16, fontweight=\"bold\")\n",
    "fig.text(0.5, -0.03, 'Months', ha='center', fontsize=16, fontweight='bold')\n",
    "#plt.savefig('/home/andtoro/figure/heatmap_layer_new_color_grid_IMP1.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar \n",
    "def select_type_and_concat(df, layer_type):\n",
    "    columns = [f'{layer_type}_layer_{i}' for i in range(13, -1, -1)]\n",
    "    return pd.concat([df[col] for col in columns], axis=1)\n",
    "\n",
    "# Reverse altitude data for plotting\n",
    "alt = np.array(['(0-390)m', '(390-1140)m', '(1140-2980)m', '(2980-7040)m'])[::-1]\n",
    "dzT = np.array(dz)[::-1]\n",
    "dza = np.array(alt)[::-1]\n",
    "h = np.array(alt)\n",
    "\n",
    "#custom_month_order = list(range(9, 13)) + list(range(1, 9))  # [9, 10, 11, 12, 1, 2, ..., 8]\n",
    "#custom_month_labels = [calendar.month_abbr[m] for m in custom_month_order]\n",
    "custom_labels = ['Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug']\n",
    "\n",
    "# Create a grid of 5x12 subplots\n",
    "fig, axes = plt.subplots(6, 1, figsize=(20, 10), constrained_layout=True, sharex= True, sharey= True)\n",
    "layer_types = ['ASOIL', 'ASEAS', 'ASO4', 'ANO3', 'OTHER', 'AEC']\n",
    "vmin, vmax = 0, 0.0538157813064139\n",
    "cmap = plt.cm.Oranges\n",
    "\n",
    "# Loop through each layer type and each month\n",
    "for i, layer_type in enumerate(layer_types):\n",
    "    df_heat = df_LAY_IMP2['M24']\n",
    "    day_heat = df_LAY_IMP2['M24']['time'].dt.day.to_numpy()\n",
    "    df_map = df_heat.drop(['time', 'REL', 'HMIX', 'AOD', 'FARM', '675nm', '500nm', 'LMP',\\\n",
    "            'err_550', '440nm', 'pw', 'ang_440_870', 'ang_440_675', 'ang_500_870',\\\n",
    "            'year', 'month', 'day', 'h', 'm', 's', 'n', 'IMP1F', 'IMP2F'], axis=1)\n",
    "    df_layer = select_type_and_concat(df_map, layer_type)\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(df_layer.T, ax=ax, vmin=vmin, vmax=vmax, cmap='Oranges', annot=False, xticklabels= day_heat, yticklabels=dza, cbar=False, \\\n",
    "        linecolor=None, linewidth=0.5)\n",
    "    if layer_type == \"ASOIL\": \n",
    "         ax.set_ylabel(\"DUST\", fontsize= 16, fontweight= 'bold')\n",
    "    else:\n",
    "         ax.set_ylabel(f'{layer_type}', fontsize= 16, fontweight= 'bold')\n",
    "        #ax.set_xticklabels([])\n",
    "    if i == 5:  # Last row for month labels\n",
    "        # Calculate midpoints for each month's data\n",
    "        month_lengths = [sep_d['time'], oct_d['time'], nov_d['time'], dec_d['time'],\n",
    "                        jan_d['time'], feb_d['time'], mar_d['time'], apr_d['time'], may_d['time'], jun_d['time'],\n",
    "                        jul_d['time'], aug_d['time']]\n",
    "        start = 0\n",
    "        midpoints = []\n",
    "        endpoints = []\n",
    "        for m_len in month_lengths:\n",
    "            end = start + m_len - 1\n",
    "            mid = (start + end) / 2\n",
    "            midpoints.append(mid)\n",
    "            endpoints.append(end)\n",
    "            start += m_len\n",
    "        ax.set_xticks(endpoints)\n",
    "        ax.set_xticklabels(custom_labels, fontsize=16)\n",
    "    else:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "fig.suptitle('Heatmaps for Different Layers Across Months', fontsize=16, fontweight=\"bold\")\n",
    "#fig.tight_layout(pad= 2.0)\n",
    "fig.colorbar(sm, ax=axes, orientation='vertical', fraction=0.02, pad=0.04, label= 'AOD of the species linked to the layer')\n",
    "#cbar.set_label('AOD of the species linked to the layer')\n",
    "#fig.text(0.05, 0.52, 'Layers', va='center', rotation='vertical', fontsize=16, fontweight= 'bold')\n",
    "fig.text(0.5, -0.03, 'Months', ha='center', fontsize=16, fontweight= 'bold')\n",
    "#plt.savefig('/home/andtoro/figure/heatmap_layer_months_grid_IMP2.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression (ODR):\n",
    "### Estimate a coefficient to improve the IMPROVE algorithm, doing so on the ASOIL component that is independent on relative humidity and then run again the algorithm to see if there is a better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "\n",
    "DeDu24_f_outliers= DeDu24_f.drop([39, 40], axis= 0)\n",
    "#DD_fit_clean = DeDu24_f_outliers[(DeDu24_f_outliers['err_IMP1_24'] > 1e-2) & (DeDu24_f_outliers['err_IMP2_24'] > 1e-2)]\n",
    "\n",
    "# data_obs = DD_fit_clean['LMP']\n",
    "# data_farm = DD_fit_clean['FARM']\n",
    "# data_imp1 = DD_fit_clean['IMP1F']\n",
    "# data_imp2 = DD_fit_clean['IMP2F']\n",
    "# errObs = DD_fit_clean['err_day_new']\n",
    "# errImp1 = DD_fit_clean['err_IMP1_24']\n",
    "# errImp2 = DD_fit_clean['err_IMP2_24']\n",
    "\n",
    "\n",
    "# dataObs = DeDu['LMP']\n",
    "# dataFarm = DeDu['FARM']\n",
    "# dataImp1 = DeDu['IMP1F']\n",
    "# dataImp2 = DeDu['IMP2F']\n",
    "# err_Obs = DeDu['err_new']\n",
    "# err_Imp1 = DeDu['err_IMP1']\n",
    "# err_Imp2 = DeDu['err_IMP2']\n",
    "\n",
    "# dataObs = DeDu24_f_outliers['LMP']\n",
    "# dataFarm = DeDu24_f_outliers['FARM']\n",
    "# dataImp1 = DeDu24_f_outliers['IMP1F']\n",
    "# dataImp2 = DeDu24_f_outliers['IMP2F']\n",
    "# err_Obs = DeDu24_f_outliers['err_day_new']\n",
    "# err_Imp1 = DeDu24_f_outliers['err_IMP1_24']\n",
    "# err_Imp2 = DeDu24_f_outliers['err_IMP2_24']\n",
    "\n",
    "# dataObs = DeDu24_f['LMP']\n",
    "# dataFarm = DeDu24_f['FARM']\n",
    "# dataImp1 = DeDu24_f['IMP1F']\n",
    "# dataImp2 = DeDu24_f['IMP2F']\n",
    "# err_Obs = DeDu24_f['err_day_new']\n",
    "# err_Imp1 = DeDu24_f['err_IMP1_24']\n",
    "# err_Imp2 = DeDu24_f['err_IMP2_24']\n",
    "\n",
    "DD_no_zero = DeDu24[(DeDu24['err_day_new'] != 0.0) & (DeDu24['err_IMP1_24'] != 0.0) & (DeDu24['err_IMP2_24'] != 0.0)]\n",
    "\n",
    "dataObs = DD_no_zero['LMP']\n",
    "dataFarm = DD_no_zero['FARM']\n",
    "dataImp1 = DD_no_zero['IMP1F']\n",
    "dataImp2 = DD_no_zero['IMP2F']\n",
    "err_Obs = DD_no_zero['err_day_new']\n",
    "err_Imp1 = DD_no_zero['err_IMP1_24']\n",
    "err_Imp2 = DD_no_zero['err_IMP2_24']\n",
    "\n",
    "#np.savetxt(\"data_obs.txt\", np.column_stack((data_obs, dataImp1, dataImp2, err_Obs, err_Imp1, err_Imp2)))\n",
    "\n",
    "def linear_model(B, x):\n",
    "    m, c = B\n",
    "    return m * x + c\n",
    "\n",
    "model = Model(linear_model)\n",
    "\n",
    "x_obs = np.array(dataObs)*2\n",
    "y_imp1 = np.array(dataImp1)*2\n",
    "y_imp2 = np.array(dataImp2)*2\n",
    "x_err_obs = np.array(err_Obs)\n",
    "y_err_imp1 = np.array(err_Imp1)\n",
    "y_err_imp2 = np.array(err_Imp2) \n",
    "\n",
    "data1 = RealData(x_obs, y_imp1, sx=x_err_obs, sy=y_err_imp1)\n",
    "data2 = RealData(x_obs, y_imp2, sx=x_err_obs, sy=y_err_imp2)\n",
    "\n",
    "odr1 = ODR(data1, model, beta0=[1.0, 0.0])\n",
    "odr2 = ODR(data2, model, beta0=[1.0, 0.0])\n",
    "output_1 = odr1.run()\n",
    "output_2 = odr2.run()\n",
    "\n",
    "params_1 = output_1.beta\n",
    "param_errors_1 = output_1.sd_beta \n",
    "params_2 = output_2.beta\n",
    "param_errors_2 = output_2.sd_beta \n",
    "\n",
    "print(\"Fitted parameters IMP1:\", params_1)\n",
    "print(\"Parameter errors IMP1:\", param_errors_1)\n",
    "print(\"Chi2 IMP1:\", output_1.sum_square)\n",
    "print(\"Chi2 IMP2:\", output_2.sum_square)\n",
    "print(\"Fitted parameters IMP2:\", params_2)\n",
    "print(\"Parameter errors IMP2:\", param_errors_2)\n",
    "print(\"dof:\", len(dataObs))\n",
    "\n",
    "x_fit_1 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "y_fit_1 = linear_model(params_1, x_fit_1)\n",
    "x_fit_2 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "y_fit_2 = linear_model(params_2, x_fit_2)\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, y_imp1, xerr=x_err_obs, yerr=y_err_imp1, fmt='.', label='Data')\n",
    "plt.plot(x_fit_1, y_fit_1, label='Fit', color='red')\n",
    "plt.xlabel('LMP', fontweight=\"bold\")\n",
    "plt.ylabel('IMP1F', fontweight=\"bold\")\n",
    "plt.title('DD events fit IMP1F', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, y_imp2, xerr=x_err_obs, yerr=y_err_imp2, fmt='.', label='Data')\n",
    "plt.plot(x_fit_2, y_fit_2, label='Fit', color='red')\n",
    "plt.xlabel('LMP', fontweight=\"bold\")\n",
    "plt.ylabel('IMP2F', fontweight=\"bold\")\n",
    "plt.title('DD events fit IMP2F', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# residuals \n",
    "res_1 = y_imp1 - linear_model(params_1, x_obs)\n",
    "res_2 = y_imp2 - linear_model(params_2, x_obs)\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, res_1, yerr=y_err_imp1, fmt='.', label='Residuals IMP1')\n",
    "plt.plot(x_fit_1, np.zeros(len(x_fit_1)), label='Zero line', color='orange')\n",
    "plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "plt.ylabel('Residuals IMP1', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, res_2, yerr=y_err_imp2, fmt='.', label='Residuals IMP2')\n",
    "plt.plot(x_fit_2, np.zeros(len(x_fit_2)), label='Zero line', color='orange')\n",
    "plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "plt.ylabel('Residuals IMP2', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# from scipy.optimize import curve_fit\n",
    "\n",
    "# # dataObs = DeDu24_f['LMP']\n",
    "# # dataFarm = DeDu24_f['FARM']\n",
    "# # dataImp1 = DeDu24_f['IMP1F']\n",
    "# # dataImp2 = DeDu24_f['IMP2F']\n",
    "# # err_Obs = DeDu24_f['err_day_new']\n",
    "# # err_Imp1 = DeDu24_f['err_IMP1_24']\n",
    "# # err_Imp2 = DeDu24_f['err_IMP2_24']\n",
    "\n",
    "# def model_eff(x, m, q): \n",
    "#     return x * m + q \n",
    "\n",
    "# xdata = DeDu24_f['LMP']*2\n",
    "# y1data = DeDu24_f['IMP1F']*2\n",
    "# y2data = DeDu24_f['IMP2F']*2\n",
    "# xerr_data = DeDu24_f['err_day_new']\n",
    "# y1err = DeDu24_f['err_IMP1_24']\n",
    "# y2err = DeDu24_f['err_IMP2_24']\n",
    "\n",
    "# popt, pcov = curve_fit(model_eff, xdata, y1data, sigma=y1err)\n",
    "\n",
    "# for i in range(100): \n",
    "#     err_eff = np.sqrt(xerr_data**2.0 + (popt[0]*xerr_data)**2.0)\n",
    "#     popt, pcov = curve_fit(model_eff, xdata, y1data, sigma=err_eff)\n",
    "#     chisq = (((y1data - model_eff(xdata, *popt))/(err_eff))**2.0).sum()\n",
    "#     print(f\"Step {i} ...\")\n",
    "#     print(popt, np.sqrt(pcov.diagonal()))\n",
    "#     print(f\"Chi2={chisq:.2f}\")\n",
    "\n",
    "# ymod = model_eff(xdata, popt[0], popt[1])\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.errorbar(xdata, y1data, xerr=xerr_data, yerr=y1err, fmt=\".\", label=\"data\")\n",
    "# plt.plot(xdata, ymod, label='Fit', color='red')\n",
    "# plt.xlabel('LMP', fontweight=\"bold\")\n",
    "# plt.ylabel('IMP1F', fontweight=\"bold\")\n",
    "# plt.title('DD events fit IMP1F', fontweight=\"bold\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# #plt.savefig('/home/andtoro/figure/ODR_fit_IMP1_outliers.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "from scipy.stats import t\n",
    "\n",
    "DeDu24_f_outliers= DeDu24_f.drop([39, 40], axis= 0)\n",
    "#DD_fit_clean = DeDu24_f_outliers[(DeDu24_f_outliers['err_IMP1_24'] > 1e-2) & (DeDu24_f_outliers['err_IMP2_24'] > 1e-2)]\n",
    "\n",
    "# data_obs = DD_fit_clean['LMP']\n",
    "# data_farm = DD_fit_clean['FARM']\n",
    "# data_imp1 = DD_fit_clean['IMP1F']\n",
    "# data_imp2 = DD_fit_clean['IMP2F']\n",
    "# errObs = DD_fit_clean['err_day_new']\n",
    "# errImp1 = DD_fit_clean['err_IMP1_24']\n",
    "# errImp2 = DD_fit_clean['err_IMP2_24']\n",
    "\n",
    "data_fit = pd.DataFrame({\n",
    "    'data_x': DeDu24_f_outliers['LMP']*2,\n",
    "    'sigma_x': DeDu24_f_outliers['err_day_new'],\n",
    "    'data_y_1': DeDu24_f_outliers['IMP1F']*2,\n",
    "    'sigma_y_1': DeDu24_f_outliers['err_IMP1_24'],\n",
    "    'data_y_2': DeDu24_f_outliers['IMP2F']*2,\n",
    "    'sigma_y_2': DeDu24_f_outliers['err_IMP2_24']\n",
    "})\n",
    "\n",
    "#data_fit_DD.to_csv(\"/home/andtoro/project_enea/enea_2/dati_DD.txt\", index=False, sep='\\t')\n",
    "#data_fit.to_csv(\"/home/andtoro/project_enea/enea_2/dati_fit.txt\", index=False, sep='\\t')\n",
    "\n",
    "\n",
    "# dataObs = DeDu['LMP']\n",
    "# dataFarm = DeDu['FARM']\n",
    "# dataImp1 = DeDu['IMP1F']\n",
    "# dataImp2 = DeDu['IMP2F']\n",
    "# err_Obs = DeDu['err_new']\n",
    "# err_Imp1 = DeDu['err_IMP1']\n",
    "# err_Imp2 = DeDu['err_IMP2']\n",
    "\n",
    "dataObs = DeDu24_f_outliers['LMP']\n",
    "dataFarm = DeDu24_f_outliers['FARM']\n",
    "dataImp1 = DeDu24_f_outliers['IMP1F']\n",
    "dataImp2 = DeDu24_f_outliers['IMP2F']\n",
    "err_Obs = DeDu24_f_outliers['err_day_new']\n",
    "err_Imp1 = DeDu24_f_outliers['err_IMP1_24']\n",
    "err_Imp2 = DeDu24_f_outliers['err_IMP2_24']\n",
    "\n",
    "# dataObs = DeDu24_f['LMP']\n",
    "# dataFarm = DeDu24_f['FARM']\n",
    "# dataImp1 = DeDu24_f['IMP1F']\n",
    "# dataImp2 = DeDu24_f['IMP2F']\n",
    "# err_Obs = DeDu24_f['err_day_new']\n",
    "# err_Imp1 = DeDu24_f['err_IMP1_24']\n",
    "# err_Imp2 = DeDu24_f['err_IMP2_24']\n",
    "\n",
    "#DD_no_zero = DeDu24_f[(DeDu24_f['err_day_new'] != 0.0) & (DeDu24_f['err_IMP1_24'] != 0.0) & (DeDu24_f['err_IMP2_24'] != 0.0)]\n",
    "\n",
    "# dataObs = DD_no_zero['LMP']\n",
    "# dataFarm = DD_no_zero['FARM']\n",
    "# dataImp1 = DD_no_zero['IMP1F']\n",
    "# dataImp2 = DD_no_zero['IMP2F']\n",
    "# err_Obs = DD_no_zero['err_day_new']\n",
    "# err_Imp1 = DD_no_zero['err_IMP1_24']\n",
    "# err_Imp2 = DD_no_zero['err_IMP2_24']\n",
    "\n",
    "#np.savetxt(\"data_obs.txt\", np.column_stack((data_obs, dataImp1, dataImp2, err_Obs, err_Imp1, err_Imp2)))\n",
    "\n",
    "def linear_model(B, x):\n",
    "    m, n, c = B\n",
    "    return m * x + n * x + c\n",
    "\n",
    "model = Model(linear_model)\n",
    "\n",
    "x_obs = np.array(dataObs)\n",
    "y_imp1 = np.array(dataImp1)\n",
    "y_imp2 = np.array(dataImp2)\n",
    "x_err_obs = np.array(err_Obs)\n",
    "y_err_imp1 = np.array(err_Imp1)\n",
    "y_err_imp2 = np.array(err_Imp2) \n",
    "\n",
    "data1 = RealData(x_obs, y_imp1, sx=x_err_obs, sy=y_err_imp1)\n",
    "data2 = RealData(x_obs, y_imp2, sx=x_err_obs, sy=y_err_imp2)\n",
    "\n",
    "odr1 = ODR(data1, model, beta0=[1.0, 0.6, 0.0])\n",
    "odr2 = ODR(data2, model, beta0=[1.0, 0.6, 0.0])\n",
    "output_1 = odr1.run()\n",
    "output_1.pprint()\n",
    "output_2 = odr2.run()\n",
    "output_2.pprint()\n",
    "\n",
    "params_1 = output_1.beta\n",
    "param_errors_1 = output_1.sd_beta \n",
    "params_2 = output_2.beta\n",
    "param_errors_2 = output_2.sd_beta \n",
    "\n",
    "# print(\"Fitted parameters IMP1:\", params_1)\n",
    "# print(\"Parameter errors IMP1:\", param_errors_1)\n",
    "# print(\"Chi2 IMP1:\", output_1.sum_square)\n",
    "# print(\"Chi2 IMP2:\", output_2.sum_square)\n",
    "# print(\"Fitted parameters IMP2:\", params_2)\n",
    "# print(\"Parameter errors IMP2:\", param_errors_2)\n",
    "# print(\"dof:\", len(dataObs))\n",
    "\n",
    "x_fit_1 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "y_fit_1 = linear_model(params_1, x_fit_1)\n",
    "x_fit_2 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "y_fit_2 = linear_model(params_2, x_fit_2)\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, y_imp1, xerr=x_err_obs, yerr=y_err_imp1, fmt='.', label='Data')\n",
    "plt.plot(x_fit_1, y_fit_1, label='Fit', color='red')\n",
    "plt.xlabel('LMP', fontweight=\"bold\")\n",
    "plt.ylabel('IMP1F', fontweight=\"bold\")\n",
    "plt.title('DD events fit IMP1F', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_fit_IMP1_outliers.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, y_imp2, xerr=x_err_obs, yerr=y_err_imp2, fmt='.', label='Data')\n",
    "plt.plot(x_fit_2, y_fit_2, label='Fit', color='red')\n",
    "plt.xlabel('LMP', fontweight=\"bold\")\n",
    "plt.ylabel('IMP2F', fontweight=\"bold\")\n",
    "plt.title('DD events fit IMP2F', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_fit_IMP2_outliers.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# residuals \n",
    "res_1 = y_imp1 - linear_model(params_1, x_obs)\n",
    "res_2 = y_imp2 - linear_model(params_2, x_obs)\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, res_1, yerr=y_err_imp1, fmt='.', label='Residuals IMP1')\n",
    "plt.plot(x_fit_1, np.zeros(len(x_fit_1)), label='Zero line', color='orange')\n",
    "plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "plt.ylabel('Residuals IMP1', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_res_IMP1_outliers.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, res_2, yerr=y_err_imp2, fmt='.', label='Residuals IMP2')\n",
    "plt.plot(x_fit_2, np.zeros(len(x_fit_2)), label='Zero line', color='orange')\n",
    "plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "plt.ylabel('Residuals IMP2', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_res_IMP2_outliers.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.odr import ODR, Model, RealData, Data\n",
    "# from scipy.stats import t\n",
    "\n",
    "# # --- Data Preparation ---\n",
    "# # Remove outliers from your DataFrame DeDu24_f (assumed to be defined)\n",
    "# DeDu24_f_outliers = DeDu24_f.drop([39, 40], axis=0)\n",
    "\n",
    "# # Build and save the fitting DataFrame\n",
    "# data_fit = pd.DataFrame({\n",
    "#     'data_x': DeDu24_f_outliers['LMP'],\n",
    "#     'sigma_x': DeDu24_f_outliers['err_day_new'],\n",
    "#     'data_y_1': DeDu24_f_outliers['IMP1F'],\n",
    "#     'sigma_y_1': DeDu24_f_outliers['err_IMP1_24'],\n",
    "#     'data_y_2': DeDu24_f_outliers['IMP2F'],\n",
    "#     'sigma_y_2': DeDu24_f_outliers['err_IMP2_24']\n",
    "# })\n",
    "# #data_fit.to_csv(\"/home/andtoro/project_enea/enea_2/dati_fit.txt\", index=False, sep='\\t')\n",
    "\n",
    "# # Extract series for ODR fitting\n",
    "# dataObs = DeDu24_f_outliers['LMP']\n",
    "# dataImp1 = DeDu24_f_outliers['IMP1F']\n",
    "# dataImp2 = DeDu24_f_outliers['IMP2F']\n",
    "# dataImp1odr = DeDu24_f_outliers['IMP2F']\n",
    "# err_Obs  = DeDu24_f_outliers['err_day_new']\n",
    "# err_Imp1 = DeDu24_f_outliers['err_IMP1_24']\n",
    "# err_Imp2 = DeDu24_f_outliers['err_IMP2_24']\n",
    "\n",
    "# # --- ODR Fitting ---\n",
    "# def linear_model(B, x):\n",
    "#     m, c = B\n",
    "#     return m * x + c\n",
    "\n",
    "# model = Model(linear_model)\n",
    "\n",
    "# x_obs = np.array(dataObs)\n",
    "# y_imp1 = np.array(dataImp1)\n",
    "# y_imp2 = np.array(dataImp2)\n",
    "# x_err_obs = np.array(err_Obs)\n",
    "# y_err_imp1 = np.array(err_Imp1)\n",
    "# y_err_imp2 = np.array(err_Imp2) \n",
    "\n",
    "# data1 = RealData(x_obs, y_imp1, sx=x_err_obs, sy=y_err_imp1)\n",
    "# data2 = RealData(x_obs, y_imp2, sx=x_err_obs, sy=y_err_imp2)\n",
    "\n",
    "# # data1 = Data(x_obs, y_imp1, wd=1./np.power(x_err_obs, 2), we=1./np.power(y_err_imp1, 2))\n",
    "# # data2 = Data(x_obs, y_imp2, wd=1./np.power(x_err_obs, 2), we=1./np.power(y_err_imp2, 2))\n",
    "\n",
    "# odr1 = ODR(data1, model, beta0=[1.0, 0.0])\n",
    "# odr2 = ODR(data2, model, beta0=[1.0, 0.0])\n",
    "# output_1 = odr1.run()\n",
    "# output_1.pprint()\n",
    "# output_2 = odr2.run()\n",
    "# output_2.pprint()\n",
    "\n",
    "# params_1 = output_1.beta       # [slope, intercept] for IMP1F\n",
    "# param_errors_1 = output_1.sd_beta \n",
    "# params_2 = output_2.beta       # [slope, intercept] for IMP2F\n",
    "# param_errors_2 = output_2.sd_beta \n",
    "\n",
    "# # --- Interval Estimation using t-distribution ---\n",
    "# # Compute degrees of freedom: n - p (here p = 2)\n",
    "# dof = len(x_obs) - 2\n",
    "# alpha = 0.05  # for 95% confidence interval\n",
    "# t_crit = t.ppf(1 - alpha/2, dof)\n",
    "# print(\"Degrees of freedom:\", dof)\n",
    "# print(\"Critical t-value:\", t_crit)\n",
    "\n",
    "# # Compute half-widths of confidence intervals for each parameter\n",
    "# ci_half_1 = t_crit * param_errors_1  # for IMP1F: [slope half-width, intercept half-width]\n",
    "# ci_half_2 = t_crit * param_errors_2  # for IMP2F\n",
    "\n",
    "# # Compute lower and upper bounds for each fit\n",
    "# ci_1_lower = params_1 - ci_half_1\n",
    "# ci_1_upper = params_1 + ci_half_1\n",
    "# ci_2_lower = params_2 - ci_half_2\n",
    "# ci_2_upper = params_2 + ci_half_2\n",
    "\n",
    "# print(\"IMP1F parameters:\")\n",
    "# print(\"  Slope: {:.5f} [{:.5f}, {:.5f}]\".format(params_1[0], ci_1_lower[0], ci_1_upper[0]))\n",
    "# print(\"  Intercept: {:.5f} [{:.5f}, {:.5f}]\".format(params_1[1], ci_1_lower[1], ci_1_upper[1]))\n",
    "# print(\"IMP2F parameters:\")\n",
    "# print(\"  Slope: {:.5f} [{:.5f}, {:.5f}]\".format(params_2[0], ci_2_lower[0], ci_2_upper[0]))\n",
    "# print(\"  Intercept: {:.5f} [{:.5f}, {:.5f}]\".format(params_2[1], ci_2_lower[1], ci_2_upper[1]))\n",
    "\n",
    "# # --- Plotting ODR Fits ---\n",
    "# x_fit_1 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "# y_fit_1 = linear_model(params_1, x_fit_1)\n",
    "# x_fit_2 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "# y_fit_2 = linear_model(params_2, x_fit_2)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.errorbar(x_obs, y_imp1, xerr=x_err_obs, yerr=y_err_imp1, fmt='.', label='Data IMP1F')\n",
    "# plt.plot(x_fit_1, y_fit_1, label='ODR Fit IMP1F', color='red')\n",
    "# plt.xlabel('LMP', fontweight=\"bold\")\n",
    "# plt.ylabel('IMP1F', fontweight=\"bold\")\n",
    "# plt.title('DD events fit IMP1F', fontweight=\"bold\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.errorbar(x_obs, y_imp2, xerr=x_err_obs, yerr=y_err_imp2, fmt='.', label='Data IMP2F')\n",
    "# plt.plot(x_fit_2, y_fit_2, label='ODR Fit IMP2F', color='red')\n",
    "# plt.xlabel('LMP', fontweight=\"bold\")\n",
    "# plt.ylabel('IMP2F', fontweight=\"bold\")\n",
    "# plt.title('DD events fit IMP2F', fontweight=\"bold\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # --- Residual Plots ---\n",
    "# res_1 = y_imp1 - linear_model(params_1, x_obs)\n",
    "# res_2 = y_imp2 - linear_model(params_2, x_obs)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.errorbar(x_obs, res_1, yerr=y_err_imp1, fmt='.', label='Residuals IMP1F')\n",
    "# plt.plot(x_fit_1, np.zeros(len(x_fit_1)), label='Zero line', color='orange')\n",
    "# plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "# plt.ylabel('Residuals IMP1F', fontweight=\"bold\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.errorbar(x_obs, res_2, yerr=y_err_imp2, fmt='.', label='Residuals IMP2F')\n",
    "# plt.plot(x_fit_2, np.zeros(len(x_fit_2)), label='Zero line', color='orange')\n",
    "# plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "# plt.ylabel('Residuals IMP2F', fontweight=\"bold\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # --- Plotting Parameter Estimates with Confidence Intervals ---\n",
    "# # Combine parameters and their errors for a single plot.\n",
    "# # We will plot IMP1F and IMP2F parameters side by side.\n",
    "# # For each fit, we have two parameters: slope and intercept.\n",
    "\n",
    "# # x positions for our four points:\n",
    "# x_positions = np.arange(4)\n",
    "# # Parameter estimates: first two for IMP1F, next two for IMP2F.\n",
    "# param_values = np.concatenate((params_1, params_2))\n",
    "# # Confidence half-widths:\n",
    "# error_half = np.concatenate((ci_half_1, ci_half_2))\n",
    "# # Labels for the x-axis:\n",
    "# labels = [\"IMP1 Slope\", \"IMP1 Intercept\", \"IMP2 Slope\", \"IMP2 Intercept\"]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# ax.errorbar(x_positions, param_values, yerr=error_half, fmt='o', capsize=5,\n",
    "#             color='blue', ecolor='red', elinewidth=2, capthick=2,\n",
    "#             label='Estimate ± 95% CI')\n",
    "# ax.set_xticks(x_positions)\n",
    "# ax.set_xticklabels(labels, rotation=45, fontsize=12)\n",
    "# ax.set_ylabel('Parameter Value', fontsize=12)\n",
    "# ax.set_title('Parameter Estimates with 95% Confidence Intervals', fontsize=14)\n",
    "# ax.grid(True)\n",
    "# ax.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style for better aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Residuals plot for IMP1F\n",
    "axes[0].errorbar(x_obs, res_1, yerr=y_err_imp1, fmt='o', markersize=6, alpha=0.7, label='Residuals IMP1F', color='royalblue')\n",
    "axes[0].hlines(0, min(x_obs), max(x_obs), color='orange', linestyles='dashed', label='Zero Line')\n",
    "axes[0].set_ylabel('Residuals IMP1F', fontweight=\"bold\", fontsize=12)\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[0].legend()\n",
    "\n",
    "# Residuals plot for IMP2F\n",
    "axes[1].errorbar(x_obs, res_2, yerr=y_err_imp2, fmt='o', markersize=6, alpha=0.7, label='Residuals IMP2F', color='firebrick')\n",
    "axes[1].hlines(0, min(x_obs), max(x_obs), color='orange', linestyles='dashed', label='Zero Line')\n",
    "axes[1].set_xlabel('Observed LMP', fontweight=\"bold\", fontsize=12)\n",
    "axes[1].set_ylabel('Residuals IMP2F', fontweight=\"bold\", fontsize=12)\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_res_imp1_imp2_residuals.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.odr import ODR, Model, RealData\n",
    "# from scipy.stats import t\n",
    "\n",
    "# def linear_model(B, x):\n",
    "#     \"\"\"Linear model: y = m*x + n*x + c\"\"\"\n",
    "#     m, n, c = B\n",
    "#     return m * x + n * x + c\n",
    "\n",
    "# def compute_confidence_intervals(output, x_fit, confidence=0.95):\n",
    "#     \"\"\"Compute confidence intervals using Student's t-distribution.\"\"\"\n",
    "#     params = output.beta\n",
    "#     param_errors = output.sd_beta\n",
    "#     dof = len(x_obs) - len(params)  # Degrees of freedom\n",
    "#     t_value = t.ppf((1 + confidence) / 2, dof)  # Critical t value\n",
    "    \n",
    "#     # Compute standard error of prediction (approximation)\n",
    "#     y_fit = linear_model(params, x_fit)\n",
    "#     se_fit = np.sqrt(sum((param_errors)**2))  # Approximate standard error\n",
    "    \n",
    "#     conf_interval = t_value * se_fit\n",
    "#     return y_fit, y_fit - conf_interval, y_fit + conf_interval\n",
    "\n",
    "# # Load data (assuming DeDu24_f_outliers is a pre-defined DataFrame)\n",
    "# data_fit = pd.DataFrame({\n",
    "#     'data_x': DeDu24_f_outliers['LMP'],\n",
    "#     'sigma_x': DeDu24_f_outliers['err_day_new'],\n",
    "#     'data_y_1': DeDu24_f_outliers['IMP1F'],\n",
    "#     'sigma_y_1': DeDu24_f_outliers['err_IMP1_24'],\n",
    "#     'data_y_2': DeDu24_f_outliers['IMP2F'],\n",
    "#     'sigma_y_2': DeDu24_f_outliers['err_IMP2_24']\n",
    "# })\n",
    "\n",
    "# # Prepare variables\n",
    "# x_obs = np.array(data_fit['data_x'])\n",
    "# y_data = [np.array(data_fit['data_y_1']), np.array(data_fit['data_y_2'])]\n",
    "# y_err = [np.array(data_fit['sigma_y_1']), np.array(data_fit['sigma_y_2'])]\n",
    "# labels = ['IMP1F', 'IMP2F']\n",
    "# colors = ['red', 'blue']\n",
    "\n",
    "# # Fit models and plot results\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# model = Model(linear_model)\n",
    "\n",
    "# for i in range(2):\n",
    "#     data = RealData(x_obs, y_data[i], sx=data_fit['sigma_x'], sy=y_err[i])\n",
    "#     odr = ODR(data, model, beta0=[1.0, 0.6, 0.0])\n",
    "#     output = odr.run()\n",
    "#     params = output.beta\n",
    "#     output.pprint()\n",
    "    \n",
    "#     # Compute fit and confidence intervals\n",
    "#     x_fit = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "#     y_fit, y_lower, y_upper = compute_confidence_intervals(output, x_fit)\n",
    "    \n",
    "#     # Plot data points with error bars\n",
    "#     plt.errorbar(x_obs, y_data[i], xerr=data_fit['sigma_x'], yerr=y_err[i], fmt='.', label=f'Data {labels[i]}', alpha=0.6)\n",
    "    \n",
    "#     # Plot best fit line\n",
    "#     plt.plot(x_fit, y_fit, label=f'Fit {labels[i]}', color=colors[i])\n",
    "    \n",
    "#     # Plot confidence bands\n",
    "#     plt.fill_between(x_fit, y_lower, y_upper, color=colors[i], alpha=0.2, label=f'Confidence {labels[i]}')\n",
    "\n",
    "# plt.xlabel('LMP', fontweight='bold')\n",
    "# plt.ylabel('IMP', fontweight='bold')\n",
    "# plt.title('ODR Fit with Confidence Bands', fontweight='bold')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "from scipy.stats import t\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# (Assumes your DataFrame DeDu24_f is already defined)\n",
    "DeDu24_f_outliers = DeDu24_f.drop([39, 40], axis=0)\n",
    "\n",
    "# Save the fitting data (optional)\n",
    "data_fit = pd.DataFrame({\n",
    "    'data_x': DeDu24_f_outliers['LMP'],\n",
    "    'sigma_x': DeDu24_f_outliers['err_day_new'],\n",
    "    'data_y_1': DeDu24_f_outliers['IMP1F'],\n",
    "    'sigma_y_1': DeDu24_f_outliers['err_IMP1_24'],\n",
    "    'data_y_2': DeDu24_f_outliers['IMP2F'],\n",
    "    'sigma_y_2': DeDu24_f_outliers['err_IMP2_24']\n",
    "})\n",
    "#data_fit.to_csv(\"/home/andtoro/project_enea/enea_2/dati_fit.txt\", index=False, sep='\\t')\n",
    "\n",
    "# Extract observed data and uncertainties for both fits\n",
    "dataObs = DeDu24_f_outliers['LMP']\n",
    "dataImp1 = DeDu24_f_outliers['IMP1F']\n",
    "dataImp2 = DeDu24_f_outliers['IMP2F']\n",
    "err_Obs  = DeDu24_f_outliers['err_day_new']\n",
    "err_Imp1 = DeDu24_f_outliers['err_IMP1_24']\n",
    "err_Imp2 = DeDu24_f_outliers['err_IMP2_24']\n",
    "\n",
    "# Convert to numpy arrays\n",
    "x_obs = np.array(dataObs)\n",
    "y_imp1 = np.array(dataImp1)\n",
    "y_imp2 = np.array(dataImp2)\n",
    "x_err_obs = np.array(err_Obs)\n",
    "y_err_imp1 = np.array(err_Imp1)\n",
    "y_err_imp2 = np.array(err_Imp2)\n",
    "\n",
    "# --- Define the Linear Model for ODR ---\n",
    "def linear_model(B, x):\n",
    "    m, c = B\n",
    "    return m * x + c\n",
    "\n",
    "model = Model(linear_model)\n",
    "\n",
    "# --- ODR Fitting for IMP1F ---\n",
    "data1 = RealData(x_obs, y_imp1, sx=x_err_obs, sy=y_err_imp1)\n",
    "odr1 = ODR(data1, model, beta0=[1.0, 0.0])\n",
    "output_1 = odr1.run()\n",
    "output_1.pprint()\n",
    "\n",
    "params_1 = output_1.beta       # [slope, intercept] for IMP1F\n",
    "param_errors_1 = output_1.sd_beta\n",
    "cov_1 = output_1.cov_beta      # Covariance matrix\n",
    "\n",
    "# --- ODR Fitting for IMP2F ---\n",
    "data2 = RealData(x_obs, y_imp2, sx=x_err_obs, sy=y_err_imp2)\n",
    "odr2 = ODR(data2, model, beta0=[1.0, 0.0])\n",
    "output_2 = odr2.run()\n",
    "output_2.pprint()\n",
    "\n",
    "params_2 = output_2.beta       # [slope, intercept] for IMP2F\n",
    "param_errors_2 = output_2.sd_beta\n",
    "cov_2 = output_2.cov_beta      # Covariance matrix\n",
    "\n",
    "# --- Confidence Band Calculation Parameters ---\n",
    "dof = len(x_obs) - 2  # degrees of freedom (n - p, with p=2)\n",
    "alpha = 0.05        # for 95% confidence interval\n",
    "t_crit = t.ppf(1 - alpha/2, dof)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Critical t-value:\", t_crit)\n",
    "\n",
    "# Create a fine grid for predictions\n",
    "x_fit = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "\n",
    "# --- Compute Confidence Band for IMP1F ---\n",
    "y_fit_1 = linear_model(params_1, x_fit)\n",
    "# For y = m*x + c, variance: Var(y) = x^2 * Var(m) + Var(c) + 2*x*Cov(m,c)\n",
    "sigma_m1 = param_errors_1[0]\n",
    "sigma_c1 = param_errors_1[1]\n",
    "cov_mc1  = cov_1[0, 1]\n",
    "\n",
    "pred_var_1 = (x_fit**2) * (sigma_m1**2) + (sigma_c1**2) + 2 * x_fit * cov_mc1\n",
    "pred_se_1 = np.sqrt(pred_var_1)\n",
    "ci_half_width_1 = t_crit * pred_se_1\n",
    "\n",
    "y_lower_1 = y_fit_1 - ci_half_width_1\n",
    "y_upper_1 = y_fit_1 + ci_half_width_1\n",
    "\n",
    "# --- Compute Confidence Band for IMP2F ---\n",
    "y_fit_2 = linear_model(params_2, x_fit)\n",
    "sigma_m2 = param_errors_2[0]\n",
    "sigma_c2 = param_errors_2[1]\n",
    "cov_mc2  = cov_2[0, 1]\n",
    "\n",
    "pred_var_2 = (x_fit**2) * (sigma_m2**2) + (sigma_c2**2) + 2 * x_fit * cov_mc2\n",
    "pred_se_2 = np.sqrt(pred_var_2)\n",
    "ci_half_width_2 = t_crit * pred_se_2\n",
    "\n",
    "y_lower_2 = y_fit_2 - ci_half_width_2\n",
    "y_upper_2 = y_fit_2 + ci_half_width_2\n",
    "\n",
    "# --- Plotting the Fit with Confidence Bands ---\n",
    "\n",
    "# Plot for IMP1F\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(x_obs, y_imp1, xerr=x_err_obs, yerr=y_err_imp1, fmt='o',\n",
    "             color='blue', ecolor='lightblue', elinewidth=2, capsize=4,\n",
    "             label='Data IMP1F')\n",
    "plt.plot(x_fit, y_fit_1, color='red', lw=2, label='Best-fit IMP1F')\n",
    "# plt.fill_between(x_fit, y_lower_1, y_upper_1, color='gray', alpha=0.3,\n",
    "#                  label='95% Confidence Band')\n",
    "plt.xlabel('LMP', fontweight=\"bold\", fontsize=14)\n",
    "plt.ylabel('IMP1F', fontweight=\"bold\", fontsize=14)\n",
    "plt.title('ODR Fit for IMP1F', fontweight=\"bold\", fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_fit_IMP1.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for IMP2F\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(x_obs, y_imp2, xerr=x_err_obs, yerr=y_err_imp2, fmt='o',\n",
    "             color='blue', ecolor='lightblue', elinewidth=2, capsize=4,\n",
    "             label='Data IMP2F')\n",
    "plt.plot(x_fit, y_fit_2, color='red', lw=2, label='Best-fit IMP2F')\n",
    "# plt.fill_between(x_fit, y_lower_2, y_upper_2, color='gray', alpha=0.3,\n",
    "#                  label='95% Confidence Band')\n",
    "plt.xlabel('LMP', fontweight=\"bold\", fontsize=14)\n",
    "plt.ylabel('IMP2F', fontweight=\"bold\", fontsize=14)\n",
    "plt.title('ODR Fit for IMP2F', fontweight=\"bold\", fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_fit_IMP2.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "from scipy.stats import t\n",
    "\n",
    "# Extract observed data and uncertainties for both fits\n",
    "dataObs = DeDu24_f['LMP']\n",
    "dataFarm = DeDu24_f['FARM']\n",
    "dataImp1 = DeDu24_f['IMP1F']\n",
    "dataImp2 = DeDu24_f['IMP2F']\n",
    "err_Obs = DeDu24_f['err_day_new']\n",
    "err_Imp1 = DeDu24_f['err_IMP1_24']\n",
    "err_Imp2 = DeDu24_f['err_IMP2_24']\n",
    "\n",
    "# Convert to numpy arrays\n",
    "x_obs = np.array(dataObs)\n",
    "y_imp1 = np.array(dataImp1)\n",
    "y_imp2 = np.array(dataImp2)\n",
    "x_err_obs = np.array(err_Obs)\n",
    "y_err_imp1 = np.array(err_Imp1)\n",
    "y_err_imp2 = np.array(err_Imp2)\n",
    "\n",
    "# --- Define the Linear Model for ODR ---\n",
    "def linear_model(B, x):\n",
    "    m, c = B\n",
    "    return m * x + c\n",
    "\n",
    "model = Model(linear_model)\n",
    "\n",
    "# --- ODR Fitting for IMP1F ---\n",
    "data1 = RealData(x_obs, y_imp1, sx=x_err_obs, sy=y_err_imp1)\n",
    "odr1 = ODR(data1, model, beta0=[1.0, 0.0])\n",
    "output_1 = odr1.run()\n",
    "output_1.pprint()\n",
    "\n",
    "params_1 = output_1.beta       # [slope, intercept] for IMP1F\n",
    "param_errors_1 = output_1.sd_beta\n",
    "cov_1 = output_1.cov_beta      # Covariance matrix\n",
    "\n",
    "# --- ODR Fitting for IMP2F ---\n",
    "data2 = RealData(x_obs, y_imp2, sx=x_err_obs, sy=y_err_imp2)\n",
    "odr2 = ODR(data2, model, beta0=[1.0, 0.0])\n",
    "output_2 = odr2.run()\n",
    "output_2.pprint()\n",
    "\n",
    "params_2 = output_2.beta       # [slope, intercept] for IMP2F\n",
    "param_errors_2 = output_2.sd_beta\n",
    "cov_2 = output_2.cov_beta      # Covariance matrix\n",
    "\n",
    "# --- Confidence Band Calculation Parameters ---\n",
    "dof = len(x_obs) - 2  # degrees of freedom (n - p, with p=2)\n",
    "alpha = 0.05        # for 95% confidence interval\n",
    "t_crit = t.ppf(1 - alpha/2, dof)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Critical t-value:\", t_crit)\n",
    "\n",
    "# Create a fine grid for predictions\n",
    "x_fit = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "\n",
    "# --- Compute Confidence Band for IMP1F ---\n",
    "y_fit_1 = linear_model(params_1, x_fit)\n",
    "# For y = m*x + c, variance: Var(y) = x^2 * Var(m) + Var(c) + 2*x*Cov(m,c)\n",
    "sigma_m1 = param_errors_1[0]\n",
    "sigma_c1 = param_errors_1[1]\n",
    "cov_mc1  = cov_1[0, 1]\n",
    "\n",
    "pred_var_1 = (x_fit**2) * (sigma_m1**2) + (sigma_c1**2) + 2 * x_fit * cov_mc1\n",
    "pred_se_1 = np.sqrt(pred_var_1)\n",
    "ci_half_width_1 = t_crit * pred_se_1\n",
    "\n",
    "y_lower_1 = y_fit_1 - ci_half_width_1\n",
    "y_upper_1 = y_fit_1 + ci_half_width_1\n",
    "\n",
    "# --- Compute Confidence Band for IMP2F ---\n",
    "y_fit_2 = linear_model(params_2, x_fit)\n",
    "sigma_m2 = param_errors_2[0]\n",
    "sigma_c2 = param_errors_2[1]\n",
    "cov_mc2  = cov_2[0, 1]\n",
    "\n",
    "pred_var_2 = (x_fit**2) * (sigma_m2**2) + (sigma_c2**2) + 2 * x_fit * cov_mc2\n",
    "pred_se_2 = np.sqrt(pred_var_2)\n",
    "ci_half_width_2 = t_crit * pred_se_2\n",
    "\n",
    "y_lower_2 = y_fit_2 - ci_half_width_2\n",
    "y_upper_2 = y_fit_2 + ci_half_width_2\n",
    "\n",
    "# --- Plotting the Fit with Confidence Bands ---\n",
    "\n",
    "# Plot for IMP1F\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(x_obs, y_imp1, xerr=x_err_obs, yerr=y_err_imp1, fmt='o',\n",
    "             color='blue', ecolor='lightblue', elinewidth=2, capsize=4,\n",
    "             label='Data IMP1F')\n",
    "plt.plot(x_fit, y_fit_1, color='red', lw=2, label='Best-fit IMP1F')\n",
    "# plt.fill_between(x_fit, y_lower_1, y_upper_1, color='gray', alpha=0.3,\n",
    "#                  label='95% Confidence Band')\n",
    "plt.xlabel('LMP', fontweight=\"bold\", fontsize=14)\n",
    "plt.ylabel('IMP1F', fontweight=\"bold\", fontsize=14)\n",
    "plt.title('ODR Fit for IMP1F', fontweight=\"bold\", fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_fit_IMP1_no_out.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot for IMP2F\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(x_obs, y_imp2, xerr=x_err_obs, yerr=y_err_imp2, fmt='o',\n",
    "             color='blue', ecolor='lightblue', elinewidth=2, capsize=4,\n",
    "             label='Data IMP2F')\n",
    "plt.plot(x_fit, y_fit_2, color='red', lw=2, label='Best-fit IMP2F')\n",
    "#plt.fill_between(x_fit, y_lower_2, y_upper_2, color='gray', alpha=0.3,\n",
    "                 #label='95% Confidence Band')\n",
    "plt.xlabel('LMP', fontweight=\"bold\", fontsize=14)\n",
    "plt.ylabel('IMP2F', fontweight=\"bold\", fontsize=14)\n",
    "plt.title('ODR Fit for IMP2F', fontweight=\"bold\", fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_fit_IMP2_no_out.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "res_1 = dataImp1 - linear_model(params_1, x_obs)\n",
    "res_2 = dataImp2 - linear_model(params_2, x_obs)\n",
    "\n",
    "# Set Seaborn style for better aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Residuals plot for IMP1F\n",
    "axes[0].errorbar(x_obs, res_1, yerr=y_err_imp1, fmt='o', markersize=6, alpha=0.7, label='Residuals IMP1F', color='royalblue')\n",
    "axes[0].hlines(0, min(x_obs), max(x_obs), color='orange', linestyles='dashed', label='Zero Line')\n",
    "axes[0].set_ylabel('Residuals IMP1F', fontweight=\"bold\", fontsize=12)\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[0].legend()\n",
    "\n",
    "# Residuals plot for IMP2F\n",
    "axes[1].errorbar(x_obs, res_2, yerr=y_err_imp2, fmt='o', markersize=6, alpha=0.7, label='Residuals IMP2F', color='firebrick')\n",
    "axes[1].hlines(0, min(x_obs), max(x_obs), color='orange', linestyles='dashed', label='Zero Line')\n",
    "axes[1].set_xlabel('Observed LMP', fontweight=\"bold\", fontsize=12)\n",
    "axes[1].set_ylabel('Residuals IMP2F', fontweight=\"bold\", fontsize=12)\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_res_imp1_imp2_residuals_no_out.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "res_1 = y_imp1 - linear_model(params_1, x_obs)\n",
    "res_2 = y_imp2 - linear_model(params_2, x_obs)\n",
    "\n",
    "# Set Seaborn style for better aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Residuals plot for IMP1F\n",
    "axes[0].errorbar(x_obs, res_1, yerr=y_err_imp1, fmt='o', markersize=6, alpha=0.7, label='Residuals IMP1F', color='royalblue')\n",
    "axes[0].hlines(0, min(x_obs), max(x_obs), color='orange', linestyles='dashed', label='Zero Line')\n",
    "axes[0].set_ylabel('Residuals IMP1F', fontweight=\"bold\", fontsize=12)\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[0].legend()\n",
    "\n",
    "# Residuals plot for IMP2F\n",
    "axes[1].errorbar(x_obs, res_2, yerr=y_err_imp2, fmt='o', markersize=6, alpha=0.7, label='Residuals IMP2F', color='firebrick')\n",
    "axes[1].hlines(0, min(x_obs), max(x_obs), color='orange', linestyles='dashed', label='Zero Line')\n",
    "axes[1].set_xlabel('Observed LMP', fontweight=\"bold\", fontsize=12)\n",
    "axes[1].set_ylabel('Residuals IMP2F', fontweight=\"bold\", fontsize=12)\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ODR_res_imp1_imp2_residuals_no_out.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "\n",
    "DeDu24_f_outliers= DeDu24_f.drop([39, 40], axis= 0)\n",
    "#DD_fit_clean = DeDu24_f_outliers[(DeDu24_f_outliers['err_IMP1_24'] > 1e-2) & (DeDu24_f_outliers['err_IMP2_24'] > 1e-2)]\n",
    "\n",
    "# data_obs = DD_fit_clean['LMP']\n",
    "# data_farm = DD_fit_clean['FARM']\n",
    "# data_imp1 = DD_fit_clean['IMP1F']\n",
    "# data_imp2 = DD_fit_clean['IMP2F']\n",
    "# errObs = DD_fit_clean['err_day_new']\n",
    "# errImp1 = DD_fit_clean['err_IMP1_24']\n",
    "# errImp2 = DD_fit_clean['err_IMP2_24']\n",
    "\n",
    "\n",
    "# dataObs = DeDu['LMP']\n",
    "# dataFarm = DeDu['FARM']\n",
    "# dataImp1 = DeDu['IMP1F']\n",
    "# dataImp2 = DeDu['IMP2F']\n",
    "# err_Obs = DeDu['err_new']\n",
    "# err_Imp1 = DeDu['err_IMP1']\n",
    "# err_Imp2 = DeDu['err_IMP2']\n",
    "\n",
    "# dataObs = DeDu24_f_outliers['LMP']\n",
    "# dataFarm = DeDu24_f_outliers['FARM']\n",
    "# dataImp1 = DeDu24_f_outliers['IMP1F']\n",
    "# dataImp2 = DeDu24_f_outliers['IMP2F']\n",
    "# err_Obs = DeDu24_f_outliers['err_day_new']\n",
    "# err_Imp1 = DeDu24_f_outliers['err_IMP1_24']\n",
    "# err_Imp2 = DeDu24_f_outliers['err_IMP2_24']\n",
    "\n",
    "dataObs = DeDu24_f['LMP']\n",
    "dataFarm = DeDu24_f['FARM']\n",
    "dataImp1 = DeDu24_f['IMP1F']\n",
    "dataImp2 = DeDu24_f['IMP2F']\n",
    "err_Obs = DeDu24_f['err_day_new']\n",
    "err_Imp1 = DeDu24_f['err_IMP1_24']\n",
    "err_Imp2 = DeDu24_f['err_IMP2_24']\n",
    "\n",
    "# DD_no_zero = DeDu24[(DeDu24['err_day_new'] != 0.0) & (DeDu24['err_IMP1_24'] != 0.0) & (DeDu24['err_IMP2_24'] != 0.0)]\n",
    "\n",
    "# dataObs = DD_no_zero['LMP']\n",
    "# dataFarm = DD_no_zero['FARM']\n",
    "# dataImp1 = DD_no_zero['IMP1F']\n",
    "# dataImp2 = DD_no_zero['IMP2F']\n",
    "# err_Obs = DD_no_zero['err_day_new']\n",
    "# err_Imp1 = DD_no_zero['err_IMP1_24']\n",
    "# err_Imp2 = DD_no_zero['err_IMP2_24']\n",
    "\n",
    "#np.savetxt(\"data_obs.txt\", np.column_stack((data_obs, dataImp1, dataImp2, err_Obs, err_Imp1, err_Imp2)))\n",
    "\n",
    "def linear_model(B, x):\n",
    "    m, c = B\n",
    "    return m * x + c\n",
    "\n",
    "model = Model(linear_model)\n",
    "\n",
    "x_obs = np.array(dataObs)\n",
    "y_imp1 = np.array(dataImp1)\n",
    "y_imp2 = np.array(dataImp2)\n",
    "x_err_obs = np.array(err_Obs)\n",
    "y_err_imp1 = np.array(err_Imp1)\n",
    "y_err_imp2 = np.array(err_Imp2) \n",
    "\n",
    "data1 = RealData(x_obs, y_imp1, sx=x_err_obs, sy=y_err_imp1)\n",
    "data2 = RealData(x_obs, y_imp2, sx=x_err_obs, sy=y_err_imp2)\n",
    "\n",
    "odr1 = ODR(data1, model, beta0=[1.0, 0.0])\n",
    "odr2 = ODR(data2, model, beta0=[1.0, 0.0])\n",
    "output_1 = odr1.run()\n",
    "output_2 = odr2.run()\n",
    "\n",
    "params_1 = output_1.beta\n",
    "param_errors_1 = output_1.sd_beta \n",
    "params_2 = output_2.beta\n",
    "param_errors_2 = output_2.sd_beta \n",
    "\n",
    "print(\"Fitted parameters IMP1:\", params_1)\n",
    "print(\"Parameter errors IMP1:\", param_errors_1)\n",
    "print(\"Chi2 IMP1:\", output_1.sum_square)\n",
    "print(\"Chi2 IMP2:\", output_2.sum_square)\n",
    "print(\"Fitted parameters IMP2:\", params_2)\n",
    "print(\"Parameter errors IMP2:\", param_errors_2)\n",
    "\n",
    "x_fit_1 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "y_fit_1 = linear_model(params_1, x_fit_1)\n",
    "x_fit_2 = np.linspace(x_obs.min(), x_obs.max(), 1000)\n",
    "y_fit_2 = linear_model(params_2, x_fit_2)\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, y_imp1, xerr=x_err_obs, yerr=y_err_imp1, fmt='.', label='Data')\n",
    "plt.plot(x_fit_1, y_fit_1, label='Fit', color='red')\n",
    "plt.xlabel('LMP', fontweight=\"bold\")\n",
    "plt.ylabel('IMP1F', fontweight=\"bold\")\n",
    "plt.title('DD events fit IMP1F', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, y_imp2, xerr=x_err_obs, yerr=y_err_imp2, fmt='.', label='Data')\n",
    "plt.plot(x_fit_2, y_fit_2, label='Fit', color='red')\n",
    "plt.xlabel('LMP', fontweight=\"bold\")\n",
    "plt.ylabel('IMP2F', fontweight=\"bold\")\n",
    "plt.title('DD events fit IMP2F', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# residuals \n",
    "res_1 = y_imp1 - linear_model(params_1, x_obs)\n",
    "res_2 = y_imp2 - linear_model(params_2, x_obs)\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, res_1, yerr=y_err_imp1, fmt='.', label='Residuals IMP1')\n",
    "plt.plot(x_fit_1, np.zeros(len(x_fit_1)), label='Zero line', color='orange')\n",
    "plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "plt.ylabel('Residuals IMP1', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (12, 8))\n",
    "plt.errorbar(x_obs, res_2, yerr=y_err_imp2, fmt='.', label='Residuals IMP2')\n",
    "plt.plot(x_fit_2, np.zeros(len(x_fit_2)), label='Zero line', color='orange')\n",
    "plt.xlabel('Observed LMP', fontweight=\"bold\")\n",
    "plt.ylabel('Residuals IMP2', fontweight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"data_obs.txt\", np.column_stack((data_obs, data_imp1, data_imp2, errObs, errImp1, errImp2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concentration for each day in order to relax filter on ANG and AOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = [40, 50, 70, 100, 130, 180, 240, 330, 440, 600, 800, 1090, 1470, 1500]\n",
    "N = len(dz)\n",
    "\n",
    "df_ug_m3 = pd.DataFrame({'time': dt_f})\n",
    "\n",
    "concentrations = ['c_ASO4J', 'c_ASO4I', 'c_ANO3J', 'c_ANO3I', 'c_ANH4J', 'c_ANH4I', 'c_AORAJ', 'c_AORAI', 'c_AORPAJ', 'c_AORPAI',\n",
    "                  'c_AORBJ', 'c_AORBI', 'c_AECJ', 'c_AECI', 'c_A25J', 'c_A25I',  'c_ACORS', 'c_ASEASJ', 'c_ASEAS', \n",
    "                  'c_ASOILJ', 'c_ASOIL']\n",
    "\n",
    "conc_data = {conc_name: df_f_dump.variables[conc_name][:, :N] for conc_name in concentrations}\n",
    "\n",
    "for conc_name, conc_array in conc_data.items():\n",
    "    conc_columns = {f'l_{i}_{conc_name}': conc_array[:, i] for i in range(N)}\n",
    "    df_ug_m3 = pd.concat([df_ug_m3, pd.DataFrame(conc_columns)], axis= 1)\n",
    "\n",
    "C_aso4 = 0\n",
    "C_ano3 = 0\n",
    "C_anh4 = 0\n",
    "C_aorg = 0\n",
    "C_abio = 0\n",
    "C_aec = 0\n",
    "C_atc = 0\n",
    "C_apant = 0\n",
    "C_apnat = 0 \n",
    "C_pmcoa = 0 \n",
    "C_pm25 = 0 \n",
    "C_pm10 = 0\n",
    "C_asoil = 0\n",
    "C_tot = 0\n",
    "\n",
    "for idx, thick in enumerate(dz):\n",
    "    \n",
    "    c_aso4 = df_ug_m3[f'l_{idx}_c_ASO4I'] + df_ug_m3[f'l_{idx}_c_ASO4J']\n",
    "\n",
    "    c_ano3 = df_ug_m3[f'l_{idx}_c_ANO3I'] + df_ug_m3[f'l_{idx}_c_ANO3J']\n",
    "\n",
    "    c_anh4 = df_ug_m3[f'l_{idx}_c_ANH4I'] + df_ug_m3[f'l_{idx}_c_ANH4J']\n",
    "\n",
    "    c_aorg = df_ug_m3[f'l_{idx}_c_AORAI'] + df_ug_m3[f'l_{idx}_c_AORAJ'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AORPAI'] + df_ug_m3[f'l_{idx}_c_AORPAJ'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AORBI'] + df_ug_m3[f'l_{idx}_c_AORBJ']\n",
    "    \n",
    "    c_abio = df_ug_m3[f'l_{idx}_c_AORBJ'] + df_ug_m3[f'l_{idx}_c_AORBI']\n",
    "\n",
    "    c_aec = df_ug_m3[f'l_{idx}_c_AECJ'] + df_ug_m3[f'l_{idx}_c_AECI']\n",
    "\n",
    "    c_atc = df_ug_m3[f'l_{idx}_c_AORAJ'] + df_ug_m3[f'l_{idx}_c_AORAI'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AORBJ'] + df_ug_m3[f'l_{idx}_c_AORBI'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AORPAJ'] + df_ug_m3[f'l_{idx}_c_AORPAI'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AECJ'] + df_ug_m3[f'l_{idx}_c_AECI']\n",
    "    \n",
    "    c_apant = df_ug_m3[f'l_{idx}_c_A25J'] + df_ug_m3[f'l_{idx}_c_A25I'] + df_ug_m3[f'l_{idx}_c_ACORS']\n",
    "\n",
    "    c_apnat = df_ug_m3[f'l_{idx}_c_ASEASJ'] + df_ug_m3[f'l_{idx}_c_ASEAS'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_ASOILJ'] + df_ug_m3[f'l_{idx}_c_ASOIL']\n",
    "    \n",
    "    c_pmcoa = df_ug_m3[f'l_{idx}_c_ASEAS'] + df_ug_m3[f'l_{idx}_c_ASOIL'] + df_ug_m3[f'l_{idx}_c_ACORS']\n",
    "\n",
    "    c_pm25 = df_ug_m3[f'l_{idx}_c_ASO4J'] + df_ug_m3[f'l_{idx}_c_ASO4I'] + df_ug_m3[f'l_{idx}_c_ANH4J'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_ANH4I'] + df_ug_m3[f'l_{idx}_c_ANO3J'] + df_ug_m3[f'l_{idx}_c_ANO3I'] + df_ug_m3[f'l_{idx}_c_AORAJ'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AORAI'] + df_ug_m3[f'l_{idx}_c_AORPAJ'] + df_ug_m3[f'l_{idx}_c_AORPAI'] + df_ug_m3[f'l_{idx}_c_AORBJ'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AORBI']+ df_ug_m3[f'l_{idx}_c_AECJ'] + df_ug_m3[f'l_{idx}_c_AECI'] + df_ug_m3[f'l_{idx}_c_A25J'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_A25I'] + df_ug_m3[f'l_{idx}_c_ASEASJ'] + df_ug_m3[f'l_{idx}_c_ASOILJ']\n",
    "    \n",
    "    c_pm10 =  df_ug_m3[f'l_{idx}_c_ASO4J'] + df_ug_m3[f'l_{idx}_c_ASO4I'] + df_ug_m3[f'l_{idx}_c_ANH4J'] + df_ug_m3[f'l_{idx}_c_ANH4I'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_ANO3J'] + df_ug_m3[f'l_{idx}_c_ANO3I'] + df_ug_m3[f'l_{idx}_c_AORAJ'] + df_ug_m3[f'l_{idx}_c_AORAI'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AORPAJ'] + df_ug_m3[f'l_{idx}_c_AORPAI'] + df_ug_m3[f'l_{idx}_c_AORBJ'] + df_ug_m3[f'l_{idx}_c_AORBI'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_AECJ'] + df_ug_m3[f'l_{idx}_c_AECI'] + df_ug_m3[f'l_{idx}_c_A25J'] + df_ug_m3[f'l_{idx}_c_A25I'] + df_ug_m3[f'l_{idx}_c_ACORS'] + \\\n",
    "        df_ug_m3[f'l_{idx}_c_ASEAS'] + df_ug_m3[f'l_{idx}_c_ASOIL'] + df_ug_m3[f'l_{idx}_c_ASEASJ'] + df_ug_m3[f'l_{idx}_c_ASOILJ']\n",
    "    \n",
    "    c_asoil =  df_ug_m3[f'l_{idx}_c_ASOIL'] + df_ug_m3[f'l_{idx}_c_ASOILJ'] \n",
    "\n",
    "    # concentration over the geometric thickness\n",
    "\n",
    "    C_aso4 += c_aso4 * dz[idx:idx+1]\n",
    "    C_ano3 += c_ano3 * dz[idx:idx+1]\n",
    "    C_anh4 += c_anh4 * dz[idx:idx+1]\n",
    "    C_aorg += c_aorg * dz[idx:idx+1]\n",
    "    C_abio += c_abio * dz[idx:idx+1]\n",
    "    C_aec += c_aec * dz[idx:idx+1]\n",
    "    C_atc += c_atc * dz[idx:idx+1]\n",
    "    C_apant += c_apant * dz[idx:idx+1]\n",
    "    C_apnat += c_apnat * dz[idx:idx+1]\n",
    "    C_pmcoa += c_pmcoa * dz[idx:idx+1]\n",
    "    C_pm25 += c_pm25 * dz[idx:idx+1]\n",
    "    C_pm10 += c_pm10 * dz[idx:idx+1]\n",
    "\n",
    "    C_tot = C_aso4 + C_ano3 + C_anh4 + C_aorg + C_abio + C_aec + C_atc + C_apant + C_apnat + C_pmcoa + C_pm25 + C_pm10\n",
    "\n",
    "    C_asoil += c_asoil * dz[idx:idx+1]\n",
    "\n",
    "df_ug_m3_tot = pd.DataFrame({'time': dt_f, 'C_tot': C_tot, 'C_asoil': C_asoil, 'asoil/tot': C_asoil/C_tot})\n",
    "df_ug_m3_tot_day = df_ug_m3_tot.resample('D', on= 'time').mean().dropna().reset_index()\n",
    "df_ugm3_err = df_ug_m3_tot.resample('D', on= 'time').std().dropna().reset_index().rename(columns={'C_tot': 'C_tot_err', 'C_asoil': 'C_asoil_err', 'asoil/tot': 'asoil/tot_err'})\n",
    "df_ug_m3_tot_day_merge_obs = pd.merge(pd.merge(df_ug_m3_tot_day, df_ugm3_err, on= 'time', how= 'inner'), Data['1D'], on= 'time', how= 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_ug_m3_tot_day_merge_obs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the percentage of ASOIL ($\\frac{\\mu g}{m^{3}}$) on total concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asoil_percentage = df_ug_m3_tot_day_merge_obs['C_asoil']/df_ug_m3_tot_day_merge_obs['C_tot']\n",
    "Time = df_ug_m3_tot_day_merge_obs['time']\n",
    "\n",
    "# filter on DD events\n",
    "events_DD = df_ug_m3_tot_day_merge_obs[(df_ug_m3_tot_day_merge_obs['LMP'] >= 0.15) & (df_ug_m3_tot_day_merge_obs['ang_440_870'] <= 0.5)]\n",
    "angMax = df_ug_m3_tot_day_merge_obs['ang_440_870'].max()\n",
    "ang = df_ug_m3_tot_day_merge_obs['ang_440_870']\n",
    "angDD = events_DD['ang_440_870']\n",
    "plt.figure(figsize= (12, 8))\n",
    "\n",
    "cmap = plt.colormaps[\"viridis\"]\n",
    "norm = Normalize(vmin=0, vmax= asoil_percentage.max()*100)\n",
    "norm_ang = Normalize(vmin=0, vmax=angMax)\n",
    "\n",
    "f = plt.scatter(Time, df_ug_m3_tot_day_merge_obs['LMP'], c=ang , cmap= cmap, marker= 'o')\n",
    "#plt.stem(events_DD['time'], events_DD['LMP'], markerfmt= 'd', linefmt= '#e2c2c6', basefmt= 'black', label= 'DD events filtered')\n",
    "#plt.plot(events_DD['time'], events_DD['LMP'], c= '#a4bef3', label= 'DD events filtered', linestyle= '-.')\n",
    "plt.xlabel('Time [YYYY-MM]', fontsize= 12, fontweight= 'bold')\n",
    "plt.ylabel(r'$\\tau$', fontsize= 16)\n",
    "plt.xlim(Time.min(), Time.max())\n",
    "plt.ylim(0, None)\n",
    "plt.grid(True)\n",
    "plt.legend(labels= ['LMP', 'DD events filtered'])\n",
    "plt.title('Observations with ASOIL percentage associated', fontweight= 'bold')\n",
    "plt.colorbar(f, label=\"ASOIL percetntage on total aerosol concentrations [%]\")\n",
    "plt.colorbar()\n",
    "cbar.set_label(\"ASOIL percentage on total aerosol concentrations\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "type_data = ['LMP', 'IMP1F', 'IMP2F']\n",
    "cmap = plt.colormaps[\"viridis\"]\n",
    "norm = Normalize(vmin=0, vmax= ((events_DD['C_asoil'])/(events_DD['C_tot'])).max()*100)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(3, 1, figsize=(15, 12), sharex= True, sharey= True)\n",
    "\n",
    "for idx, name in enumerate(type_data):\n",
    "    if name == 'LMP':\n",
    "        sc_ang = ax[idx].scatter(events_DD['time'], events_DD[f'{name}'], c=angDD, cmap=cmap, norm=norm_ang, label=f'{name}', marker='p', s=45)\n",
    "        cbar2 = f.colorbar(ax=ax[idx], mappable=sc_ang, orientation='vertical', pad=0.05, cmap=cmap, norm=norm_ang )\n",
    "        ax[idx].grid(True)\n",
    "    #sc= ax[idx].scatter(Time, df_ug_m3_tot_day_merge_obs[f'{name}'], c= asoil_percentage*100, cmap= cmap, norm= norm, marker= 'o', label= f'{name}')\n",
    "    else:\n",
    "        sc= ax[idx].scatter(events_DD['time'], events_DD[f'{name}'], c= ((events_DD['C_asoil'])/(events_DD['C_tot']))*100, cmap= cmap, norm= norm, label= f\"DD events filtered of {name}\", marker= 'p', s= 45)\n",
    "        ax[idx].set_xlim(Time.min(), Time.max())\n",
    "        ax[idx].set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "        ax[idx].legend(loc= 'best')\n",
    "        ax[idx].grid(True)\n",
    "        if idx == 2:\n",
    "            ax[idx].set_xlabel('Time [YYYY-MM]', fontsize= 12, fontweight= 'bold')\n",
    "        else: \n",
    "            ax[idx].set_xlabel(None)\n",
    "        cbar = f.colorbar(ax=ax[idx], mappable= sc, orientation='vertical', pad=0.05, cmap=cmap, norm=norm)\n",
    "\n",
    "f.suptitle('Observations and modelled data with ASOIL percentage associated', fontsize= 16, fontweight= 'bold', y= 0.92)\n",
    "#cbar.set_label(\"ASOIL percentage on total aerosol concentrations [%]\", fontsize=16)\n",
    "#cbar2.set_label(\"ANG associated with observations\", fontsize=16)\n",
    "#plt.tight_layout(rect= [0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asoil_percentage = df_ug_m3_tot_day_merge_obs['C_asoil']/df_ug_m3_tot_day_merge_obs['C_tot']\n",
    "Time = df_ug_m3_tot_day_merge_obs['time']\n",
    "events_DD = df_ug_m3_tot_day_merge_obs[(df_ug_m3_tot_day_merge_obs['LMP'] >= 0.15) & (df_ug_m3_tot_day_merge_obs['ang_440_870'] <= 0.5)]\n",
    "angMax = events_DD['ang_440_870'].max()\n",
    "ang = events_DD['ang_440_870']\n",
    "\n",
    "cmap = plt.colormaps[\"viridis\"]\n",
    "cmap_r = plt.colormaps[\"viridis_r\"]\n",
    "norm_ang = Normalize(vmin=0, vmax=angMax)\n",
    "type_data = ['LMP', 'IMP1F', 'IMP2F']\n",
    "norm_asoil = Normalize(vmin=0, vmax= ((events_DD['C_asoil'])/(events_DD['C_tot'])).max()*100)\n",
    "\n",
    "f, ax = plt.subplots(3, 1, figsize=(15, 12), sharex=True, sharey=True)\n",
    "\n",
    "for idx, name in enumerate(type_data):\n",
    "    if name == 'LMP':\n",
    "        # Scatter plot per ANG\n",
    "        sc_ang = ax[idx].scatter(\n",
    "            events_DD['time'],\n",
    "            events_DD[f'{name}'],\n",
    "            c=ang,\n",
    "            cmap=cmap_r,\n",
    "            norm=norm_ang,\n",
    "            label=f'{name}',\n",
    "            marker='p',\n",
    "            s=45,\n",
    "        )\n",
    "        # Colorbar per ANG\n",
    "        cbar_ang = f.colorbar(\n",
    "            sc_ang,\n",
    "            ax=ax[idx],\n",
    "            orientation='vertical',\n",
    "            pad=0.05,\n",
    "            fraction=0.02,\n",
    "        )\n",
    "        cbar_ang.set_label(r\"$\\alpha$ associated\", fontsize=12)\n",
    "        ax[idx].set_ylabel(r'$\\tau$', fontsize=16)\n",
    "        ax[idx].legend(loc='best')\n",
    "        ax[idx].grid(True)\n",
    "    else:\n",
    "        # Scatter plot per ASOIL\n",
    "        sc = ax[idx].scatter(\n",
    "            events_DD['time'],\n",
    "            events_DD[f'{name}'],\n",
    "            c=((events_DD['C_asoil']) / (events_DD['C_tot'])) * 100,\n",
    "            cmap=cmap,\n",
    "            norm=norm_asoil,\n",
    "            label=f\"DD events filtered of {name}\",\n",
    "            marker='p',\n",
    "            s=45,\n",
    "        )\n",
    "        # Colorbar per ASOIL\n",
    "        cbar_asoil = f.colorbar(\n",
    "            sc,\n",
    "            ax=ax[idx],\n",
    "            orientation='vertical',\n",
    "            pad=0.05,\n",
    "            fraction=0.02,\n",
    "        )\n",
    "        cbar_asoil.set_label(\"DUST concentrations [%]\", fontsize=12)\n",
    "        ax[idx].set_ylabel(r'$\\tau$', fontsize=16)\n",
    "        ax[idx].legend(loc='best')\n",
    "        ax[idx].grid(True)\n",
    "\n",
    "    if idx == 2:\n",
    "        ax[idx].set_xlabel('Time [YYYY-MM]', fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        ax[idx].set_xlabel(None)\n",
    "\n",
    "# Titolo globale\n",
    "f.suptitle('Observations and modelled data with DUST percentage associated', fontsize=16, fontweight='bold', y=0.92)\n",
    "#plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "#plt.savefig('/home/andtoro/figure/ang_concentration.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of $\\frac{ASOIL}{AOD_{tot}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_DD_aod_1 = df_SPEC_IMP1['M24'][(df_SPEC_IMP1['M24']['LMP'] >= 0.15) & (df_SPEC_IMP1['M24']['ang_440_870'] <= 0.5)]\n",
    "events_DD_aod_2 = df_SPEC_IMP2['M24'][(df_SPEC_IMP2['M24']['LMP'] >= 0.15) & (df_SPEC_IMP2['M24']['ang_440_870'] <= 0.5)]\n",
    "frac_1= ((events_DD_aod_1['ASOIL'])/(events_DD_aod_1['IMP1F']))\n",
    "frac_2= ((events_DD_aod_2['ASOIL'])/(events_DD_aod_2['IMP2F']))\n",
    "Time1= events_DD_aod_1['time']\n",
    "Time2= events_DD_aod_2['time']\n",
    "cmap = plt.colormaps[\"plasma\"]\n",
    "\n",
    "fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex= True, sharey= True)\n",
    "\n",
    "norm1 = Normalize(vmin=0, vmax= frac_1.max()*100)\n",
    "\n",
    "sc1= ax1.scatter(Time1, events_DD_aod_1['LMP'], cmap= cmap, norm= norm1, c= frac_1*100)\n",
    "ax1.grid(True)\n",
    "ax1.set_xlim(Time1.min(), Time1.max())\n",
    "ax1.set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "ax1.legend(labels= ['LMP'])\n",
    "\n",
    "sc2= ax2.scatter(Time1, events_DD_aod_1['IMP1F'], cmap= cmap, norm= norm1, c= frac_1*100)\n",
    "ax2.grid(True)\n",
    "ax2.set_xlim(Time1.min(), Time1.max())\n",
    "ax2.set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "ax2.set_xlabel('Time [YYYY-MM]', fontweight= 'bold')\n",
    "ax2.legend(labels= ['IMP1F'])\n",
    "\n",
    "fig1.suptitle('Observation and modelled data with ASOIL percentage associated on total AOD', fontsize= 16, fontweight= 'bold', y= 0.94)\n",
    "cbar = fig1.colorbar(ax=(ax1, ax2), mappable= sc2, orientation='vertical', pad=0.05, cmap= cmap, norm= norm)\n",
    "cbar.set_label(\"ASOIL percentage on total aerosol concentrations [%]\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "fig2, (ax3, ax4) = plt.subplots(2, 1, figsize=(12, 8), sharex= True, sharey= True)\n",
    "\n",
    "norm2 = Normalize(vmin=0, vmax= frac_2.max()*100)\n",
    "sc3= ax3.scatter(Time2, events_DD_aod_2['LMP'], cmap= cmap, norm= norm2, c= frac_2*100)\n",
    "ax3.grid(True)\n",
    "ax3.set_xlim(Time2.min(), Time2.max())\n",
    "ax3.set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "ax3.legend(labels=['LMP'])\n",
    "\n",
    "sc4= ax4.scatter(Time2, events_DD_aod_2['IMP2F'], cmap= cmap, norm= norm2, c= frac_2*100)\n",
    "ax4.grid(True)\n",
    "ax4.set_xlim(Time2.min(), Time2.max())\n",
    "ax4.set_xlabel('Time [YYYY-MM]', fontweight= 'bold')\n",
    "ax4.set_ylabel(r'$\\tau$', fontsize= 16)\n",
    "ax4.legend(labels= ['IMP2F'])\n",
    "\n",
    "fig2.suptitle('Observation and modelled data with ASOIL percentage associated on total AOD', fontsize= 16, fontweight= 'bold', y= 0.94)\n",
    "cbar = fig2.colorbar(ax=(ax3, ax4), mappable= sc4, orientation='vertical', pad=0.05, cmap= cmap, norm= norm)\n",
    "cbar.set_label(\"ASOIL percentage on total aerosol concentrations [%]\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "events_DD_aod_1 = df_SPEC_IMP1['M24'][(df_SPEC_IMP1['M24']['LMP'] >= 0.15) & (df_SPEC_IMP1['M24']['ang_440_870'] <= 0.5)]\n",
    "events_DD_aod_2 = df_SPEC_IMP2['M24'][(df_SPEC_IMP2['M24']['LMP'] >= 0.15) & (df_SPEC_IMP2['M24']['ang_440_870'] <= 0.5)]\n",
    "events_DD_aod_1.reset_index(inplace=True, drop=True)\n",
    "events_DD_aod_2.reset_index(inplace=True, drop=True)\n",
    "frac_1= ((events_DD_aod_1['ASOIL'])/(events_DD_aod_1['IMP1F']))\n",
    "frac_2= ((events_DD_aod_2['ASOIL'])/(events_DD_aod_2['IMP2F']))\n",
    "\n",
    "ang1 = events_DD_aod_1['ang_440_870']\n",
    "ang2 = events_DD_aod_2['ang_440_870']\n",
    "\n",
    "Time1= events_DD_aod_1['time']\n",
    "Time2= events_DD_aod_2['time']\n",
    "cmap = plt.colormaps[\"plasma\"]\n",
    "cmap_r = plt.colormaps[\"plasma_r\"]\n",
    "\n",
    "# Figure 1: Fraction 1 (ASOIL/IMP1F)\n",
    "fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "\n",
    "norm1 = Normalize(vmin=0, vmax=frac_1.max() * 100)\n",
    "norm_ang_1 = Normalize(vmin=0, vmax=ang1.max())\n",
    "\n",
    "idx_1, idx_2 = 25, 26  # Change this to select a different point\n",
    "x_1 = events_DD_aod_1['LMP'].iloc[idx_1]\n",
    "y_1 = events_DD_aod_1['IMP1F'].iloc[idx_1]\n",
    "x_2 = events_DD_aod_1['LMP'].iloc[idx_2]\n",
    "y_2 = events_DD_aod_1['IMP1F'].iloc[idx_2]\n",
    "\n",
    "x_3 = events_DD_aod_2['LMP'].iloc[idx_1]\n",
    "y_3 = events_DD_aod_2['IMP2F'].iloc[idx_1]\n",
    "x_4 = events_DD_aod_2['LMP'].iloc[idx_2]\n",
    "y_4 = events_DD_aod_2['IMP2F'].iloc[idx_2]\n",
    "\n",
    "# First subplot with colorbar for LMP\n",
    "sc1 = ax1.scatter(Time1, events_DD_aod_1['LMP'], cmap=cmap_r, norm=norm_ang_1, c=ang1)\n",
    "ax1.scatter(x_1,  y_1, facecolors='none', edgecolors='blue', s=200, linewidths=2)\n",
    "ax1.scatter(x_1,  y_1, c= 'red', s=30)\n",
    "ax1.scatter(x_1, y_1, facecolors='none', edgecolors='blue', s=200, linewidths=2)\n",
    "ax1.grid(True)\n",
    "ax1.set_xlim(Time1.min(), Time1.max())\n",
    "ax1.set_ylabel(r'$\\tau$', fontsize=16)\n",
    "ax1.legend(labels=['LMP'])\n",
    "# circle_1 = Circle((x_label_1, y_label_1), radius=1.0, color='blue', fill=True, linewidth=0.5)\n",
    "# ax1.add_patch(circle_1) \n",
    "# circle_2 = Circle((x_label_2, y_label_2), radius=1.0, color='blue', fill=False, linewidth=0.5)\n",
    "# ax1.add_patch(circle_2)\n",
    "cbar1 = fig1.colorbar(sc1, ax=ax1, orientation='vertical', pad=0.05, fraction=0.02)\n",
    "cbar1.set_label(r\"$\\alpha_{(440-870)nm}$ associated\", fontsize=12)\n",
    " \n",
    "\n",
    "# Second subplot with colorbar for IMP1F\n",
    "sc2 = ax2.scatter(Time1, events_DD_aod_1['IMP1F'], cmap=cmap, norm=norm1, c=frac_1 * 100)\n",
    "ax2.scatter(x_1,  y_1, facecolors='none', edgecolors='blue', s=200, linewidths=2)\n",
    "ax2.scatter(x_1, y_1, facecolors='none', edgecolors='blue', s=200, linewidths=2)\n",
    "ax2.grid(True)\n",
    "ax2.set_xlim(Time1.min(), Time1.max())\n",
    "ax2.set_ylabel(r'$\\tau$', fontsize=16)\n",
    "ax2.set_xlabel('Time [YYYY-MM]', fontweight='bold')\n",
    "ax2.legend(labels=['IMP1F'])\n",
    "# circle_1 = Circle((x_label_1, y_label_1), radius=0.5, color='blue', fill=False, linewidth=0.5)\n",
    "# ax2.add_patch(circle_1) \n",
    "# circle_2 = Circle((x_label_2, y_label_2), radius=0.5, color='blue', fill=False, linewidth=0.5)\n",
    "# ax2.add_patch(circle_2) \n",
    "cbar2 = fig1.colorbar(sc2, ax=ax2, orientation='vertical', pad=0.05, fraction=0.02)\n",
    "cbar2.set_label(\"DUST concentrations [%]\", fontsize=12)\n",
    "\n",
    "\n",
    "fig1.suptitle('Observations and modeled data with DUST percentage associated on total AOD (IMP1F)', \n",
    "              fontsize=16, fontweight='bold', y=0.94)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "#plt.savefig('/home/andtoro/figure/ang_AOSIL_percent_IMP1.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Figure 2: Fraction 2 (ASOIL/IMP2F)\n",
    "fig2, (ax3, ax4) = plt.subplots(2, 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "\n",
    "norm2 = Normalize(vmin=0, vmax=frac_2.max() * 100)\n",
    "norm_ang_2 = Normalize(vmin=0, vmax=ang2.max())\n",
    "\n",
    "# First subplot with colorbar for LMP\n",
    "sc3 = ax3.scatter(Time2, events_DD_aod_2['LMP'], cmap=cmap_r, norm=norm_ang_2, c=ang2)\n",
    "ax3.grid(True)\n",
    "ax3.set_xlim(Time2.min(), Time2.max())\n",
    "ax3.set_ylabel(r'$\\tau$', fontsize=16)\n",
    "ax3.legend(labels=['LMP'])\n",
    "cbar3 = fig2.colorbar(sc3, ax=ax3, orientation='vertical', pad=0.05, fraction=0.02)\n",
    "cbar3.set_label(r\"$\\alpha_{(440-870)nm}$ associated\", fontsize=12)\n",
    "# circle_3 = Circle((x_label_3, y_label_3), radius=0.02, color='blue', fill=False, linewidth=2)\n",
    "# ax3.add_patch(circle_3) \n",
    "# circle_4 = Circle((x_label_4, y_label_4), radius=0.02, color='blue', fill=False, linewidth=2)\n",
    "# ax3.add_patch(circle_4)\n",
    "# Second subplot with colorbar for IMP2F\n",
    "sc4 = ax4.scatter(Time2, events_DD_aod_2['IMP2F'], cmap=cmap, norm=norm2, c=frac_2 * 100)\n",
    "ax4.grid(True)\n",
    "ax4.set_xlim(Time2.min(), Time2.max())\n",
    "ax4.set_xlabel('Time [YYYY-MM]', fontweight='bold')\n",
    "ax4.set_ylabel(r'$\\tau$', fontsize=16)\n",
    "ax4.legend(labels=['IMP2F'])\n",
    "cbar4 = fig2.colorbar(sc4, ax=ax4, orientation='vertical', pad=0.05, fraction=0.02)\n",
    "cbar4.set_label(\"DUST concentrations [%]\", fontsize=12)\n",
    "# circle_3 = Circle((x_label_3, y_label_3), radius=0.02, color='blue', fill=False, linewidth=2)\n",
    "# ax4.add_patch(circle_3) \n",
    "# circle_4 = Circle((x_label_4, y_label_4), radius=0.02, color='blue', fill=False, linewidth=2)\n",
    "# ax4.add_patch(circle_4)\n",
    "fig2.suptitle('Observations and modeled data with DUST percentage associated on total AOD (IMP2F)', \n",
    "              fontsize=16, fontweight='bold', y=0.94)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "#plt.savefig('/home/andtoro/figure/ang_AOSIL_percent_IMP2.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm1 = Normalize(vmin=0, vmax= frac_1.max()*100)\n",
    "norm2 = Normalize(vmin=0, vmax= frac_2.max()*100)\n",
    "cmap = plt.colormaps[\"plasma\"]\n",
    "\n",
    "fig3 = plt.figure(figsize= (10, 6))\n",
    "\n",
    "sc5= plt.scatter(events_DD_aod_1['LMP'], events_DD_aod_1['IMP1F'], c= frac_1*100, cmap= cmap, norm= norm1)\n",
    "plt.xlim(left= 0.15)\n",
    "plt.ylim(bottom= 0)\n",
    "plt.grid(True)\n",
    "plt.title('Scatter plot with ASOIL percentage associated', fontweight= 'bold')\n",
    "plt.xlabel('LMP', fontsize= 16)\n",
    "plt.ylabel('IMP1F', fontsize= 16)\n",
    "plt.colorbar(sc5, label=\"ASOIL percetntage on total aerosol concentrations [%]\")\n",
    "cbar.set_label(\"ASOIL percentage on total aerosol concentrations\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig4 = plt.figure(figsize= (10, 6))\n",
    "\n",
    "sc6= plt.scatter(events_DD_aod_2['LMP'], events_DD_aod_2['IMP2F'], c= frac_2*100, cmap= cmap, norm= norm2)\n",
    "plt.xlim(left= 0.15)\n",
    "plt.ylim(bottom= 0)\n",
    "plt.grid(True)\n",
    "plt.title('Scatter plot with ASOIL percentage associated', fontweight= 'bold')\n",
    "plt.xlabel('LMP', fontsize= 16)\n",
    "plt.ylabel('IMP2F', fontsize= 16)\n",
    "plt.colorbar(sc6, label=\"ASOIL percetntage on total aerosol concentrations [%]\")\n",
    "cbar.set_label(\"ASOIL percentage on total aerosol concentrations\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_DD_out = DeDu24['LMP'].to_numpy()\n",
    "imp1_odr_DD = DeDu24['IMP1F_ODR'].to_numpy()\n",
    "imp1_odr_DD = DeDu24['IMP2F_ODR'].to_numpy()\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Calculate Bias\n",
    "    bias = np.mean(y_true - y_pred)\n",
    "\n",
    "    # Calculate Correlation\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt((np.mean((y_true - y_pred) ** 2 )))\n",
    "    \n",
    "    # Calculate NMSE\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    var_y = np.var(y_true)\n",
    "    #nmse = mse / var_y if var_y != 0 else np.nan  # Avoid division by zero\n",
    "\n",
    "    # Calculate Variance\n",
    "    variance = var_y\n",
    "    return bias, corr, rmse, variance, mse\n",
    "\n",
    "# Calculate metrics for each comparison\n",
    "metrics_imp1f= calculate_metrics(obs_DD_out, imp1_odr_DD)\n",
    "metrics_imp1f= calculate_metrics(obs_DD_out, imp1_odr_DD)\n",
    "\n",
    "# Print the results\n",
    "print(\"Metrics for AOD (FARM-DD):\")\n",
    "print(f'Bias: {metrics_farm_DD[0]}, Correlation: {metrics_farm_DD[1]}, RMSE: {metrics_farm_DD[2]}, Variance: {metrics_farm_DD[3]}, n_DD: {len(obs_DD)}')\n",
    "print(\"Metrics for AOD (FARM-BU):\")\n",
    "print(f'Bias: {metrics_farm_BB[0]}, Correlation: {metrics_farm_BB[1]}, RMSE: {metrics_farm_BB[2]}, Variance: {metrics_farm_BB[3]}, n_BB: {len(obs_BB)}')\n",
    "print(\"Metrics for AOD (FARM-M):\")\n",
    "print(f'Bias: {metrics_farm_MX[0]}, Correlation: {metrics_farm_MX[1]}, RMSE: {metrics_farm_MX[2]}, Variance: {metrics_farm_MX[3]}, n_MX: {len(obs_MX)}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP1F-DD):\")\n",
    "print(f'Bias: {metrics_imp1f_DD[0]}, Correlation: {metrics_imp1f_DD[1]}, RMSE: {metrics_imp1f_DD[2]}, Variance: {metrics_imp1f_DD[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP1F-BU):\")\n",
    "print(f'Bias: {metrics_imp1f_BB[0]}, Correlation: {metrics_imp1f_BB[1]}, RMSE: {metrics_imp1f_BB[2]}, Variance: {metrics_imp1f_BB[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP1F-M):\")\n",
    "print(f'Bias: {metrics_imp1f_MX[0]}, Correlation: {metrics_imp1f_MX[1]}, RMSE: {metrics_imp1f_MX[2]}, Variance: {metrics_imp1f_MX[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP1F_ODR-DD):\")\n",
    "print(f'Bias: {metrics_imp1f_odr_DD[0]}, Correlation: {metrics_imp1f_odr_DD[1]}, RMSE: {metrics_imp1f_odr_DD[2]}, Variance: {metrics_imp1f_odr_DD[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP1F_ODR-BB):\")\n",
    "print(f'Bias: {metrics_imp1f_odr_BB[0]}, Correlation: {metrics_imp1f_odr_BB[1]}, RMSE: {metrics_imp1f_odr_BB[2]}, Variance: {metrics_imp1f_odr_BB[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP1F_ODR-MX):\")\n",
    "print(f'Bias: {metrics_imp1f_odr_MX[0]}, Correlation: {metrics_imp1f_odr_MX[1]}, RMSE: {metrics_imp1f_odr_MX[2]}, Variance: {metrics_imp1f_odr_MX[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP2F-DD):\")\n",
    "print(f'Bias: {metrics_imp2f_DD[0]}, Correlation: {metrics_imp2f_DD[1]}, RMSE: {metrics_imp2f_DD[2]}, Variance: {metrics_imp2f_DD[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP2F-BB):\")\n",
    "print(f'Bias: {metrics_imp2f_BB[0]}, Correlation: {metrics_imp2f_BB[1]}, RMSE: {metrics_imp2f_BB[2]}, Variance: {metrics_imp2f_BB[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP2F-MX):\")\n",
    "print(f'Bias: {metrics_imp2f_MX[0]}, Correlation: {metrics_imp2f_MX[1]}, RMSE: {metrics_imp2f_MX[2]}, Variance: {metrics_imp2f_MX[3]}')\n",
    "\n",
    "print(\"\\nMetrics for AOD (IMP2F_ODR-DD):\")\n",
    "print(f'Bias: {metrics_imp2f_odr_DD[0]}, Correlation: {metrics_imp2f_odr_DD[1]}, RMSE: {metrics_imp2f_odr_DD[2]}, Variance: {metrics_imp2f_odr_DD[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP2F_ODR-BB):\")\n",
    "print(f'Bias: {metrics_imp2f_odr_BB[0]}, Correlation: {metrics_imp2f_odr_BB[1]}, RMSE: {metrics_imp2f_odr_BB[2]}, Variance: {metrics_imp2f_odr_BB[3]}')\n",
    "print(\"\\nMetrics for AOD (IMP2F_ODR-MX):\")\n",
    "print(f'Bias: {metrics_imp2f_odr_MX[0]}, Correlation: {metrics_imp2f_odr_MX[1]}, RMSE: {metrics_imp2f_odr_MX[2]}, Variance: {metrics_imp2f_odr_MX[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Normalization for color mapping\n",
    "norm1 = Normalize(vmin=0, vmax=frac_1.max() * 100)\n",
    "norm2 = Normalize(vmin=0, vmax=frac_2.max() * 100)\n",
    "cmap = plt.colormaps[\"plasma\"]\n",
    "\n",
    "# First scatter plot\n",
    "fig3 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "sc5 = plt.scatter(events_DD_aod_1['LMP'], events_DD_aod_1['IMP1F'], c=frac_1 * 100, cmap=cmap, norm=norm1)\n",
    "plt.xlim(left=0.15)\n",
    "plt.ylim(bottom=0)\n",
    "plt.grid(True)\n",
    "plt.title('Scatter plot with ASOIL percentage associated', fontweight='bold')\n",
    "plt.xlabel('LMP', fontsize=16)\n",
    "plt.ylabel('IMP1F', fontsize=16)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(sc5)\n",
    "cbar.set_label(\"DUST percentage on total aerosol concentrations [%]\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Second scatter plot\n",
    "fig4 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "sc6 = plt.scatter(events_DD_aod_2['LMP'], events_DD_aod_2['IMP2F'], c=frac_2 * 100, cmap=cmap, norm=norm2)\n",
    "plt.xlim(left=0.15)\n",
    "plt.ylim(bottom=0)\n",
    "plt.grid(True)\n",
    "plt.title('Scatter plot with DUST percentage associated', fontweight='bold')\n",
    "plt.xlabel('LMP', fontsize=16)\n",
    "plt.ylabel('IMP2F', fontsize=16)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(sc6)\n",
    "cbar.set_label(\"DUST percentage on total aerosol concentrations [%]\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "events_DD_aod_1 = df_SPEC_IMP1['M24'][(df_SPEC_IMP1['M24']['LMP'] >= 0.15) & (df_SPEC_IMP1['M24']['ang_440_870'] <= 0.5)]\n",
    "events_DD_aod_2 = df_SPEC_IMP2['M24'][(df_SPEC_IMP2['M24']['LMP'] >= 0.15) & (df_SPEC_IMP2['M24']['ang_440_870'] <= 0.5)]\n",
    "frac_1= ((events_DD_aod_1['ASOIL'])/(events_DD_aod_1['IMP1F']))\n",
    "frac_2= ((events_DD_aod_2['ASOIL'])/(events_DD_aod_2['IMP2F']))\n",
    "Time1= events_DD_aod_1['time']\n",
    "Time2= events_DD_aod_2['time']\n",
    "events_DD_aod_1.reset_index(inplace=True)\n",
    "events_DD_aod_2.reset_index(inplace=True)\n",
    "\n",
    "# Normalization for color mapping\n",
    "norm1 = Normalize(vmin=0, vmax=frac_1.max() * 100)\n",
    "norm2 = Normalize(vmin=0, vmax=frac_2.max() * 100)\n",
    "cmap = plt.colormaps[\"plasma\"]\n",
    "\n",
    "# Create subplots: 1 row, 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)  # `sharey=True` aligns the y-axis\n",
    "\n",
    "# First scatter plot\n",
    "sc1 = ax1.scatter(events_DD_aod_1['LMP'], events_DD_aod_1['IMP1F'], c=frac_1 * 100, cmap=cmap, norm=norm1)\n",
    "ax1.set_xlim(left=0.15)\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.grid(True)\n",
    "ax1.set_title('Scatter plot DD events', fontweight='bold')\n",
    "ax1.set_xlabel('LMP', fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_ylabel('IMP1F', fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar1 = fig.colorbar(sc1, ax=ax1)\n",
    "cbar1.set_label(\"DUST percentage [%]\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "idx_1 = 25  # Change this to select a different point\n",
    "x_label_1 = events_DD_aod_1['LMP'].iloc[idx_1]\n",
    "y_label_1 = events_DD_aod_1['IMP1F'].iloc[idx_1]\n",
    "time_label_1 = events_DD_aod_1['time'].iloc[idx_1].strftime('%Y-%m-%d')  # Example: \"2024-01-30 14:45\"\n",
    "\n",
    "ax1.text(x_label_1, y_label_1, f\"{time_label_1}\", fontsize=12, color=\"black\", ha=\"right\", va=\"top\")\n",
    "\n",
    "idx_2 = 26  # Change this to select a different point\n",
    "x_label_2 = events_DD_aod_1['LMP'].iloc[idx_2]\n",
    "y_label_2 = events_DD_aod_1['IMP1F'].iloc[idx_2]\n",
    "time_label_2 = events_DD_aod_1['time'].iloc[idx_2].strftime('%Y-%m-%d')  # Example: \"30-Jan 14:45\" \n",
    "\n",
    "ax1.text(x_label_2, y_label_2, f\"{time_label_2}\", fontsize=12, color=\"black\", ha=\"right\", va=\"top\")\n",
    "# Second scatter plot\n",
    "sc2 = ax2.scatter(events_DD_aod_2['LMP'], events_DD_aod_2['IMP2F'], c=frac_2 * 100, cmap=cmap, norm=norm2)\n",
    "ax2.set_xlim(left=0.15)\n",
    "ax2.set_ylim(bottom=0)\n",
    "ax2.grid(True)\n",
    "ax2.set_title('Scatter plot DD events', fontweight='bold')\n",
    "ax2.set_xlabel('LMP', fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_ylabel('IMP2F', fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "idx_3 = 25  # Change this to select a different point\n",
    "x_label_3 = events_DD_aod_2['LMP'].iloc[idx_3]\n",
    "y_label_3 = events_DD_aod_2['IMP1F'].iloc[idx_3]\n",
    "time_label_3 = events_DD_aod_2['time'].iloc[idx_3].strftime('%Y-%m-%d')  # Example: \"14:45:30\"\n",
    "\n",
    "ax2.text(x_label_3, y_label_3, f\"{time_label_3}\", fontsize=12, color=\"black\", ha=\"right\", va=\"bottom\")\n",
    "\n",
    "idx_4 = 26  # Change this to select a different point\n",
    "x_label_4 = events_DD_aod_2['LMP'].iloc[idx_4]\n",
    "y_label_4 = events_DD_aod_2['IMP1F'].iloc[idx_4]\n",
    "time_label_4 = events_DD_aod_2['time'].iloc[idx_4].strftime('%Y-%m-%d')\n",
    "\n",
    "ax2.text(x_label_4, y_label_4, f\"{time_label_4}\", fontsize=12, color=\"black\", ha=\"right\", va=\"bottom\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar2 = fig.colorbar(sc2, ax=ax2)\n",
    "cbar2.set_label(\"DUST percentage [%]\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ang_AOSIL_per_IMP12_scatter.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "cmap = plt.colormaps[\"plasma_r\"]\n",
    "\n",
    "# Create subplots: 1 row, 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)  # `sharey=True` aligns the y-axis\n",
    "\n",
    "# First scatter plot\n",
    "sc1 = ax1.scatter(Data['1D']['LMP'], Data['1D']['IMP1F_ODR'], c=Data['1D']['ang_440_870'], cmap=cmap)\n",
    "sc1 = ax1.scatter(Data['1D']['LMP'], Data['1D']['IMP1F'], c=\"blue\")\n",
    "ax1.set_xlim(left=0.15)\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.grid(True)\n",
    "ax1.set_title('Scatter plot DD events', fontweight='bold')\n",
    "ax1.set_xlabel('LMP', fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_ylabel('IMP1F_ODR', fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar1 = fig.colorbar(sc1, ax=ax1)\n",
    "cbar1.set_label(\"ASOIL percentage [%]\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Second scatter plot\n",
    "sc2 = ax2.scatter(Data['1D']['LMP'], Data['1D']['IMP2F_ODR'], c=Data['1D']['ang_440_870'], cmap=cmap)\n",
    "sc2 = ax2.scatter(Data['1D']['LMP'], Data['1D']['IMP2F'], c=\"blue\")\n",
    "ax2.set_xlim(left=0.15)\n",
    "ax2.set_ylim(bottom=0)\n",
    "ax2.grid(True)\n",
    "ax2.set_title('Scatter plot DD events', fontweight='bold')\n",
    "ax2.set_xlabel('LMP', fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_ylabel('IMP2F_ODR', fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar2 = fig.colorbar(sc2, ax=ax2)\n",
    "cbar2.set_label(\"ASOIL percentage [%]\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/home/andtoro/figure/ang_AOSIL_per_IMP12_scatter.pdf', format='pdf', bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(len(Data['1D']['LMP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specs = ['ASO4', 'ANO3', 'OTHER', 'ASEAS', 'ASOIL']\n",
    "# colors = {\n",
    "#     'Layer 0': '#17bebb', \n",
    "#     'Layer 1': '#f9cff2', \n",
    "#     'Layer 2': '#cd5334', \n",
    "#     'Layer 3': '#8cc084', \n",
    "#     'Layer 4': '#edb88b', \n",
    "#     'Layer 5': '#a491d3',\n",
    "#     'Layer 6': '#c5dca0',\n",
    "#     'Layer 7': '#9000b3',\n",
    "#     'Layer 8': '#ba1200',\n",
    "#     'Layer 9': '#f87575',\n",
    "#     'Layer 10': '#cfd11a',\n",
    "#     'Layer 11': '#e6af2e',\n",
    "#     'Layer 12': '#573d1c'\n",
    "#     }\n",
    "# colors_spec = ['#b20d30', '#caf7e2', '#c17817', '#3f84e5', '#3f784c']\n",
    "# colors_name = {\n",
    "#     'ASO4': '#b20d30',\n",
    "#     'ANO3': '#8d9f87',\n",
    "#     'ASOIL': '#c17817',\n",
    "#     'ASEAS': '#3f84e5',\n",
    "#     'OTHER': '#3f784c'\n",
    "# }\n",
    "\n",
    "# fig, ax = plt.subplots(5, 1, sharex= True, sharey= True, figsize= (12, 12))\n",
    "\n",
    "# for k, h in enumerate(specs):\n",
    "#     bot_x = np.zeros(len(df_FarmRhSpecies_merged_layer))\n",
    "#     for i, j in enumerate(colors): \n",
    "#         ax[k].plot(df_FarmRhSpecies_merged_layer['time'], bot_x+df_FarmRhSpecies_merged_layer[f'{h}_layer_{i}'], color= colors[f'{j}'])\n",
    "#         bot_x += df_FarmRhSpecies_merged_layer[f'{h}_layer_{i}']\n",
    "#         ax[k].set_ylabel(f'AOD [ad.] of {h}')\n",
    "# ax[-1].set_xlabel('Time [yyyy/mm]')\n",
    "\n",
    "# fig.legend(labels= [j for j in colors], ncol= 3)\n",
    "# fig.suptitle(r'Species by layer (24h)')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"/home/andtoro/figure/AOD_SpLY_separate_24h.svg\", format=\"svg\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize= (10, 10))\n",
    "\n",
    "# fig, ax = plt.subplots(4, 4, sharex= False, sharey= True, figsize= (12, 12))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "# for i, j in enumerate(colors):\n",
    "#     for k, h in enumerate(specs): \n",
    "#         ax[i].plot(df_FarmRhSpecies_merged_layer['time'], df_FarmRhSpecies_merged_layer[f'{h}_layer_{i}'], color= colors_name[f'{h}'])\n",
    "#         ax[i].set_title(f'Layer_{i}')\n",
    "#         ax[i].set_xlabel('Time [yyyy/mm]')\n",
    "#         ax[i].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "#         ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "#         ax[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# for i in range(len(colors), len(ax)):\n",
    "#     ax[i].axis('off')\n",
    "\n",
    "# fig.legend(labels= [k for k in specs], ncol= 3, loc='upper center', bbox_to_anchor=(0.9, 1.01), fontsize='small', fancybox= True, shadow= True)\n",
    "# fig.suptitle(r'Layers for each species (24h)', fontweight='bold', y= 1.01)\n",
    "# fig.text(0.01, 0.52, 'AOD [ad.]', va='center', rotation='vertical', fontsize=12)\n",
    "# #fig.text(0.5, 0.04, 'Date [yyyy/mm]', ha='center', fontsize=12)\n",
    "# fig.subplots_adjust(top=0.90)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"/home/andtoro/figure/AOD_SpLy_24h_species_for_layer.svg\", format=\"svg\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe with LMP, IMP1F, IMP2F with errors to do the Nested Sampling (daily data)\n",
    "import pandas as pd\n",
    "# Data = {\n",
    "#     '1H': data_h['m1'],\n",
    "#     '3H': data_h['m3'],\n",
    "#     '6H': data_h['m6'],\n",
    "#      '1D': pd.merge(data_h['m24'], df_ErrMod, on= 'time', how= 'inner'),\n",
    "#      '1D_f': df_cleaned\n",
    "# }\n",
    "\n",
    "# DeDu24 = Data['1D'][\n",
    "#     (Data['1D']['LMP'] >= 0.15) & \n",
    "#     (Data['1D']['ang_440_870'] <= 0.5)\n",
    "# ]\n",
    "\n",
    "# dati totali\n",
    "data_fit_all = pd.DataFrame({\n",
    "    'time': Data['1D']['time'], \n",
    "    'LMP': Data['1D']['LMP'],\n",
    "    'err_LMP': Data['1D']['err_day_new'],\n",
    "    'FARM': Data['1D']['FARM'],\n",
    "    'err_FARM': Data['1D']['errFarm_24'],\n",
    "    'IMP1F': Data['1D']['IMP1F'],\n",
    "    'err_IMP1F': Data['1D']['err_IMP1_24'],\n",
    "    'IMP2F': Data['1D']['IMP2F'],\n",
    "    'err_IMP2F': Data['1D']['err_IMP2_24']\n",
    "})\n",
    "\n",
    "# dati relativi al Desert Dust\n",
    "data_fit_DD = pd.DataFrame({\n",
    "    'time': DeDu24['time'], \n",
    "    'LMP': DeDu24['LMP'],\n",
    "    'err_LMP': DeDu24['err_day_new'],\n",
    "    'FARM': DeDu24['FARM'],\n",
    "    'err_FARM': DeDu24['errFarm_24'],\n",
    "    'IMP1F': DeDu24['IMP1F'],\n",
    "    'err_IMP1F': DeDu24['err_IMP1_24'],\n",
    "    'IMP2F': DeDu24['IMP2F'],\n",
    "    'err_IMP2F': DeDu24['err_IMP2_24']\n",
    "})\n",
    "\n",
    "# dati relativi al Desert Dust puliti sulle ore di luce al 50%\n",
    "data_fit_DD_clean_50 = pd.DataFrame({\n",
    "    'data_x': DeDu24_f_outliers['LMP'],\n",
    "    'sigma_x': DeDu24_f_outliers['err_day_new'],\n",
    "    'data_y_1': DeDu24_f_outliers['IMP1F'],\n",
    "    'sigma_y_1': DeDu24_f_outliers['err_IMP1_24'],\n",
    "    'data_y_2': DeDu24_f_outliers['IMP2F'],\n",
    "    'sigma_y_2': DeDu24_f_outliers['err_IMP2_24']\n",
    "})\n",
    "\n",
    "#data_fit_DD.to_csv(\"/home/andtoro/project_enea/enea_2/dati_DD.txt\", index=False, sep='\\t')\n",
    "#data_fit_DD_clean_50.to_csv(\"/home/andtoro/project_enea/enea_2/dati_DD_50.txt\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taylor Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skill_metrics import taylor_diagram\n",
    "\n",
    "# # Your data\n",
    "# observations = np.array(Data['1D']['LMP'])\n",
    "# models = {\n",
    "#     \"FARM\": np.array(Data['1D']['FARM']),\n",
    "#     \"IMP1F\": np.array(Data['1D']['IMP1F']),\n",
    "#     \"IMP2F\": np.array(Data['1D']['IMP2F']),\n",
    "#     \"IMP1F_ODR\": np.array(Data['1D']['IMP1F_ODR']),\n",
    "#     \"IMP2F_ODR\": np.array(Data['1D']['IMP2F_ODR'])\n",
    "# }\n",
    "\n",
    "# # Compute standard deviations and correlations for each model\n",
    "# std_ref = np.std(observations, ddof=1)  # Reference standard deviation\n",
    "# std_models = []\n",
    "# rms_models = [] \n",
    "# corr_models = []\n",
    "# model_names = []\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     std_models.append(np.std(model, ddof=1))  # Standard deviation\n",
    "#     rms = np.sqrt(np.mean((model - observations)**2))  # Root Mean Square (RMS)\n",
    "#     rms_models.append(rms) \n",
    "#     corr_models.append(np.corrcoef(observations, model)[0, 1])  # Correlation\n",
    "#     model_names.append(name)\n",
    "\n",
    "# std_models = np.array(std_models)\n",
    "# corr_models = np.array(corr_models)\n",
    "# rms_models = np.array(rms_models)\n",
    "\n",
    "# print(\"Correlation Coefficients:\", corr_models)\n",
    "# print(\"Standard Deviations:\", std_models)\n",
    "# print(\"RMS:\", rms_models)\n",
    "# print(\"Reference Standard Deviation:\", std_ref)\n",
    "# print(\"Length of observations:\", len(observations))\n",
    "# print(\"Length of models:\", [len(model) for model in models.values()])\n",
    "\n",
    "# #max_std = max(std_models.max(), std_ref) * 1.2\n",
    "# max_std = 0.5\n",
    "# # Create figure with square aspect ratio\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='polar')\n",
    "\n",
    "# # Configure polar plot\n",
    "# ax.set_theta_zero_location('E')\n",
    "# ax.set_theta_direction(1)\n",
    "# ax.set_rlim(0, 1)\n",
    "# ax.set_thetalim(0, np.pi/2)\n",
    "\n",
    "# # Ensure square aspect ratio\n",
    "# plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# # Create Taylor diagram\n",
    "# taylor_diagram(ax, std_models, std_ref, corr_models)\n",
    "\n",
    "# # Adjust layout to prevent squeezing\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skill_metrics import taylor_diagram\n",
    "# import geocat.viz as gv\n",
    "\n",
    "# dAtA = {\n",
    "#     \"Observed\": np.array(Data['1D']['LMP']),\n",
    "#     \"FARM\": np.array(Data['1D']['FARM']),\n",
    "#     \"IMP1F\": np.array(Data['1D']['IMP1F']),\n",
    "#     \"IMP2F\": np.array(Data['1D']['IMP2F']),\n",
    "#     \"IMP1F_ODR\": np.array(Data['1D']['IMP1F_ODR']),\n",
    "#     \"IMP2F_ODR\": np.array(Data['1D']['IMP2F_ODR'])\n",
    "# }\n",
    "\n",
    "# # List of model names (excluding Observed)\n",
    "# mod_list = list(dAtA.keys())[1:]\n",
    "\n",
    "# # Observations\n",
    "# std_ref = np.std(dAtA[\"Observed\"])\n",
    "\n",
    "# colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\"]\n",
    "# models = [\"FARM\", \"IMP1F\", \"IMP2F\", \"IMP1F_ODR\", \"IMP2F_ODR\"]\n",
    "\n",
    "# # Calculate statistics for each model\n",
    "# stds = []\n",
    "# corrs = []\n",
    "# biases = []\n",
    "\n",
    "# for model in mod_list:\n",
    "#     stds.append(np.std(dAtA[model]) / std_ref)  # Normalized standard deviation\n",
    "#     corrs.append(np.corrcoef(dAtA[\"Observed\"], dAtA[model])[0, 1])  # Correlation coefficient\n",
    "#     biases.append(np.mean(dAtA[model] - dAtA[\"Observed\"]) * 100)  # Bias (%)\n",
    "\n",
    "# # Convert to NumPy arrays\n",
    "# stds = np.array(stds)\n",
    "# corrs = np.array(corrs)\n",
    "# biases = np.array(biases)\n",
    "\n",
    "# # Plot the Taylor Diagram\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# taylor = gv.TaylorDiagram(fig=fig, label=\"Obs-Ref\")\n",
    "# taylor.add_corr_grid(np.linspace(0, 1, 11))  # Correlation grid lines\n",
    "\n",
    "\n",
    "# # Add models to the Taylor diagram\n",
    "# # taylor.add_model_set(\n",
    "# #     stds,  # Standard deviations\n",
    "# #     corrs,  # Correlations\n",
    "# #     percent_bias_on=True,  # Use bias for marker size\n",
    "# #     bias_array=biases,  # Bias array\n",
    "# #     color=\"black\",\n",
    "# #     #label=\"Models\",  # Label for the legend\n",
    "# #     fontsize=12\n",
    "# # )\n",
    "# for i, model in enumerate(mod_list):\n",
    "#     taylor.add_model_set(\n",
    "#         [stds[i]],  # Standard deviations\n",
    "#         [corrs[i]],  # Correlations\n",
    "#         percent_bias_on=True,  # Disable bias labeling\n",
    "#         bias_array=[biases[i]],  # Bias array\n",
    "#         color=colors[i],  # Assign each model a color\n",
    "#         label=models[i],\n",
    "#         fontsize=12\n",
    "#     )\n",
    "\n",
    "# # Add model names\n",
    "# #taylor.add_model_name(mod_list, fontsize=12)\n",
    "\n",
    "# # Add legends and contours\n",
    "# taylor.add_legend(fontsize=12)\n",
    "# taylor.add_bias_legend()\n",
    "# taylor.add_contours(levels=np.arange(0, 1, 0.25), colors=\"lightgray\", linewidths=0.5)\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmp_dust_enea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
